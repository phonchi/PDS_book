<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.306">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="phonchi">
<meta name="dcterms.date" content="2023-05-29">

<title>Practical and Innovative Analytics in Data Science - 13&nbsp; Hyperparameter Tuning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./NumPy_tutorial.html" rel="next">
<link href="./12_Representation_learning.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./13_Hyperparameter.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Practical and Innovative Analytics in Data Science</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_end_to_end_machine_learning_project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">End-to-end Machine Learning project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Framing the problem and constructing the dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Relational_Database_and_data_wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Relational Database and data wrangling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Clean_feature_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data cleaning and feature engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Feature_selection_extraction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Feature selection and extraction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_XAI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Explainable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Deploy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Deploy and monitoring</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_neural_nets_with_tensorflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to Artificial Neural Networks - Tensorflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_Convolutional_NeuralNetworks_tensorflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Image processing with Convolutional Neural Networks - Tensorflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_Recurrent_Neural_Networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence Processing with RNNs and Attention - Tensforflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_Transfer_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Transfer learning and self-supervised learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_Representation_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Representation learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_Hyperparameter.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./NumPy_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Numpy - multidimensional data arrays for python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Introduction to Colab</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kaggle-explore.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Introduction to Kaggle</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_neural_nets_with_pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Introduction to Artificial Neural Networks - Pytorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_Convolutional_NeuralNetworks_pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Image processing with Convolutional Neural Networks - Pytorch</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#setup" id="toc-setup" class="nav-link active" data-scroll-target="#setup"><span class="header-section-number">13.1</span> Setup</a></li>
  <li><a href="#hyparameter-tuning-for-sklearn" id="toc-hyparameter-tuning-for-sklearn" class="nav-link" data-scroll-target="#hyparameter-tuning-for-sklearn"><span class="header-section-number">13.2</span> Hyparameter tuning for <code>sklearn</code></a>
  <ul class="collapse">
  <li><a href="#grid-search" id="toc-grid-search" class="nav-link" data-scroll-target="#grid-search"><span class="header-section-number">13.2.1</span> Grid search</a></li>
  <li><a href="#random-search" id="toc-random-search" class="nav-link" data-scroll-target="#random-search"><span class="header-section-number">13.2.2</span> Random Search</a></li>
  <li><a href="#bayesian-optimization" id="toc-bayesian-optimization" class="nav-link" data-scroll-target="#bayesian-optimization"><span class="header-section-number">13.2.3</span> Bayesian Optimization</a></li>
  </ul></li>
  <li><a href="#hyperparamter-tuning-using-kerastuner" id="toc-hyperparamter-tuning-using-kerastuner" class="nav-link" data-scroll-target="#hyperparamter-tuning-using-kerastuner"><span class="header-section-number">13.3</span> Hyperparamter tuning using <code>KerasTuner</code></a>
  <ul class="collapse">
  <li><a href="#tune-model-architecture" id="toc-tune-model-architecture" class="nav-link" data-scroll-target="#tune-model-architecture"><span class="header-section-number">13.3.1</span> Tune model architecture</a></li>
  <li><a href="#tune-model-training" id="toc-tune-model-training" class="nav-link" data-scroll-target="#tune-model-training"><span class="header-section-number">13.3.2</span> Tune model training</a></li>
  <li><a href="#tune-data-preprocessing" id="toc-tune-data-preprocessing" class="nav-link" data-scroll-target="#tune-data-preprocessing"><span class="header-section-number">13.3.3</span> Tune data preprocessing</a></li>
  </ul></li>
  <li><a href="#network-architecture-search-with-autokeras" id="toc-network-architecture-search-with-autokeras" class="nav-link" data-scroll-target="#network-architecture-search-with-autokeras"><span class="header-section-number">13.4</span> Network architecture search with <code>AutoKeras</code></a>
  <ul class="collapse">
  <li><a href="#tuning-cnns-for-image-classification" id="toc-tuning-cnns-for-image-classification" class="nav-link" data-scroll-target="#tuning-cnns-for-image-classification"><span class="header-section-number">13.4.1</span> Tuning CNNs for image classification</a></li>
  <li><a href="#automated-pipeline-search-with-autokeras" id="toc-automated-pipeline-search-with-autokeras" class="nav-link" data-scroll-target="#automated-pipeline-search-with-autokeras"><span class="header-section-number">13.4.2</span> Automated pipeline search with <code>AutoKeras</code></a></li>
  </ul></li>
  <li><a href="#w-b" id="toc-w-b" class="nav-link" data-scroll-target="#w-b"><span class="header-section-number">13.5</span> W &amp; B</a>
  <ul class="collapse">
  <li><a href="#normal-logging-flow" id="toc-normal-logging-flow" class="nav-link" data-scroll-target="#normal-logging-flow"><span class="header-section-number">13.5.1</span> Normal logging flow</a></li>
  <li><a href="#log-predictions-on-test-data-using-wandbevalcallback" id="toc-log-predictions-on-test-data-using-wandbevalcallback" class="nav-link" data-scroll-target="#log-predictions-on-test-data-using-wandbevalcallback"><span class="header-section-number">13.5.3</span> Log predictions on test data using <code>WandbEvalCallback</code></a></li>
  <li><a href="#introduction-to-hyperparameter-sweeps-using-wb-and-keras" id="toc-introduction-to-hyperparameter-sweeps-using-wb-and-keras" class="nav-link" data-scroll-target="#introduction-to-hyperparameter-sweeps-using-wb-and-keras"><span class="header-section-number">13.5.5</span> Introduction to Hyperparameter Sweeps using W&amp;B and <code>Keras</code></a></li>
  <li><a href="#model-and-data-versioning" id="toc-model-and-data-versioning" class="nav-link" data-scroll-target="#model-and-data-versioning"><span class="header-section-number">13.5.16</span> Model and data versioning</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">13.6</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>phonchi </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 29, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>


<table align="left">
<tbody><tr><td>
<a href="https://colab.research.google.com/github/phonchi/nsysu-math608/blob/master/static_files/presentations/13_Hyperparameter.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
</td>
<td>
<a target="_blank" href="https://kaggle.com/kernels/welcome?src=https://github.com/phonchi/nsysu-math608/blob/master/static_files/presentations/13_Hyperparameter.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg"></a>
</td>

</tr></tbody></table>
<p><br></p>
<section id="setup" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="setup"><span class="header-section-number">13.1</span> Setup</h2>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:43721,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685245851723,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="c8e359ee-e6a8-4363-e055-cea7843b0ae2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="op">%</span>pip install optuna <span class="op">-</span>q</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="op">%</span>pip install keras<span class="op">-</span>tuner <span class="op">-</span>q</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="op">%</span>pip install autokeras <span class="op">-</span>q</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="op">%</span>pip install wandb <span class="op">-</span>q</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 365.7/365.7 kB 4.1 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 15.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 6.1 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.1/176.1 kB 14.8 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.6/148.6 kB 9.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 527.7/527.7 kB 32.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 39.4 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 26.0 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 22.0 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.5/206.5 kB 22.8 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 8.6 MB/s eta 0:00:00
  Building wheel for pathtools (setup.py) ... done</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Python ≥3.7 is recommended</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">import</span> sys</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="cf">assert</span> sys.version_info <span class="op">&gt;=</span> (<span class="dv">3</span>, <span class="dv">7</span>)</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co"># Scikit-Learn ≥1.01 is recommended</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="im">from</span> packaging <span class="im">import</span> version</span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="im">import</span> sklearn</span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, roc_curve</span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> average_precision_score</span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> label_binarize</span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="cf">assert</span> version.parse(sklearn.__version__) <span class="op">&gt;=</span> version.parse(<span class="st">"1.0.1"</span>)</span>
<span id="cb3-18"><a href="#cb3-18"></a></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co"># Tensorflow ≥2.8.0 is recommended</span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-21"><a href="#cb3-21"></a><span class="cf">assert</span> version.parse(tf.__version__) <span class="op">&gt;=</span> version.parse(<span class="st">"2.8.0"</span>)</span>
<span id="cb3-22"><a href="#cb3-22"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span>
<span id="cb3-23"><a href="#cb3-23"></a><span class="im">from</span> tensorflow.keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb3-24"><a href="#cb3-24"></a></span>
<span id="cb3-25"><a href="#cb3-25"></a><span class="im">import</span> optuna </span>
<span id="cb3-26"><a href="#cb3-26"></a><span class="im">from</span> optuna.samplers <span class="im">import</span> GridSampler, RandomSampler, TPESampler</span>
<span id="cb3-27"><a href="#cb3-27"></a><span class="im">import</span> keras_tuner <span class="im">as</span> kt</span>
<span id="cb3-28"><a href="#cb3-28"></a><span class="im">import</span> autokeras <span class="im">as</span> ak</span>
<span id="cb3-29"><a href="#cb3-29"></a></span>
<span id="cb3-30"><a href="#cb3-30"></a><span class="im">import</span> wandb</span>
<span id="cb3-31"><a href="#cb3-31"></a><span class="im">from</span> wandb.keras <span class="im">import</span> WandbMetricsLogger, WandbModelCheckpoint, WandbEvalCallback, WandbCallback</span>
<span id="cb3-32"><a href="#cb3-32"></a></span>
<span id="cb3-33"><a href="#cb3-33"></a><span class="co"># Common imports</span></span>
<span id="cb3-34"><a href="#cb3-34"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-35"><a href="#cb3-35"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-36"><a href="#cb3-36"></a><span class="im">import</span> os</span>
<span id="cb3-37"><a href="#cb3-37"></a><span class="im">from</span> random <span class="im">import</span> shuffle</span>
<span id="cb3-38"><a href="#cb3-38"></a><span class="im">import</span> random</span>
<span id="cb3-39"><a href="#cb3-39"></a><span class="im">import</span> time</span>
<span id="cb3-40"><a href="#cb3-40"></a><span class="im">import</span> math</span>
<span id="cb3-41"><a href="#cb3-41"></a><span class="im">import</span> pprint</span>
<span id="cb3-42"><a href="#cb3-42"></a></span>
<span id="cb3-43"><a href="#cb3-43"></a><span class="co"># To plot pretty figures</span></span>
<span id="cb3-44"><a href="#cb3-44"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-45"><a href="#cb3-45"></a><span class="im">import</span> matplotlib</span>
<span id="cb3-46"><a href="#cb3-46"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb3-47"><a href="#cb3-47"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb3-48"><a href="#cb3-48"></a></span>
<span id="cb3-49"><a href="#cb3-49"></a>plt.rc(<span class="st">'font'</span>, size<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb3-50"><a href="#cb3-50"></a>plt.rc(<span class="st">'axes'</span>, labelsize<span class="op">=</span><span class="dv">14</span>, titlesize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb3-51"><a href="#cb3-51"></a>plt.rc(<span class="st">'legend'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb3-52"><a href="#cb3-52"></a>plt.rc(<span class="st">'xtick'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-53"><a href="#cb3-53"></a>plt.rc(<span class="st">'ytick'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-54"><a href="#cb3-54"></a></span>
<span id="cb3-55"><a href="#cb3-55"></a><span class="co"># to make this notebook's output stable across runs</span></span>
<span id="cb3-56"><a href="#cb3-56"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-57"><a href="#cb3-57"></a>tf.random.set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="cf">if</span> <span class="kw">not</span> tf.config.list_physical_devices(<span class="st">'GPU'</span>):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="bu">print</span>(<span class="st">"No GPU was detected. Neural nets can be very slow without a GPU."</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="cf">if</span> <span class="st">"google.colab"</span> <span class="kw">in</span> sys.modules:</span>
<span id="cb4-4"><a href="#cb4-4"></a>        <span class="bu">print</span>(<span class="st">"Go to Runtime &gt; Change runtime and select a GPU hardware "</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>              <span class="st">"accelerator."</span>)</span>
<span id="cb4-6"><a href="#cb4-6"></a>    <span class="cf">if</span> <span class="st">"kaggle_secrets"</span> <span class="kw">in</span> sys.modules:</span>
<span id="cb4-7"><a href="#cb4-7"></a>        <span class="bu">print</span>(<span class="st">"Go to Settings &gt; Accelerator and select GPU."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="hyparameter-tuning-for-sklearn" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="hyparameter-tuning-for-sklearn"><span class="header-section-number">13.2</span> Hyparameter tuning for <code>sklearn</code></h2>
<p>Hyper-parameters are parameters that are not directly learnt within estimators. In <code>scikit-learn</code> they are passed as arguments to the constructor of the estimator classes. Typical examples include <code>C</code>, <code>kernel</code> and <code>gamma</code> for Support Vector Classifier, <code>alpha</code> for Lasso, etc.</p>
<p>It is possible and recommended to search the hyper-parameter space for the best cross validation score. Any parameter provided when constructing an estimator may be optimized in this manner. Specifically, to find the names and current values for all parameters for a given estimator, we can use <code>estimator.get_params()</code>.</p>
<p>A search consists of: - an estimator (regressor or classifier such as <code>sklearn.svm.SVC()</code>); - a parameter space; - a method for searching or sampling candidates; - a cross-validation scheme; and - a score function.</p>
<blockquote class="blockquote">
<p>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. <strong>It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior.</strong></p>
</blockquote>
<p>Let us load the example dataset first:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># load data</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>digits <span class="op">=</span> datasets.load_digits()</span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="co"># flatten the images</span></span>
<span id="cb5-5"><a href="#cb5-5"></a>n_samples <span class="op">=</span> <span class="bu">len</span>(digits.images)</span>
<span id="cb5-6"><a href="#cb5-6"></a>data <span class="op">=</span> digits.images.reshape((n_samples, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb5-7"><a href="#cb5-7"></a></span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="co"># Split data into train and test subsets</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(data, digits.target, test_size<span class="op">=</span><span class="fl">0.25</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:311,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685246157980,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="d1f7e5e5-2c01-4be2-d9cb-d53b5e886540">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>X_train.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(1347, 64)</code></pre>
</div>
</div>
<section id="grid-search" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="grid-search"><span class="header-section-number">13.2.1</span> Grid search</h3>
<p>The grid search provided by <code>GridSearchCV()</code> exhaustively generates candidates from a grid of parameter values specified with the <code>param_grid</code> parameter. Here our estimator is <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForestClassifier</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># random forest classifier object</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>rfc <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co"># define sample space</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>param_grid <span class="op">=</span> {</span>
<span id="cb8-6"><a href="#cb8-6"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>],</span>
<span id="cb8-7"><a href="#cb8-7"></a>    <span class="st">'criterion'</span>: [<span class="st">'gini'</span>, <span class="st">'entropy'</span>],</span>
<span id="cb8-8"><a href="#cb8-8"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>],</span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>],</span>
<span id="cb8-10"><a href="#cb8-10"></a>    <span class="st">'max_depth'</span>: [<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>]</span>
<span id="cb8-11"><a href="#cb8-11"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, let’s obtain the optimal hyperparameters using the grid search method and time the process. This means that we will test all 108 hyperparameter sets and pick out the one that yields the best results.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># create grid search object</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>gs <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>rfc,</span>
<span id="cb9-3"><a href="#cb9-3"></a>                  param_grid<span class="op">=</span>param_grid,</span>
<span id="cb9-4"><a href="#cb9-4"></a>                  scoring<span class="op">=</span><span class="st">'f1_micro'</span>,</span>
<span id="cb9-5"><a href="#cb9-5"></a>                  cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb9-6"><a href="#cb9-6"></a>                  verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a>gs.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we will use <code>Optuna</code> instead:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb10-2"><a href="#cb10-2"></a>    <span class="co">"""return the f1-score"""</span></span>
<span id="cb10-3"><a href="#cb10-3"></a></span>
<span id="cb10-4"><a href="#cb10-4"></a>    <span class="co"># search space</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>    n_estimators <span class="op">=</span>  trial.suggest_int(<span class="st">'n_estimators'</span>, low<span class="op">=</span><span class="dv">100</span>, high<span class="op">=</span><span class="dv">200</span>, step<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb10-6"><a href="#cb10-6"></a>    criterion <span class="op">=</span> trial.suggest_categorical(<span class="st">'criterion'</span>, [<span class="st">'gini'</span>, <span class="st">'entropy'</span>])</span>
<span id="cb10-7"><a href="#cb10-7"></a>    min_samples_split <span class="op">=</span> trial.suggest_int(<span class="st">'min_samples_split'</span>, low<span class="op">=</span><span class="dv">2</span>, high<span class="op">=</span><span class="dv">4</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8"></a>    max_depth <span class="op">=</span> trial.suggest_int(<span class="st">'max_depth'</span>, low<span class="op">=</span><span class="dv">5</span>, high<span class="op">=</span><span class="dv">7</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-9"><a href="#cb10-9"></a>    max_features <span class="op">=</span> trial.suggest_categorical(<span class="st">'max_features'</span>, [<span class="st">'sqrt'</span>,<span class="st">'log2'</span>])</span>
<span id="cb10-10"><a href="#cb10-10"></a>    <span class="co"># random forest classifier object</span></span>
<span id="cb10-11"><a href="#cb10-11"></a>    rfc <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span>n_estimators, </span>
<span id="cb10-12"><a href="#cb10-12"></a>                                                  criterion<span class="op">=</span>criterion,</span>
<span id="cb10-13"><a href="#cb10-13"></a>                                                  min_samples_split<span class="op">=</span>min_samples_split,</span>
<span id="cb10-14"><a href="#cb10-14"></a>                                                  max_depth<span class="op">=</span>max_depth,</span>
<span id="cb10-15"><a href="#cb10-15"></a>                                                  max_features<span class="op">=</span>max_features,</span>
<span id="cb10-16"><a href="#cb10-16"></a>                                                  random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-17"><a href="#cb10-17"></a>    score <span class="op">=</span>  cross_val_score(estimator<span class="op">=</span>rfc, </span>
<span id="cb10-18"><a href="#cb10-18"></a>                             X<span class="op">=</span>X_train, </span>
<span id="cb10-19"><a href="#cb10-19"></a>                             y<span class="op">=</span>y_train, </span>
<span id="cb10-20"><a href="#cb10-20"></a>                             scoring<span class="op">=</span><span class="st">'f1_micro'</span>,</span>
<span id="cb10-21"><a href="#cb10-21"></a>                             cv<span class="op">=</span><span class="dv">5</span>).mean()</span>
<span id="cb10-22"><a href="#cb10-22"></a>    <span class="cf">return</span> score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:236893,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899418661,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="5c92634a-41a7-44cb-da38-3eb350d3cb10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># create a study (aim to maximize score)</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>search_space <span class="op">=</span> param_grid</span>
<span id="cb11-3"><a href="#cb11-3"></a>study <span class="op">=</span> optuna.create_study(sampler<span class="op">=</span>GridSampler(param_grid), direction<span class="op">=</span><span class="st">'maximize'</span>)</span>
<span id="cb11-4"><a href="#cb11-4"></a></span>
<span id="cb11-5"><a href="#cb11-5"></a><span class="co"># perform hyperparamter tuning (while timing the process)</span></span>
<span id="cb11-6"><a href="#cb11-6"></a>time_start <span class="op">=</span> time.time()</span>
<span id="cb11-7"><a href="#cb11-7"></a>study.optimize(objective, show_progress_bar<span class="op">=</span><span class="va">True</span>, n_trials<span class="op">=</span><span class="dv">108</span>)</span>
<span id="cb11-8"><a href="#cb11-8"></a>time_grid <span class="op">=</span> time.time() <span class="op">-</span> time_start</span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="co"># store result in a data frame </span></span>
<span id="cb11-11"><a href="#cb11-11"></a>columns <span class="op">=</span> [<span class="st">'Number of iterations'</span>, <span class="st">'Iteration Number of Optimal Hyperparamters'</span>, <span class="st">'Score'</span>, <span class="st">'Time Elapsed (s)'</span>]</span>
<span id="cb11-12"><a href="#cb11-12"></a>values_grid <span class="op">=</span> [<span class="dv">108</span>, study.best_trial.number, study.best_trial.value, time_grid]</span>
<span id="cb11-13"><a href="#cb11-13"></a>results_grid <span class="op">=</span> pd.DataFrame([values_grid], columns <span class="op">=</span> columns)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2023-05-24 03:32:56,934] A new study created in memory with name: no-name-185675b5-a671-4372-8e9a-468be41c2e10
/usr/local/lib/python3.10/dist-packages/optuna/progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.
  self._init_valid()</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"396c5c711b344dae8bb394bd95ea3769","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2023-05-24 03:32:59,443] Trial 0 finished with value: 0.912405342145119 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 0 with value: 0.912405342145119.
[I 2023-05-24 03:33:02,630] Trial 1 finished with value: 0.9250227178851714 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 1 with value: 0.9250227178851714.
[I 2023-05-24 03:33:05,533] Trial 2 finished with value: 0.9324631694891918 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:06,777] Trial 3 finished with value: 0.9183367754371471 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:08,470] Trial 4 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:10,680] Trial 5 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:13,703] Trial 6 finished with value: 0.9064628941208868 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:16,354] Trial 7 finished with value: 0.9005039239983479 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:19,684] Trial 8 finished with value: 0.9235439900867408 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:21,402] Trial 9 finished with value: 0.9257662123089634 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:24,212] Trial 10 finished with value: 0.9094203497177474 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:27,877] Trial 11 finished with value: 0.909436871816054 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:29,396] Trial 12 finished with value: 0.9146413327825968 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:31,885] Trial 13 finished with value: 0.9094396254991051 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:34,273] Trial 14 finished with value: 0.9220542475561062 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:35,409] Trial 15 finished with value: 0.9064601404378356 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:36,590] Trial 16 finished with value: 0.9005259534627564 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:38,963] Trial 17 finished with value: 0.9146358254164946 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:42,036] Trial 18 finished with value: 0.9027509293680298 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:44,686] Trial 19 finished with value: 0.9294781770618201 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:46,076] Trial 20 finished with value: 0.9161145532149249 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:48,029] Trial 21 finished with value: 0.9220597549222085 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:50,518] Trial 22 finished with value: 0.9116590940382763 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:52,397] Trial 23 finished with value: 0.90868787002616 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:56,365] Trial 24 finished with value: 0.9124136031942722 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:33:58,279] Trial 25 finished with value: 0.9168552939556657 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:01,031] Trial 26 finished with value: 0.9183477901693516 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:02,537] Trial 27 finished with value: 0.9109211069805866 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:04,567] Trial 28 finished with value: 0.9131488365689109 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:06,559] Trial 29 finished with value: 0.9146385790995456 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:08,323] Trial 30 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:10,239] Trial 31 finished with value: 0.9027454220019276 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:12,345] Trial 32 finished with value: 0.9153738124741843 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:14,730] Trial 33 finished with value: 0.9198320253338842 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:17,433] Trial 34 finished with value: 0.9138758088943962 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:19,158] Trial 35 finished with value: 0.9309596585433016 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:21,127] Trial 36 finished with value: 0.9213190141814678 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:23,385] Trial 37 finished with value: 0.9034861627426685 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:25,632] Trial 38 finished with value: 0.9317114140162467 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:27,953] Trial 39 finished with value: 0.8990279498829684 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:29,098] Trial 40 finished with value: 0.8938372573316811 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:30,595] Trial 41 finished with value: 0.9109100922483823 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:31,638] Trial 42 finished with value: 0.8960677406030566 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:33,112] Trial 43 finished with value: 0.9057221533801461 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:38,448] Trial 44 finished with value: 0.9294754233787691 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:42,098] Trial 45 finished with value: 0.9086933773922621 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:44,185] Trial 46 finished with value: 0.9146413327825966 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:45,545] Trial 47 finished with value: 0.9294919454770756 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:49,061] Trial 48 finished with value: 0.9176042957455597 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:51,829] Trial 49 finished with value: 0.9235384827206389 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:53,027] Trial 50 finished with value: 0.9242764697783284 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:56,547] Trial 51 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:58,264] Trial 52 finished with value: 0.9205782734407271 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:34:59,834] Trial 53 finished with value: 0.922048740190004 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:35:03,354] Trial 54 finished with value: 0.9287346826380283 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:35:04,961] Trial 55 finished with value: 0.9124136031942722 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:35:07,470] Trial 56 finished with value: 0.9302326862178163 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:35:08,708] Trial 57 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:35:11,191] Trial 58 finished with value: 0.9116618477213272 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9324631694891918.
[I 2023-05-24 03:35:12,661] Trial 59 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:15,838] Trial 60 finished with value: 0.9175987883794576 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:16,986] Trial 61 finished with value: 0.8916040203772544 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:18,563] Trial 62 finished with value: 0.8967947129285418 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:21,396] Trial 63 finished with value: 0.9250227178851714 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:24,192] Trial 64 finished with value: 0.916869062370921 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:26,956] Trial 65 finished with value: 0.9183395291201982 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:29,498] Trial 66 finished with value: 0.9034944237918217 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:30,592] Trial 67 finished with value: 0.9131433292028088 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:32,428] Trial 68 finished with value: 0.9294864381109734 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:33,919] Trial 69 finished with value: 0.89605121850475 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:35,847] Trial 70 finished with value: 0.928007710312543 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:38,759] Trial 71 finished with value: 0.9324576621230897 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:40,130] Trial 72 finished with value: 0.9124053421451193 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:42,819] Trial 73 finished with value: 0.9086933773922622 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:44,966] Trial 74 finished with value: 0.9153738124741843 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:46,137] Trial 75 finished with value: 0.924292991876635 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:47,752] Trial 76 finished with value: 0.915371058791133 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:49,775] Trial 77 finished with value: 0.9257827344072698 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:51,653] Trial 78 finished with value: 0.9153765661572354 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:54,414] Trial 79 finished with value: 0.9317114140162467 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:57,526] Trial 80 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:35:59,378] Trial 81 finished with value: 0.9294891917940244 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:36:00,680] Trial 82 finished with value: 0.9064601404378356 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:36:03,287] Trial 83 finished with value: 0.9116480793060718 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:36:05,805] Trial 84 finished with value: 0.9072174032768829 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 59 with value: 0.9331956491807792.
[I 2023-05-24 03:36:07,974] Trial 85 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:10,077] Trial 86 finished with value: 0.9220570012391572 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:11,690] Trial 87 finished with value: 0.9168580476387168 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:12,870] Trial 88 finished with value: 0.9131626049841663 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:15,187] Trial 89 finished with value: 0.913148836568911 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:17,057] Trial 90 finished with value: 0.9079498829684702 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:19,437] Trial 91 finished with value: 0.9228032493460002 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:22,674] Trial 92 finished with value: 0.9101831199228968 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:24,856] Trial 93 finished with value: 0.9220652622883106 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:26,105] Trial 94 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:28,253] Trial 95 finished with value: 0.9072063885446784 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:29,936] Trial 96 finished with value: 0.9072036348616275 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:32,011] Trial 97 finished with value: 0.8982789480930744 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:34,132] Trial 98 finished with value: 0.8975437147184359 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:36,927] Trial 99 finished with value: 0.928007710312543 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:38,974] Trial 100 finished with value: 0.9176042957455598 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:40,226] Trial 101 finished with value: 0.9153765661572353 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:42,948] Trial 102 finished with value: 0.9190885309100922 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:44,413] Trial 103 finished with value: 0.9294836844279224 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:45,530] Trial 104 finished with value: 0.9057276607462482 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:49,537] Trial 105 finished with value: 0.9294891917940244 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 85 with value: 0.9346853917114141.
[I 2023-05-24 03:36:51,709] Trial 106 finished with value: 0.9354261324521549 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 106 with value: 0.9354261324521549.
[I 2023-05-24 03:36:53,457] Trial 107 finished with value: 0.9279966955803387 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 106 with value: 0.9354261324521549.</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:16,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899418661,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="2230b2d9-b477-4bb8-bc75-82f83801dd50">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>study.best_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>{'n_estimators': 150,
 'criterion': 'entropy',
 'min_samples_split': 3,
 'max_depth': 7,
 'max_features': 'sqrt'}</code></pre>
</div>
</div>
</section>
<section id="random-search" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="random-search"><span class="header-section-number">13.2.2</span> Random Search</h3>
<p>While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favorable properties. <code>RandomizedSearchCV</code> implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:</p>
<ul>
<li>A budget can be chosen independent of the number of parameters and possible values.</li>
<li>Adding parameters that do not influence the performance does not decrease efficiency.</li>
</ul>
<p>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for <code>GridSearchCV</code>. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the <code>n_iter</code> parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># create a random search object</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>rs <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>rfc,</span>
<span id="cb16-3"><a href="#cb16-3"></a>                  param_distributions<span class="op">=</span>param_grid,</span>
<span id="cb16-4"><a href="#cb16-4"></a>                  scoring<span class="op">=</span><span class="st">'f1_micro'</span>,</span>
<span id="cb16-5"><a href="#cb16-5"></a>                  cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb16-6"><a href="#cb16-6"></a>                  n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb16-7"><a href="#cb16-7"></a>                  verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb16-8"><a href="#cb16-8"></a>                  n_iter<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb16-9"><a href="#cb16-9"></a></span>
<span id="cb16-10"><a href="#cb16-10"></a>rs.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we will use <code>Optuna</code> instead:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:99060,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899517714,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="c651c1f5-8bb1-445b-f018-eb341e13e327">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># create a study (aim to maximize score)</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>study <span class="op">=</span> optuna.create_study(sampler<span class="op">=</span>RandomSampler(), direction<span class="op">=</span><span class="st">'maximize'</span>)</span>
<span id="cb17-3"><a href="#cb17-3"></a></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="co"># perform hyperparamter tuning (while timing the process)</span></span>
<span id="cb17-5"><a href="#cb17-5"></a>time_start <span class="op">=</span> time.time()</span>
<span id="cb17-6"><a href="#cb17-6"></a>study.optimize(objective, show_progress_bar<span class="op">=</span><span class="va">True</span>, n_trials<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb17-7"><a href="#cb17-7"></a>time_random <span class="op">=</span> time.time() <span class="op">-</span> time_start</span>
<span id="cb17-8"><a href="#cb17-8"></a></span>
<span id="cb17-9"><a href="#cb17-9"></a><span class="co"># store result in a data frame </span></span>
<span id="cb17-10"><a href="#cb17-10"></a>columns <span class="op">=</span> [<span class="st">'Number of iterations'</span>, <span class="st">'Iteration Number of Optimal Hyperparamters'</span>, <span class="st">'Score'</span>, <span class="st">'Time Elapsed (s)'</span>]</span>
<span id="cb17-11"><a href="#cb17-11"></a>values_random <span class="op">=</span> [<span class="dv">50</span>, study.best_trial.number, study.best_trial.value, time_random]</span>
<span id="cb17-12"><a href="#cb17-12"></a>results_random <span class="op">=</span> pd.DataFrame([values_random], columns <span class="op">=</span> columns)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2023-05-24 03:36:53,501] A new study created in memory with name: no-name-6b952135-06c4-4c62-bfe4-10f435063be0
/usr/local/lib/python3.10/dist-packages/optuna/progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.
  self._init_valid()</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5bfd115f1b2f41e3ae843e7b54315e40","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2023-05-24 03:36:56,505] Trial 0 finished with value: 0.9116618477213272 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9116618477213272.
[I 2023-05-24 03:36:58,816] Trial 1 finished with value: 0.9064628941208868 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.9116618477213272.
[I 2023-05-24 03:37:00,477] Trial 2 finished with value: 0.9146413327825968 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9146413327825968.
[I 2023-05-24 03:37:02,120] Trial 3 finished with value: 0.8938372573316811 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9146413327825968.
[I 2023-05-24 03:37:03,514] Trial 4 finished with value: 0.9294919454770756 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:06,530] Trial 5 finished with value: 0.9094203497177474 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:09,683] Trial 6 finished with value: 0.9146358254164946 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:12,148] Trial 7 finished with value: 0.9176042957455597 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:13,912] Trial 8 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:16,052] Trial 9 finished with value: 0.8967947129285418 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:18,753] Trial 10 finished with value: 0.9190885309100922 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:19,989] Trial 11 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9294919454770756.
[I 2023-05-24 03:37:21,311] Trial 12 finished with value: 0.9309596585433016 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:22,570] Trial 13 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:24,167] Trial 14 finished with value: 0.9168580476387168 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:25,251] Trial 15 finished with value: 0.9057276607462482 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:26,730] Trial 16 finished with value: 0.9109100922483823 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:29,249] Trial 17 finished with value: 0.9086933773922622 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:31,401] Trial 18 finished with value: 0.9153738124741843 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:32,559] Trial 19 finished with value: 0.9064601404378356 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:34,848] Trial 20 finished with value: 0.913148836568911 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:36,454] Trial 21 finished with value: 0.915371058791133 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:38,933] Trial 22 finished with value: 0.9183395291201982 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:41,200] Trial 23 finished with value: 0.8967947129285418 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:42,603] Trial 24 finished with value: 0.9109211069805866 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:44,407] Trial 25 finished with value: 0.9294864381109734 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:46,818] Trial 26 finished with value: 0.9072174032768829 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:48,624] Trial 27 finished with value: 0.9168580476387168 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:51,256] Trial 28 finished with value: 0.9294754233787691 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:52,510] Trial 29 finished with value: 0.924292991876635 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:54,237] Trial 30 finished with value: 0.9131626049841663 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:56,439] Trial 31 finished with value: 0.9079498829684702 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:58,165] Trial 32 finished with value: 0.9220570012391572 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:37:59,389] Trial 33 finished with value: 0.9027509293680298 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:00,889] Trial 34 finished with value: 0.89605121850475 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:02,171] Trial 35 finished with value: 0.9168552939556657 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:04,603] Trial 36 finished with value: 0.9072174032768829 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:07,636] Trial 37 finished with value: 0.9250227178851714 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:10,114] Trial 38 finished with value: 0.9072063885446784 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:11,235] Trial 39 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:13,222] Trial 40 finished with value: 0.9250227178851714 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:14,296] Trial 41 finished with value: 0.9057276607462482 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:17,222] Trial 42 finished with value: 0.9294891917940244 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:18,473] Trial 43 finished with value: 0.9027509293680298 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:20,391] Trial 44 finished with value: 0.9309596585433016 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:22,972] Trial 45 finished with value: 0.9176042957455598 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:25,420] Trial 46 finished with value: 0.9072174032768829 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:27,583] Trial 47 finished with value: 0.9094203497177474 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:30,060] Trial 48 finished with value: 0.9116618477213272 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.9309596585433016.
[I 2023-05-24 03:38:32,588] Trial 49 finished with value: 0.9101831199228968 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 12 with value: 0.9309596585433016.</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:11,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899517714,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="62084408-f2b1-4516-ad78-0fd9d677975f">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>study.best_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>{'n_estimators': 100,
 'criterion': 'entropy',
 'min_samples_split': 2,
 'max_depth': 7,
 'max_features': 'log2'}</code></pre>
</div>
</div>
</section>
<section id="bayesian-optimization" class="level3" data-number="13.2.3">
<h3 data-number="13.2.3" class="anchored" data-anchor-id="bayesian-optimization"><span class="header-section-number">13.2.3</span> Bayesian Optimization</h3>
<p>Finally, we perform hyperparameter tuning with the Bayesian optimization and time the process. In Python, this can be accomplished with the <code>Optuna</code> module.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:104257,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899654724,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="03f14c16-4281-41c4-b2f8-fec8176898e3">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="co"># create a study (aim to maximize score)</span></span>
<span id="cb22-2"><a href="#cb22-2"></a>study <span class="op">=</span> optuna.create_study(sampler<span class="op">=</span>TPESampler(), direction<span class="op">=</span><span class="st">'maximize'</span>)</span>
<span id="cb22-3"><a href="#cb22-3"></a></span>
<span id="cb22-4"><a href="#cb22-4"></a><span class="co"># perform hyperparamter tuning (while timing the process)</span></span>
<span id="cb22-5"><a href="#cb22-5"></a>time_start <span class="op">=</span> time.time()</span>
<span id="cb22-6"><a href="#cb22-6"></a>study.optimize(objective, show_progress_bar<span class="op">=</span><span class="va">True</span>, n_trials<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb22-7"><a href="#cb22-7"></a>time_bayesian <span class="op">=</span> time.time() <span class="op">-</span> time_start</span>
<span id="cb22-8"><a href="#cb22-8"></a></span>
<span id="cb22-9"><a href="#cb22-9"></a><span class="co"># store result in a data frame </span></span>
<span id="cb22-10"><a href="#cb22-10"></a>values_bayesian <span class="op">=</span> [<span class="dv">50</span>, study.best_trial.number, study.best_trial.value, time_bayesian]</span>
<span id="cb22-11"><a href="#cb22-11"></a>results_bayesian <span class="op">=</span> pd.DataFrame([values_bayesian], columns <span class="op">=</span> columns)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[I 2023-05-24 03:39:05,603] A new study created in memory with name: no-name-fc37470e-3f6d-4b2a-ba76-90827f032e79
/usr/local/lib/python3.10/dist-packages/optuna/progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.
  self._init_valid()</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"585beda71d714aac87605705d7f9ae2b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2023-05-24 03:39:10,555] Trial 0 finished with value: 0.90868787002616 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.90868787002616.
[I 2023-05-24 03:39:13,367] Trial 1 finished with value: 0.9220570012391572 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 1 with value: 0.9220570012391572.
[I 2023-05-24 03:39:14,553] Trial 2 finished with value: 0.9205782734407271 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9220570012391572.
[I 2023-05-24 03:39:16,294] Trial 3 finished with value: 0.9257662123089634 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:17,825] Trial 4 finished with value: 0.9161145532149249 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:19,972] Trial 5 finished with value: 0.8938372573316811 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:21,584] Trial 6 finished with value: 0.9057221533801461 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:24,523] Trial 7 finished with value: 0.909436871816054 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:27,335] Trial 8 finished with value: 0.9101831199228968 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:29,828] Trial 9 finished with value: 0.9250227178851714 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 3 with value: 0.9257662123089634.
[I 2023-05-24 03:39:31,891] Trial 10 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:33,954] Trial 11 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:36,098] Trial 12 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:40,490] Trial 13 finished with value: 0.912405342145119 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:42,994] Trial 14 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:44,695] Trial 15 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:47,372] Trial 16 finished with value: 0.912405342145119 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:49,691] Trial 17 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:52,292] Trial 18 finished with value: 0.9146385790995456 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:54,780] Trial 19 finished with value: 0.9235439900867408 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:56,426] Trial 20 finished with value: 0.9124136031942722 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:58,119] Trial 21 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:39:59,827] Trial 22 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:01,533] Trial 23 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:03,474] Trial 24 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:05,210] Trial 25 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:09,968] Trial 26 finished with value: 0.9235467437697921 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:11,895] Trial 27 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:14,346] Trial 28 finished with value: 0.9257662123089634 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:15,609] Trial 29 finished with value: 0.9287401900041307 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:17,691] Trial 30 finished with value: 0.9124136031942722 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:20,106] Trial 31 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:21,825] Trial 32 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:24,146] Trial 33 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:25,892] Trial 34 finished with value: 0.9287512047363349 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:27,630] Trial 35 finished with value: 0.9220570012391572 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 10 with value: 0.9287512047363349.
[I 2023-05-24 03:40:28,882] Trial 36 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9309651659094038.
[I 2023-05-24 03:40:30,523] Trial 37 finished with value: 0.9161145532149249 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9309651659094038.
[I 2023-05-24 03:40:32,396] Trial 38 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9309651659094038.
[I 2023-05-24 03:40:33,900] Trial 39 finished with value: 0.9309651659094038 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9309651659094038.
[I 2023-05-24 03:40:35,399] Trial 40 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:36,926] Trial 41 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:38,393] Trial 42 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:39,915] Trial 43 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:41,399] Trial 44 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:42,900] Trial 45 finished with value: 0.9331956491807792 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:44,694] Trial 46 finished with value: 0.9057221533801461 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 40 with value: 0.9331956491807792.
[I 2023-05-24 03:40:46,780] Trial 47 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 47 with value: 0.9346853917114141.
[I 2023-05-24 03:40:48,298] Trial 48 finished with value: 0.9346853917114141 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 47 with value: 0.9346853917114141.
[I 2023-05-24 03:40:49,700] Trial 49 finished with value: 0.922048740190004 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 47 with value: 0.9346853917114141.</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:7,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899654724,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="8f3b7e8d-ac49-4ed3-c6c0-c2f40c853a6d">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>study.best_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>{'n_estimators': 100,
 'criterion': 'entropy',
 'min_samples_split': 2,
 'max_depth': 7,
 'max_features': 'sqrt'}</code></pre>
</div>
</div>
<p>We summarized the results below:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:7,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684899654725,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="038d01d2-d47f-48de-825a-216d61ec3eb3">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># store all results in a single data frame</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>df <span class="op">=</span> results_grid.append(results_random).append(results_bayesian)</span>
<span id="cb27-3"><a href="#cb27-3"></a>df.index <span class="op">=</span> [<span class="st">'Grid Search'</span>, <span class="st">'Random Search'</span>, <span class="st">'Bayesian Optimization'</span>]</span>
<span id="cb27-4"><a href="#cb27-4"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  df = results_grid.append(results_random).append(results_bayesian)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="74">

  <div id="df-333c4ca3-0add-4062-8ceb-cdbb1c82f250">
    <div class="colab-df-container">
      <div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Number of iterations</th>
<th data-quarto-table-cell-role="th">Iteration Number of Optimal Hyperparamters</th>
<th data-quarto-table-cell-role="th">Score</th>
<th data-quarto-table-cell-role="th">Time Elapsed (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Grid Search</td>
<td>108</td>
<td>106</td>
<td>0.935426</td>
<td>236.524639</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Random Search</td>
<td>50</td>
<td>12</td>
<td>0.930960</td>
<td>99.094361</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Bayesian Optimization</td>
<td>50</td>
<td>47</td>
<td>0.934685</td>
<td>104.101121</td>
</tr>
</tbody>
</table>


</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-333c4ca3-0add-4062-8ceb-cdbb1c82f250')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-333c4ca3-0add-4062-8ceb-cdbb1c82f250 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-333c4ca3-0add-4062-8ceb-cdbb1c82f250');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<p>The grid search registered the highest score. However, the method required more trials and only managed to obtain the optimal hyperparameters at the 106th iteration. Also, its run time far exceeded that of the random search and the Bayesian optimization methods. The random search method required only 50 trials and needed only 12 iterations to find the best hyperparameter set. It also took the least amount of time to execute. However, the random search method registered the lowest score out of the 3 methods. The Bayesian optimization also performed 50 trials but was able to achieve the highest score after only 47 iterations, far less than the grid search. Although it executed the same number of trials as the random search, it has a longer run time since it is an informed search method.</p>
</section>
</section>
<section id="hyperparamter-tuning-using-kerastuner" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="hyperparamter-tuning-using-kerastuner"><span class="header-section-number">13.3</span> Hyperparamter tuning using <code>KerasTuner</code></h2>
<p>Training the weights of a model is relatively easy: you compute a loss function on a mini-batch of data and then use backpropagation to move the weights in the right direction. Updating hyperparameters, on the other hand, presents unique challenges. Consider these points:</p>
<ul>
<li>The hyperparameter space is typically made up of discrete decisions and thus isn’t continuous or differentiable. Hence, you typically can’t do gradient descent in hyperparameter space. Instead, you must rely on gradient-free optimization techniques, which naturally are far less efficient than gradient descent.</li>
<li>Computing the feedback signal of this optimization process (does this set of hyperparameters lead to a high-performing model on this task?) can be extremely expensive: it requires creating and training a new model from scratch on your dataset.</li>
<li>The feedback signal may be noisy: if a training run performs 0.2% better, is that because of a better model configuration, or because you got lucky with the initial weight values?</li>
</ul>
<p>Thankfully, there’s a tool that makes hyperparameter tuning simpler: <code>KerasTuner</code>. Let’s check it out.</p>
<p><code>KerasTuner</code> lets you replace hard-coded hyperparameter values, such as <code>units=32</code>, with a range of possible choices, such as <code>Int(name="units", min_value=16, max_value=64, step=16)</code>. This set of choices in a given model is called the search space of the hyperparameter tuning process.</p>
<p>To specify a search space, define a model-building function. It takes an hp argument, from which you can sample hyperparameter ranges, and it returns a compiled Keras model.</p>
<section id="tune-model-architecture" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="tune-model-architecture"><span class="header-section-number">13.3.1</span> Tune model architecture</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb29-2"><a href="#cb29-2"></a>    <span class="co"># Sample hyperparameter values from the hp object. After sampling, these values (such as the "units" which is number of nuerons </span></span>
<span id="cb29-3"><a href="#cb29-3"></a>    <span class="co"># variable here) are just regular Python constants.</span></span>
<span id="cb29-4"><a href="#cb29-4"></a>    model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb29-5"><a href="#cb29-5"></a>    model.add(tf.keras.layers.Flatten())</span>
<span id="cb29-6"><a href="#cb29-6"></a>    <span class="co"># Tune the number of layers.</span></span>
<span id="cb29-7"><a href="#cb29-7"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(hp.Int(<span class="st">"num_layers"</span>, <span class="dv">1</span>, <span class="dv">3</span>)):</span>
<span id="cb29-8"><a href="#cb29-8"></a>        model.add(        </span>
<span id="cb29-9"><a href="#cb29-9"></a>            tf.keras.layers.Dense(</span>
<span id="cb29-10"><a href="#cb29-10"></a>            <span class="co"># Tune number of units.</span></span>
<span id="cb29-11"><a href="#cb29-11"></a>            units<span class="op">=</span>hp.Int(<span class="st">"units"</span>, min_value<span class="op">=</span><span class="dv">16</span>, max_value<span class="op">=</span><span class="dv">64</span>, step<span class="op">=</span><span class="dv">16</span>),</span>
<span id="cb29-12"><a href="#cb29-12"></a>            <span class="co"># Tune the activation function to use.</span></span>
<span id="cb29-13"><a href="#cb29-13"></a>            activation<span class="op">=</span>hp.Choice(<span class="st">"activation"</span>, [<span class="st">"relu"</span>, <span class="st">"tanh"</span>]),</span>
<span id="cb29-14"><a href="#cb29-14"></a>            )</span>
<span id="cb29-15"><a href="#cb29-15"></a>        )</span>
<span id="cb29-16"><a href="#cb29-16"></a>    <span class="co"># Tune whether to use dropout.</span></span>
<span id="cb29-17"><a href="#cb29-17"></a>    <span class="cf">if</span> hp.Boolean(<span class="st">"dropout"</span>):</span>
<span id="cb29-18"><a href="#cb29-18"></a>        model.add(tf.keras.layers.Dropout(rate<span class="op">=</span><span class="fl">0.25</span>))</span>
<span id="cb29-19"><a href="#cb29-19"></a>    model.add(tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>))</span>
<span id="cb29-20"><a href="#cb29-20"></a>    <span class="co"># Define the optimizer learning rate as a hyperparameter.</span></span>
<span id="cb29-21"><a href="#cb29-21"></a>    learning_rate <span class="op">=</span> hp.Float(<span class="st">"lr"</span>, min_value<span class="op">=</span><span class="fl">1e-4</span>, max_value<span class="op">=</span><span class="fl">1e-2</span>, sampling<span class="op">=</span><span class="st">"log"</span>)</span>
<span id="cb29-22"><a href="#cb29-22"></a>    optimizer <span class="op">=</span> hp.Choice(name<span class="op">=</span><span class="st">"optimizer"</span>, values<span class="op">=</span>[<span class="st">"rmsprop"</span>, <span class="st">"adam"</span>])</span>
<span id="cb29-23"><a href="#cb29-23"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb29-24"><a href="#cb29-24"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb29-25"><a href="#cb29-25"></a>        loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb29-26"><a href="#cb29-26"></a>        metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb29-27"><a href="#cb29-27"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If you want to adopt a more modular and configurable approach to model-building, you can also subclass the <code>HyperModel</code> class and define a <code>build()</code> method, as follows.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="kw">class</span> SimpleMLP(kt.HyperModel):</span>
<span id="cb30-2"><a href="#cb30-2"></a>    <span class="co"># Thanks to the object-oriented approach, we can configure model constants</span></span>
<span id="cb30-3"><a href="#cb30-3"></a>    <span class="co"># as constructor arguments (instead of hardcoding them in the model-building</span></span>
<span id="cb30-4"><a href="#cb30-4"></a>    <span class="co"># function).</span></span>
<span id="cb30-5"><a href="#cb30-5"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb30-6"><a href="#cb30-6"></a>        <span class="va">self</span>.num_classes <span class="op">=</span> num_classes</span>
<span id="cb30-7"><a href="#cb30-7"></a>    <span class="co"># The build() method is identical to our prior build_model() standalone function.</span></span>
<span id="cb30-8"><a href="#cb30-8"></a>    <span class="kw">def</span> build(<span class="va">self</span>, hp):</span>
<span id="cb30-9"><a href="#cb30-9"></a>      <span class="co"># Sample hyperparameter values from the hp object. After sampling, these values (such as the "units" which is number of nuerons </span></span>
<span id="cb30-10"><a href="#cb30-10"></a>      <span class="co"># variable here) are just regular Python constants.</span></span>
<span id="cb30-11"><a href="#cb30-11"></a>        model <span class="op">=</span> tf.keras.keras.Sequential()</span>
<span id="cb30-12"><a href="#cb30-12"></a>        model.add(tf.keras.layers.Flatten())</span>
<span id="cb30-13"><a href="#cb30-13"></a>        <span class="co"># Tune the number of layers.</span></span>
<span id="cb30-14"><a href="#cb30-14"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(hp.Int(<span class="st">"num_layers"</span>, <span class="dv">1</span>, <span class="dv">3</span>)):</span>
<span id="cb30-15"><a href="#cb30-15"></a>            model.add(        </span>
<span id="cb30-16"><a href="#cb30-16"></a>              tf.keras.layers.Dense(</span>
<span id="cb30-17"><a href="#cb30-17"></a>              <span class="co"># Tune number of units.</span></span>
<span id="cb30-18"><a href="#cb30-18"></a>              units<span class="op">=</span>hp.Int(<span class="st">"units"</span>, min_value<span class="op">=</span><span class="dv">16</span>, max_value<span class="op">=</span><span class="dv">64</span>, step<span class="op">=</span><span class="dv">16</span>),</span>
<span id="cb30-19"><a href="#cb30-19"></a>              <span class="co"># Tune the activation function to use.</span></span>
<span id="cb30-20"><a href="#cb30-20"></a>              activation<span class="op">=</span>hp.Choice(<span class="st">"activation"</span>, [<span class="st">"relu"</span>, <span class="st">"tanh"</span>]),</span>
<span id="cb30-21"><a href="#cb30-21"></a>              )</span>
<span id="cb30-22"><a href="#cb30-22"></a>            )</span>
<span id="cb30-23"><a href="#cb30-23"></a>        <span class="co"># Tune whether to use dropout.</span></span>
<span id="cb30-24"><a href="#cb30-24"></a>        <span class="cf">if</span> hp.Boolean(<span class="st">"dropout"</span>):</span>
<span id="cb30-25"><a href="#cb30-25"></a>            model.add(tf.keras.layers.Dropout(rate<span class="op">=</span><span class="fl">0.25</span>))</span>
<span id="cb30-26"><a href="#cb30-26"></a>        model.add(tf.keras.layers.Dense(<span class="va">self</span>.num_classes, activation<span class="op">=</span><span class="st">"softmax"</span>))</span>
<span id="cb30-27"><a href="#cb30-27"></a>        <span class="co"># Define the optimizer learning rate as a hyperparameter.</span></span>
<span id="cb30-28"><a href="#cb30-28"></a>        learning_rate <span class="op">=</span> hp.Float(<span class="st">"lr"</span>, min_value<span class="op">=</span><span class="fl">1e-4</span>, max_value<span class="op">=</span><span class="fl">1e-2</span>, sampling<span class="op">=</span><span class="st">"log"</span>)</span>
<span id="cb30-29"><a href="#cb30-29"></a>        optimizer <span class="op">=</span> hp.Choice(name<span class="op">=</span><span class="st">"optimizer"</span>, values<span class="op">=</span>[<span class="st">"rmsprop"</span>, <span class="st">"adam"</span>])</span>
<span id="cb30-30"><a href="#cb30-30"></a>        model.<span class="bu">compile</span>(</span>
<span id="cb30-31"><a href="#cb30-31"></a>            optimizer<span class="op">=</span>optimizer,</span>
<span id="cb30-32"><a href="#cb30-32"></a>            loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb30-33"><a href="#cb30-33"></a>            metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb30-34"><a href="#cb30-34"></a>        <span class="cf">return</span> model</span>
<span id="cb30-35"><a href="#cb30-35"></a></span>
<span id="cb30-36"><a href="#cb30-36"></a>hypermodel <span class="op">=</span> SimpleMLP(num_classes<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next step is to define a “tuner.” Schematically, you can think of a tuner as a for loop that will repeatedly  1. Pick a set of hyperparameter values 2. Call the model-building function with these values to create a model 3. Train the model and record its metrics</p>
<p>KerasTuner has several built-in tuners available— <strong>RandomSearch, BayesianOptimization, and Hyperband</strong>. Let’s try BayesianOptimization, a tuner that attempts to make smart predictions for which new hyperparameter values are likely to perform best given the outcomes of previous choices:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>tuner <span class="op">=</span> kt.BayesianOptimization(</span>
<span id="cb31-2"><a href="#cb31-2"></a>    build_model,</span>
<span id="cb31-3"><a href="#cb31-3"></a>    objective<span class="op">=</span><span class="st">"val_accuracy"</span>,</span>
<span id="cb31-4"><a href="#cb31-4"></a>    max_trials<span class="op">=</span><span class="dv">3</span>, <span class="co"># Increase this if you would like to do more search</span></span>
<span id="cb31-5"><a href="#cb31-5"></a>    executions_per_trial<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb31-6"><a href="#cb31-6"></a>    directory<span class="op">=</span><span class="st">"mnist_kt_test"</span>,</span>
<span id="cb31-7"><a href="#cb31-7"></a>    overwrite<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb31-8"><a href="#cb31-8"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><p><code>objective</code>: Specify the metric that the tuner will seek to optimize. Always specify validation metrics, since the goal of the search process is to find models that generalize!</p></li>
<li><p><code>max_trials</code>: Maximum number of different model configurations (“trials”) to try before ending the search.</p></li>
<li><p><code>executions_per_trial</code>: To reduce metrics variance, you can train the same model multiple times and average the results. <code>executions_per_trial</code> is how many training rounds(executions) to run for each model configuration (trial).</p></li>
<li><p><code>directory</code>: Where to store search logs</p></li>
<li><p><code>overwrite</code>: Whether to overwrite data in directory to start a new search. Set this to <code>True</code> if you’ve modified the model-building function, or to <code>False</code> to resume a previously started search with the same model-building function.</p></li>
</ul>
<p>You can display an overview of the search space via <code>search_space_summary()</code>:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:255,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684900188664,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="5dfe0089-d92f-4d09-8091-0e8da90946e8">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a>tuner.search_space_summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Search space summary
Default search space size: 6
num_layers (Int)
{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}
units (Int)
{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}
activation (Choice)
{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}
dropout (Boolean)
{'default': False, 'conditions': []}
lr (Float)
{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}
optimizer (Choice)
{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}</code></pre>
</div>
</div>
<p>Finally, let’s launch the search. <strong>Don’t forget to pass validation data, and make sure not to use your test set as validation data</strong> — otherwise you’d quickly start overfitting to your test data, and you wouldn’t be able to trust your test metrics anymore:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:465859,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684900671386,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="18b1f2d8-673f-4ae2-d283-4dc95e0870cb">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> tf.keras.datasets.mnist.load_data()</span>
<span id="cb34-2"><a href="#cb34-2"></a>x_train <span class="op">=</span> x_train.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>)).astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb34-3"><a href="#cb34-3"></a>x_test <span class="op">=</span> x_test.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>)).astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb34-4"><a href="#cb34-4"></a><span class="co"># Reserve these for later.</span></span>
<span id="cb34-5"><a href="#cb34-5"></a>x_train_full <span class="op">=</span> x_train[:]</span>
<span id="cb34-6"><a href="#cb34-6"></a>y_train_full <span class="op">=</span> y_train[:]</span>
<span id="cb34-7"><a href="#cb34-7"></a>num_val_samples <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb34-8"><a href="#cb34-8"></a><span class="co"># Set these aside as a validation set.</span></span>
<span id="cb34-9"><a href="#cb34-9"></a>x_train, x_val <span class="op">=</span> x_train[:<span class="op">-</span>num_val_samples], x_train[<span class="op">-</span>num_val_samples:]</span>
<span id="cb34-10"><a href="#cb34-10"></a>y_train, y_val <span class="op">=</span> y_train[:<span class="op">-</span>num_val_samples], y_train[<span class="op">-</span>num_val_samples:]</span>
<span id="cb34-11"><a href="#cb34-11"></a></span>
<span id="cb34-12"><a href="#cb34-12"></a><span class="co"># This takes the same arguments as fit() (it simply passes them</span></span>
<span id="cb34-13"><a href="#cb34-13"></a><span class="co"># down to fit() for each new model).</span></span>
<span id="cb34-14"><a href="#cb34-14"></a>callbacks <span class="op">=</span> [</span>
<span id="cb34-15"><a href="#cb34-15"></a>    tf.keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">"val_loss"</span>, patience<span class="op">=</span><span class="dv">5</span>),</span>
<span id="cb34-16"><a href="#cb34-16"></a>]</span>
<span id="cb34-17"><a href="#cb34-17"></a><span class="co"># Use a large number of epochs (you don’t know in advance how</span></span>
<span id="cb34-18"><a href="#cb34-18"></a><span class="co"># many epochs each model will need), and use an EarlyStopping</span></span>
<span id="cb34-19"><a href="#cb34-19"></a><span class="co"># callback to stop training when you start overfitting.</span></span>
<span id="cb34-20"><a href="#cb34-20"></a>tuner.search(</span>
<span id="cb34-21"><a href="#cb34-21"></a>    x_train, y_train,</span>
<span id="cb34-22"><a href="#cb34-22"></a>    batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb34-23"><a href="#cb34-23"></a>    epochs<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb34-24"><a href="#cb34-24"></a>    validation_data<span class="op">=</span>(x_val, y_val),</span>
<span id="cb34-25"><a href="#cb34-25"></a>    callbacks<span class="op">=</span>callbacks,</span>
<span id="cb34-26"><a href="#cb34-26"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb34-27"><a href="#cb34-27"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 3 Complete [00h 03m 17s]
val_accuracy: 0.9639500081539154

Best val_accuracy So Far: 0.9647500216960907
Total elapsed time: 00h 07m 45s</code></pre>
</div>
</div>
<p>The preceding example will run in just a few minutes, since we’re only looking at a few possible choices and we’re training on MNIST. However, with a typical search space and dataset, you’ll often find yourself letting the hyperparameter search run overnight or even over several days. <strong>If your search process crashes, you can always restart it — just specify <code>overwrite=False</code> in the tuner so that it can resume from the trial logs stored on disk.</strong></p>
<p>Once the search is complete, you can query the best hyperparameter configurations, which you can use to create high-performing models that you can then retrain.</p>
<section id="querying-the-best-hyperparameter-configurations" class="level4" data-number="13.3.1.1">
<h4 data-number="13.3.1.1" class="anchored" data-anchor-id="querying-the-best-hyperparameter-configurations"><span class="header-section-number">13.3.1.1</span> Querying the best hyperparameter configurations</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a>top_n <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb36-2"><a href="#cb36-2"></a>best_hps <span class="op">=</span> tuner.get_best_hyperparameters(top_n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Usually, when retraining these models, <strong>you may want to include the validation data as part of the training data, since you won’t be making any further hyperparameter changes, and thus you will no longer be evaluating performance on the validation data.</strong> In our example, we’d train these final models on the totality of the original MNIST training data, without reserving a validation set.</p>
<p>Before we can train on the full training data, though, there’s one last parameter we need to settle: the optimal number of epochs to train for. Typically, you’ll want to train the new models for longer than you did during the search: using an aggressive patience value in the <code>EarlyStopping</code> callback saves time during the search, but it may lead to under-fit models. Just use the validation set to find the best epoch:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="kw">def</span> get_best_epoch(hp):</span>
<span id="cb37-2"><a href="#cb37-2"></a>    model <span class="op">=</span> build_model(hp)</span>
<span id="cb37-3"><a href="#cb37-3"></a>    callbacks<span class="op">=</span>[</span>
<span id="cb37-4"><a href="#cb37-4"></a>        tf.keras.callbacks.EarlyStopping(</span>
<span id="cb37-5"><a href="#cb37-5"></a>            monitor<span class="op">=</span><span class="st">"val_loss"</span>, mode<span class="op">=</span><span class="st">"min"</span>, patience<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb37-6"><a href="#cb37-6"></a>    ]</span>
<span id="cb37-7"><a href="#cb37-7"></a>    history <span class="op">=</span> model.fit(</span>
<span id="cb37-8"><a href="#cb37-8"></a>        x_train, y_train,</span>
<span id="cb37-9"><a href="#cb37-9"></a>        validation_data<span class="op">=</span>(x_val, y_val),</span>
<span id="cb37-10"><a href="#cb37-10"></a>        epochs<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb37-11"><a href="#cb37-11"></a>        batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb37-12"><a href="#cb37-12"></a>        callbacks<span class="op">=</span>callbacks)</span>
<span id="cb37-13"><a href="#cb37-13"></a>    val_loss_per_epoch <span class="op">=</span> history.history[<span class="st">"val_loss"</span>]</span>
<span id="cb37-14"><a href="#cb37-14"></a>    best_epoch <span class="op">=</span> val_loss_per_epoch.index(<span class="bu">min</span>(val_loss_per_epoch)) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb37-15"><a href="#cb37-15"></a>    <span class="bu">print</span>(<span class="ss">f"Best epoch: </span><span class="sc">{</span>best_epoch<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-16"><a href="#cb37-16"></a>    <span class="cf">return</span> best_epoch, model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, train on the full dataset for just a bit longer than this epoch count, since you’re training on more data; 20% more in this case:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:474824,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684902326882,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="77c72fc9-84b0-452d-f045-cfbe9d531ca8">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="kw">def</span> get_best_trained_model(hp):</span>
<span id="cb38-2"><a href="#cb38-2"></a>    best_epoch, model <span class="op">=</span> get_best_epoch(hp)</span>
<span id="cb38-3"><a href="#cb38-3"></a>    model.fit(</span>
<span id="cb38-4"><a href="#cb38-4"></a>        x_train_full, y_train_full,</span>
<span id="cb38-5"><a href="#cb38-5"></a>        batch_size<span class="op">=</span><span class="dv">128</span>, epochs<span class="op">=</span><span class="bu">int</span>(best_epoch <span class="op">*</span> <span class="fl">1.2</span>))</span>
<span id="cb38-6"><a href="#cb38-6"></a>    <span class="cf">return</span> model</span>
<span id="cb38-7"><a href="#cb38-7"></a></span>
<span id="cb38-8"><a href="#cb38-8"></a>best_models <span class="op">=</span> []</span>
<span id="cb38-9"><a href="#cb38-9"></a><span class="cf">for</span> hp <span class="kw">in</span> best_hps:</span>
<span id="cb38-10"><a href="#cb38-10"></a>    model <span class="op">=</span> get_best_trained_model(hp)</span>
<span id="cb38-11"><a href="#cb38-11"></a>    model.evaluate(x_test, y_test)</span>
<span id="cb38-12"><a href="#cb38-12"></a>    best_models.append(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/100
391/391 [==============================] - 2s 4ms/step - loss: 0.6390 - accuracy: 0.8321 - val_loss: 0.3086 - val_accuracy: 0.9149
Epoch 2/100
391/391 [==============================] - 1s 4ms/step - loss: 0.3483 - accuracy: 0.9005 - val_loss: 0.2482 - val_accuracy: 0.9301
Epoch 3/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.9109 - val_loss: 0.2270 - val_accuracy: 0.9338
Epoch 4/100
391/391 [==============================] - 2s 4ms/step - loss: 0.2823 - accuracy: 0.9172 - val_loss: 0.2175 - val_accuracy: 0.9370
Epoch 5/100
391/391 [==============================] - 2s 5ms/step - loss: 0.2644 - accuracy: 0.9217 - val_loss: 0.1991 - val_accuracy: 0.9419
Epoch 6/100
391/391 [==============================] - 1s 4ms/step - loss: 0.2518 - accuracy: 0.9260 - val_loss: 0.1919 - val_accuracy: 0.9449
Epoch 7/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2422 - accuracy: 0.9277 - val_loss: 0.1835 - val_accuracy: 0.9472
Epoch 8/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2323 - accuracy: 0.9309 - val_loss: 0.1832 - val_accuracy: 0.9470
Epoch 9/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2272 - accuracy: 0.9331 - val_loss: 0.1756 - val_accuracy: 0.9493
Epoch 10/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.9343 - val_loss: 0.1736 - val_accuracy: 0.9484
Epoch 11/100
391/391 [==============================] - 1s 4ms/step - loss: 0.2174 - accuracy: 0.9346 - val_loss: 0.1692 - val_accuracy: 0.9494
Epoch 12/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2089 - accuracy: 0.9369 - val_loss: 0.1663 - val_accuracy: 0.9506
Epoch 13/100
391/391 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9383 - val_loss: 0.1634 - val_accuracy: 0.9516
Epoch 14/100
391/391 [==============================] - 2s 5ms/step - loss: 0.2036 - accuracy: 0.9385 - val_loss: 0.1627 - val_accuracy: 0.9515
Epoch 15/100
391/391 [==============================] - 2s 5ms/step - loss: 0.1955 - accuracy: 0.9411 - val_loss: 0.1595 - val_accuracy: 0.9525
Epoch 16/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9392 - val_loss: 0.1555 - val_accuracy: 0.9550
Epoch 17/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1896 - accuracy: 0.9429 - val_loss: 0.1528 - val_accuracy: 0.9551
Epoch 18/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9416 - val_loss: 0.1522 - val_accuracy: 0.9541
Epoch 19/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9426 - val_loss: 0.1499 - val_accuracy: 0.9544
Epoch 20/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1829 - accuracy: 0.9431 - val_loss: 0.1477 - val_accuracy: 0.9560
Epoch 21/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9438 - val_loss: 0.1475 - val_accuracy: 0.9558
Epoch 22/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1795 - accuracy: 0.9454 - val_loss: 0.1484 - val_accuracy: 0.9567
Epoch 23/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1794 - accuracy: 0.9450 - val_loss: 0.1475 - val_accuracy: 0.9557
Epoch 24/100
391/391 [==============================] - 2s 5ms/step - loss: 0.1745 - accuracy: 0.9454 - val_loss: 0.1478 - val_accuracy: 0.9561
Epoch 25/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9456 - val_loss: 0.1452 - val_accuracy: 0.9563
Epoch 26/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1700 - accuracy: 0.9470 - val_loss: 0.1445 - val_accuracy: 0.9567
Epoch 27/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1710 - accuracy: 0.9459 - val_loss: 0.1441 - val_accuracy: 0.9569
Epoch 28/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9485 - val_loss: 0.1442 - val_accuracy: 0.9562
Epoch 29/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1698 - accuracy: 0.9472 - val_loss: 0.1454 - val_accuracy: 0.9564
Epoch 30/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9495 - val_loss: 0.1453 - val_accuracy: 0.9568
Epoch 31/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9491 - val_loss: 0.1440 - val_accuracy: 0.9575
Epoch 32/100
391/391 [==============================] - 2s 5ms/step - loss: 0.1615 - accuracy: 0.9498 - val_loss: 0.1406 - val_accuracy: 0.9583
Epoch 33/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1592 - accuracy: 0.9505 - val_loss: 0.1425 - val_accuracy: 0.9569
Epoch 34/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9510 - val_loss: 0.1415 - val_accuracy: 0.9575
Epoch 35/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1589 - accuracy: 0.9494 - val_loss: 0.1400 - val_accuracy: 0.9583
Epoch 36/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1552 - accuracy: 0.9510 - val_loss: 0.1384 - val_accuracy: 0.9597
Epoch 37/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1565 - accuracy: 0.9503 - val_loss: 0.1397 - val_accuracy: 0.9597
Epoch 38/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.9502 - val_loss: 0.1386 - val_accuracy: 0.9584
Epoch 39/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9521 - val_loss: 0.1395 - val_accuracy: 0.9586
Epoch 40/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9507 - val_loss: 0.1364 - val_accuracy: 0.9592
Epoch 41/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1529 - accuracy: 0.9516 - val_loss: 0.1383 - val_accuracy: 0.9581
Epoch 42/100
391/391 [==============================] - 2s 5ms/step - loss: 0.1498 - accuracy: 0.9524 - val_loss: 0.1407 - val_accuracy: 0.9592
Epoch 43/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9531 - val_loss: 0.1365 - val_accuracy: 0.9588
Epoch 44/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9532 - val_loss: 0.1368 - val_accuracy: 0.9604
Epoch 45/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1476 - accuracy: 0.9534 - val_loss: 0.1397 - val_accuracy: 0.9591
Epoch 46/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9529 - val_loss: 0.1375 - val_accuracy: 0.9605
Epoch 47/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.1376 - val_accuracy: 0.9594
Epoch 48/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1467 - accuracy: 0.9536 - val_loss: 0.1385 - val_accuracy: 0.9582
Epoch 49/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9531 - val_loss: 0.1374 - val_accuracy: 0.9594
Epoch 50/100
391/391 [==============================] - 2s 5ms/step - loss: 0.1442 - accuracy: 0.9544 - val_loss: 0.1375 - val_accuracy: 0.9590
Best epoch: 40
Epoch 1/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9517
Epoch 2/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1515 - accuracy: 0.9519
Epoch 3/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1514 - accuracy: 0.9518
Epoch 4/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1493 - accuracy: 0.9534
Epoch 5/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9533
Epoch 6/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1473 - accuracy: 0.9533
Epoch 7/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1482 - accuracy: 0.9540
Epoch 8/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9540
Epoch 9/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1439 - accuracy: 0.9549
Epoch 10/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9542
Epoch 11/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1441 - accuracy: 0.9545
Epoch 12/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1451 - accuracy: 0.9542
Epoch 13/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1434 - accuracy: 0.9551
Epoch 14/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9554
Epoch 15/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1445 - accuracy: 0.9537
Epoch 16/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9547
Epoch 17/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 0.9544
Epoch 18/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1382 - accuracy: 0.9556
Epoch 19/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1403 - accuracy: 0.9557
Epoch 20/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1404 - accuracy: 0.9551
Epoch 21/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1373 - accuracy: 0.9558
Epoch 22/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1385 - accuracy: 0.9556
Epoch 23/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9557
Epoch 24/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9561
Epoch 25/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9559
Epoch 26/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9557
Epoch 27/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9569
Epoch 28/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9574
Epoch 29/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9561
Epoch 30/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1334 - accuracy: 0.9574
Epoch 31/48
469/469 [==============================] - 2s 3ms/step - loss: 0.1348 - accuracy: 0.9562
Epoch 32/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1327 - accuracy: 0.9569
Epoch 33/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9575
Epoch 34/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1331 - accuracy: 0.9576
Epoch 35/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1321 - accuracy: 0.9571
Epoch 36/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9564
Epoch 37/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1319 - accuracy: 0.9568
Epoch 38/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1330 - accuracy: 0.9578
Epoch 39/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9582
Epoch 40/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1278 - accuracy: 0.9589
Epoch 41/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1317 - accuracy: 0.9574
Epoch 42/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1303 - accuracy: 0.9576
Epoch 43/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1314 - accuracy: 0.9579
Epoch 44/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9586
Epoch 45/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1255 - accuracy: 0.9601
Epoch 46/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1299 - accuracy: 0.9586
Epoch 47/48
469/469 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9591
Epoch 48/48
469/469 [==============================] - 2s 4ms/step - loss: 0.1266 - accuracy: 0.9583
313/313 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9569
Epoch 1/100
391/391 [==============================] - 2s 4ms/step - loss: 0.5987 - accuracy: 0.8426 - val_loss: 0.2958 - val_accuracy: 0.9201
Epoch 2/100
391/391 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.9019 - val_loss: 0.2486 - val_accuracy: 0.9301
Epoch 3/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.9136 - val_loss: 0.2239 - val_accuracy: 0.9345
Epoch 4/100
391/391 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9193 - val_loss: 0.2085 - val_accuracy: 0.9403
Epoch 5/100
391/391 [==============================] - 2s 4ms/step - loss: 0.2616 - accuracy: 0.9235 - val_loss: 0.1980 - val_accuracy: 0.9445
Epoch 6/100
391/391 [==============================] - 2s 4ms/step - loss: 0.2541 - accuracy: 0.9255 - val_loss: 0.1880 - val_accuracy: 0.9456
Epoch 7/100
391/391 [==============================] - 2s 5ms/step - loss: 0.2427 - accuracy: 0.9283 - val_loss: 0.1822 - val_accuracy: 0.9481
Epoch 8/100
391/391 [==============================] - 2s 5ms/step - loss: 0.2367 - accuracy: 0.9301 - val_loss: 0.1794 - val_accuracy: 0.9491
Epoch 9/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2301 - accuracy: 0.9317 - val_loss: 0.1697 - val_accuracy: 0.9511
Epoch 10/100
391/391 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9317 - val_loss: 0.1670 - val_accuracy: 0.9507
Epoch 11/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9353 - val_loss: 0.1637 - val_accuracy: 0.9514
Epoch 12/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2153 - accuracy: 0.9359 - val_loss: 0.1613 - val_accuracy: 0.9541
Epoch 13/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2090 - accuracy: 0.9374 - val_loss: 0.1577 - val_accuracy: 0.9539
Epoch 14/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9368 - val_loss: 0.1544 - val_accuracy: 0.9557
Epoch 15/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2035 - accuracy: 0.9385 - val_loss: 0.1533 - val_accuracy: 0.9556
Epoch 16/100
391/391 [==============================] - 1s 3ms/step - loss: 0.2023 - accuracy: 0.9396 - val_loss: 0.1479 - val_accuracy: 0.9571
Epoch 17/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1954 - accuracy: 0.9416 - val_loss: 0.1474 - val_accuracy: 0.9575
Epoch 18/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1979 - accuracy: 0.9399 - val_loss: 0.1500 - val_accuracy: 0.9555
Epoch 19/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9421 - val_loss: 0.1497 - val_accuracy: 0.9562
Epoch 20/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9413 - val_loss: 0.1442 - val_accuracy: 0.9578
Epoch 21/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1882 - accuracy: 0.9425 - val_loss: 0.1439 - val_accuracy: 0.9586
Epoch 22/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1896 - accuracy: 0.9416 - val_loss: 0.1458 - val_accuracy: 0.9575
Epoch 23/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1858 - accuracy: 0.9432 - val_loss: 0.1410 - val_accuracy: 0.9580
Epoch 24/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.9439 - val_loss: 0.1396 - val_accuracy: 0.9591
Epoch 25/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1807 - accuracy: 0.9447 - val_loss: 0.1391 - val_accuracy: 0.9592
Epoch 26/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1814 - accuracy: 0.9444 - val_loss: 0.1402 - val_accuracy: 0.9594
Epoch 27/100
391/391 [==============================] - 2s 5ms/step - loss: 0.1790 - accuracy: 0.9450 - val_loss: 0.1397 - val_accuracy: 0.9596
Epoch 28/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9473 - val_loss: 0.1368 - val_accuracy: 0.9612
Epoch 29/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9456 - val_loss: 0.1369 - val_accuracy: 0.9605
Epoch 30/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1763 - accuracy: 0.9449 - val_loss: 0.1375 - val_accuracy: 0.9594
Epoch 31/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1748 - accuracy: 0.9462 - val_loss: 0.1392 - val_accuracy: 0.9600
Epoch 32/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1719 - accuracy: 0.9469 - val_loss: 0.1389 - val_accuracy: 0.9593
Epoch 33/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1741 - accuracy: 0.9466 - val_loss: 0.1366 - val_accuracy: 0.9605
Epoch 34/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9462 - val_loss: 0.1338 - val_accuracy: 0.9613
Epoch 35/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1679 - accuracy: 0.9477 - val_loss: 0.1342 - val_accuracy: 0.9601
Epoch 36/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1669 - accuracy: 0.9478 - val_loss: 0.1345 - val_accuracy: 0.9622
Epoch 37/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9483 - val_loss: 0.1349 - val_accuracy: 0.9598
Epoch 38/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9482 - val_loss: 0.1308 - val_accuracy: 0.9617
Epoch 39/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9501 - val_loss: 0.1339 - val_accuracy: 0.9616
Epoch 40/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1637 - accuracy: 0.9498 - val_loss: 0.1336 - val_accuracy: 0.9609
Epoch 41/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1650 - accuracy: 0.9490 - val_loss: 0.1356 - val_accuracy: 0.9610
Epoch 42/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9503 - val_loss: 0.1338 - val_accuracy: 0.9604
Epoch 43/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1604 - accuracy: 0.9508 - val_loss: 0.1325 - val_accuracy: 0.9622
Epoch 44/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9506 - val_loss: 0.1319 - val_accuracy: 0.9622
Epoch 45/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1601 - accuracy: 0.9500 - val_loss: 0.1325 - val_accuracy: 0.9624
Epoch 46/100
391/391 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9512 - val_loss: 0.1326 - val_accuracy: 0.9610
Epoch 47/100
391/391 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9515 - val_loss: 0.1325 - val_accuracy: 0.9610
Epoch 48/100
391/391 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9510 - val_loss: 0.1322 - val_accuracy: 0.9602
Best epoch: 38
Epoch 1/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9503
Epoch 2/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9500
Epoch 3/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9511
Epoch 4/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9499
Epoch 5/45
469/469 [==============================] - 2s 3ms/step - loss: 0.1610 - accuracy: 0.9504
Epoch 6/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1594 - accuracy: 0.9506
Epoch 7/45
469/469 [==============================] - 2s 3ms/step - loss: 0.1578 - accuracy: 0.9513
Epoch 8/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9513
Epoch 9/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9517
Epoch 10/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9523
Epoch 11/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9522
Epoch 12/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1540 - accuracy: 0.9521
Epoch 13/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1540 - accuracy: 0.9527
Epoch 14/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9531
Epoch 15/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1527 - accuracy: 0.9530
Epoch 16/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1519 - accuracy: 0.9528
Epoch 17/45
469/469 [==============================] - 3s 6ms/step - loss: 0.1536 - accuracy: 0.9525
Epoch 18/45
469/469 [==============================] - 3s 5ms/step - loss: 0.1496 - accuracy: 0.9533
Epoch 19/45
469/469 [==============================] - 2s 5ms/step - loss: 0.1519 - accuracy: 0.9526
Epoch 20/45
469/469 [==============================] - 2s 5ms/step - loss: 0.1499 - accuracy: 0.9534
Epoch 21/45
469/469 [==============================] - 3s 7ms/step - loss: 0.1506 - accuracy: 0.9529
Epoch 22/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1488 - accuracy: 0.9528
Epoch 23/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1481 - accuracy: 0.9540
Epoch 24/45
469/469 [==============================] - 2s 5ms/step - loss: 0.1485 - accuracy: 0.9530
Epoch 25/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1489 - accuracy: 0.9541
Epoch 26/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9546
Epoch 27/45
469/469 [==============================] - 2s 3ms/step - loss: 0.1474 - accuracy: 0.9538
Epoch 28/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1477 - accuracy: 0.9546
Epoch 29/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1447 - accuracy: 0.9550
Epoch 30/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9539
Epoch 31/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9546
Epoch 32/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1447 - accuracy: 0.9547
Epoch 33/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1426 - accuracy: 0.9553
Epoch 34/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1454 - accuracy: 0.9538
Epoch 35/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9552
Epoch 36/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1446 - accuracy: 0.9546
Epoch 37/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1420 - accuracy: 0.9546
Epoch 38/45
469/469 [==============================] - 2s 4ms/step - loss: 0.1437 - accuracy: 0.9551
Epoch 39/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1423 - accuracy: 0.9555
Epoch 40/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1423 - accuracy: 0.9551
Epoch 41/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1423 - accuracy: 0.9552
Epoch 42/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1411 - accuracy: 0.9564
Epoch 43/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9555
Epoch 44/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9555
Epoch 45/45
469/469 [==============================] - 1s 3ms/step - loss: 0.1395 - accuracy: 0.9573
313/313 [==============================] - 1s 2ms/step - loss: 0.1281 - accuracy: 0.9594
Epoch 1/100
391/391 [==============================] - 2s 4ms/step - loss: 0.9668 - accuracy: 0.6927 - val_loss: 0.3765 - val_accuracy: 0.9067
Epoch 2/100
391/391 [==============================] - 4s 10ms/step - loss: 0.5680 - accuracy: 0.8247 - val_loss: 0.3022 - val_accuracy: 0.9171
Epoch 3/100
391/391 [==============================] - 2s 6ms/step - loss: 0.5119 - accuracy: 0.8404 - val_loss: 0.2724 - val_accuracy: 0.9255
Epoch 4/100
391/391 [==============================] - 2s 5ms/step - loss: 0.4760 - accuracy: 0.8503 - val_loss: 0.2577 - val_accuracy: 0.9304
Epoch 5/100
391/391 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.8557 - val_loss: 0.2427 - val_accuracy: 0.9340
Epoch 6/100
391/391 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8607 - val_loss: 0.2324 - val_accuracy: 0.9361
Epoch 7/100
391/391 [==============================] - 1s 4ms/step - loss: 0.4304 - accuracy: 0.8633 - val_loss: 0.2303 - val_accuracy: 0.9371
Epoch 8/100
391/391 [==============================] - 1s 4ms/step - loss: 0.4181 - accuracy: 0.8684 - val_loss: 0.2285 - val_accuracy: 0.9380
Epoch 9/100
391/391 [==============================] - 1s 3ms/step - loss: 0.4156 - accuracy: 0.8691 - val_loss: 0.2250 - val_accuracy: 0.9390
Epoch 10/100
391/391 [==============================] - 2s 4ms/step - loss: 0.4088 - accuracy: 0.8696 - val_loss: 0.2186 - val_accuracy: 0.9414
Epoch 11/100
391/391 [==============================] - 2s 5ms/step - loss: 0.4025 - accuracy: 0.8719 - val_loss: 0.2168 - val_accuracy: 0.9407
Epoch 12/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3985 - accuracy: 0.8732 - val_loss: 0.2130 - val_accuracy: 0.9407
Epoch 13/100
391/391 [==============================] - 1s 4ms/step - loss: 0.3949 - accuracy: 0.8763 - val_loss: 0.2119 - val_accuracy: 0.9418
Epoch 14/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3909 - accuracy: 0.8754 - val_loss: 0.2130 - val_accuracy: 0.9429
Epoch 15/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3841 - accuracy: 0.8780 - val_loss: 0.2139 - val_accuracy: 0.9428
Epoch 16/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3844 - accuracy: 0.8792 - val_loss: 0.2105 - val_accuracy: 0.9433
Epoch 17/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8774 - val_loss: 0.2131 - val_accuracy: 0.9430
Epoch 18/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8808 - val_loss: 0.2114 - val_accuracy: 0.9436
Epoch 19/100
391/391 [==============================] - 2s 4ms/step - loss: 0.3804 - accuracy: 0.8785 - val_loss: 0.2075 - val_accuracy: 0.9431
Epoch 20/100
391/391 [==============================] - 2s 4ms/step - loss: 0.3764 - accuracy: 0.8807 - val_loss: 0.2045 - val_accuracy: 0.9447
Epoch 21/100
391/391 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8813 - val_loss: 0.2027 - val_accuracy: 0.9455
Epoch 22/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8812 - val_loss: 0.2018 - val_accuracy: 0.9444
Epoch 23/100
391/391 [==============================] - 2s 5ms/step - loss: 0.3711 - accuracy: 0.8818 - val_loss: 0.2028 - val_accuracy: 0.9450
Epoch 24/100
391/391 [==============================] - 2s 6ms/step - loss: 0.3699 - accuracy: 0.8825 - val_loss: 0.2039 - val_accuracy: 0.9464
Epoch 25/100
391/391 [==============================] - 3s 7ms/step - loss: 0.3688 - accuracy: 0.8828 - val_loss: 0.2038 - val_accuracy: 0.9449
Epoch 26/100
391/391 [==============================] - 4s 10ms/step - loss: 0.3629 - accuracy: 0.8850 - val_loss: 0.2029 - val_accuracy: 0.9457
Epoch 27/100
391/391 [==============================] - 3s 7ms/step - loss: 0.3596 - accuracy: 0.8863 - val_loss: 0.2025 - val_accuracy: 0.9453
Epoch 28/100
391/391 [==============================] - 2s 6ms/step - loss: 0.3636 - accuracy: 0.8846 - val_loss: 0.2018 - val_accuracy: 0.9465
Epoch 29/100
391/391 [==============================] - 2s 6ms/step - loss: 0.3596 - accuracy: 0.8861 - val_loss: 0.1979 - val_accuracy: 0.9451
Epoch 30/100
391/391 [==============================] - 1s 4ms/step - loss: 0.3580 - accuracy: 0.8878 - val_loss: 0.1990 - val_accuracy: 0.9440
Epoch 31/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3609 - accuracy: 0.8866 - val_loss: 0.2016 - val_accuracy: 0.9455
Epoch 32/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3580 - accuracy: 0.8853 - val_loss: 0.1999 - val_accuracy: 0.9450
Epoch 33/100
391/391 [==============================] - 2s 5ms/step - loss: 0.3528 - accuracy: 0.8889 - val_loss: 0.1961 - val_accuracy: 0.9473
Epoch 34/100
391/391 [==============================] - 2s 4ms/step - loss: 0.3539 - accuracy: 0.8882 - val_loss: 0.1992 - val_accuracy: 0.9457
Epoch 35/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3568 - accuracy: 0.8880 - val_loss: 0.1989 - val_accuracy: 0.9458
Epoch 36/100
391/391 [==============================] - 1s 4ms/step - loss: 0.3536 - accuracy: 0.8885 - val_loss: 0.1987 - val_accuracy: 0.9462
Epoch 37/100
391/391 [==============================] - 2s 4ms/step - loss: 0.3496 - accuracy: 0.8892 - val_loss: 0.1992 - val_accuracy: 0.9473
Epoch 38/100
391/391 [==============================] - 2s 5ms/step - loss: 0.3506 - accuracy: 0.8897 - val_loss: 0.2051 - val_accuracy: 0.9445
Epoch 39/100
391/391 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8884 - val_loss: 0.2024 - val_accuracy: 0.9446
Epoch 40/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.8884 - val_loss: 0.2007 - val_accuracy: 0.9441
Epoch 41/100
391/391 [==============================] - 2s 4ms/step - loss: 0.3472 - accuracy: 0.8901 - val_loss: 0.2028 - val_accuracy: 0.9448
Epoch 42/100
391/391 [==============================] - 2s 5ms/step - loss: 0.3464 - accuracy: 0.8916 - val_loss: 0.2012 - val_accuracy: 0.9452
Epoch 43/100
391/391 [==============================] - 1s 3ms/step - loss: 0.3501 - accuracy: 0.8882 - val_loss: 0.2014 - val_accuracy: 0.9444
Best epoch: 33
Epoch 1/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8903
Epoch 2/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8903
Epoch 3/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3488 - accuracy: 0.8901
Epoch 4/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8920
Epoch 5/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8909
Epoch 6/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8919
Epoch 7/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3437 - accuracy: 0.8907
Epoch 8/39
469/469 [==============================] - 2s 5ms/step - loss: 0.3464 - accuracy: 0.8907
Epoch 9/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3449 - accuracy: 0.8918
Epoch 10/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3425 - accuracy: 0.8927
Epoch 11/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3403 - accuracy: 0.8929
Epoch 12/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8928
Epoch 13/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8935
Epoch 14/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3396 - accuracy: 0.8939
Epoch 15/39
469/469 [==============================] - 2s 3ms/step - loss: 0.3423 - accuracy: 0.8936
Epoch 16/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3424 - accuracy: 0.8935
Epoch 17/39
469/469 [==============================] - 2s 3ms/step - loss: 0.3353 - accuracy: 0.8944
Epoch 18/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8960
Epoch 19/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8929
Epoch 20/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8960
Epoch 21/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3353 - accuracy: 0.8957
Epoch 22/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8944
Epoch 23/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8950
Epoch 24/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3317 - accuracy: 0.8962
Epoch 25/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3327 - accuracy: 0.8965
Epoch 26/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.8953
Epoch 27/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8959
Epoch 28/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8957
Epoch 29/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8953
Epoch 30/39
469/469 [==============================] - 2s 3ms/step - loss: 0.3351 - accuracy: 0.8941
Epoch 31/39
469/469 [==============================] - 2s 5ms/step - loss: 0.3298 - accuracy: 0.8970
Epoch 32/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3259 - accuracy: 0.8986
Epoch 33/39
469/469 [==============================] - 3s 6ms/step - loss: 0.3326 - accuracy: 0.8967
Epoch 34/39
469/469 [==============================] - 3s 6ms/step - loss: 0.3291 - accuracy: 0.8978
Epoch 35/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3340 - accuracy: 0.8955
Epoch 36/39
469/469 [==============================] - 2s 5ms/step - loss: 0.3332 - accuracy: 0.8972
Epoch 37/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3310 - accuracy: 0.8975
Epoch 38/39
469/469 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8982
Epoch 39/39
469/469 [==============================] - 2s 4ms/step - loss: 0.3292 - accuracy: 0.8987
313/313 [==============================] - 1s 3ms/step - loss: 0.2235 - accuracy: 0.9439</code></pre>
</div>
</div>
<p>Note that if you’re not worried about slightly underperforming, there’s a shortcut you can take: just use the tuner to reload the top-performing models with the best weights saved during the hyperparameter search, without retraining new models from scratch:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:838,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684902328023,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="f732a918-42c9-4664-a61f-7f5709a7ee84">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>models <span class="op">=</span> tuner.get_best_models(top_n)</span>
<span id="cb40-2"><a href="#cb40-2"></a>best_model <span class="op">=</span> models[<span class="dv">0</span>]</span>
<span id="cb40-3"><a href="#cb40-3"></a><span class="co"># Build the model.</span></span>
<span id="cb40-4"><a href="#cb40-4"></a><span class="co"># Needed for `Sequential` without specified `input_shape`.</span></span>
<span id="cb40-5"><a href="#cb40-5"></a>best_model.build(input_shape<span class="op">=</span>(<span class="va">None</span>, <span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb40-6"><a href="#cb40-6"></a>best_model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 32)                25120     
                                                                 
 dropout (Dropout)           (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 25,450
Trainable params: 25,450
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2335,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684902488375,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="c86d9d20-4bfa-484f-b748-d5917eb35536">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>best_model.evaluate(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 [==============================] - 2s 4ms/step - loss: 0.1319 - accuracy: 0.9616</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>[0.1318952739238739, 0.9616000056266785]</code></pre>
</div>
</div>
<p>You can also print a summary of the search results.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:4,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684902328023,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="4747c76a-8f39-41e2-dfc0-ef2cd8c07903">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a>tuner.results_summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Results summary
Results in mnist_kt_test/untitled_project
Showing 10 best trials
Objective(name="val_accuracy", direction="max")

Trial 0 summary
Hyperparameters:
num_layers: 1
units: 32
activation: tanh
dropout: True
lr: 0.001023588238883239
optimizer: adam
Score: 0.9647500216960907

Trial 2 summary
Hyperparameters:
num_layers: 1
units: 32
activation: tanh
dropout: True
lr: 0.00020952911266579243
optimizer: rmsprop
Score: 0.9639500081539154

Trial 1 summary
Hyperparameters:
num_layers: 1
units: 16
activation: relu
dropout: True
lr: 0.004306213731281972
optimizer: rmsprop
Score: 0.9480000138282776</code></pre>
</div>
</div>
</section>
</section>
<section id="tune-model-training" class="level3" data-number="13.3.2">
<h3 data-number="13.3.2" class="anchored" data-anchor-id="tune-model-training"><span class="header-section-number">13.3.2</span> Tune model training</h3>
<p>To tune the model building process, we need to subclass the <code>HyperModel</code> class, which also makes it easy to share and reuse hypermodels.</p>
<p>We need to override <code>HyperModel.build()</code> and <code>HyperModel.fit()</code> to tune the model building and training process respectively. A <code>HyperModel.build()</code> method is the same as the model-building function, which creates a Keras model using the hyperparameters and returns it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1"></a><span class="kw">class</span> MyHyperModel(kt.HyperModel):</span>
<span id="cb47-2"><a href="#cb47-2"></a>    <span class="kw">def</span> build(<span class="va">self</span>, hp):</span>
<span id="cb47-3"><a href="#cb47-3"></a>        model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb47-4"><a href="#cb47-4"></a>        model.add(tf.keras.layers.Flatten())</span>
<span id="cb47-5"><a href="#cb47-5"></a>        model.add(</span>
<span id="cb47-6"><a href="#cb47-6"></a>            tf.keras.layers.Dense(</span>
<span id="cb47-7"><a href="#cb47-7"></a>                units<span class="op">=</span>hp.Int(<span class="st">"units"</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>),</span>
<span id="cb47-8"><a href="#cb47-8"></a>                activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb47-9"><a href="#cb47-9"></a>            )</span>
<span id="cb47-10"><a href="#cb47-10"></a>        )</span>
<span id="cb47-11"><a href="#cb47-11"></a>        model.add(tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>))</span>
<span id="cb47-12"><a href="#cb47-12"></a>        model.<span class="bu">compile</span>(</span>
<span id="cb47-13"><a href="#cb47-13"></a>            optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"categorical_crossentropy"</span>, metrics<span class="op">=</span>[<span class="st">"accuracy"</span>],</span>
<span id="cb47-14"><a href="#cb47-14"></a>        )</span>
<span id="cb47-15"><a href="#cb47-15"></a>        <span class="cf">return</span> model</span>
<span id="cb47-16"><a href="#cb47-16"></a></span>
<span id="cb47-17"><a href="#cb47-17"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, hp, model, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb47-18"><a href="#cb47-18"></a>        <span class="cf">return</span> model.fit(</span>
<span id="cb47-19"><a href="#cb47-19"></a>            <span class="op">*</span>args,</span>
<span id="cb47-20"><a href="#cb47-20"></a>            <span class="co"># Tune whether to shuffle the data in each epoch!</span></span>
<span id="cb47-21"><a href="#cb47-21"></a>            shuffle<span class="op">=</span>hp.Boolean(<span class="st">"shuffle"</span>),</span>
<span id="cb47-22"><a href="#cb47-22"></a>            <span class="op">**</span>kwargs,</span>
<span id="cb47-23"><a href="#cb47-23"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can do a quick check to see if the code works correctly by using a small amount of random data.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1750,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684902509370,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="c22bde00-3ab6-4eef-8de2-25dc42816a5b">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>hp <span class="op">=</span> kt.HyperParameters()</span>
<span id="cb48-2"><a href="#cb48-2"></a>hypermodel <span class="op">=</span> MyHyperModel()</span>
<span id="cb48-3"><a href="#cb48-3"></a>model <span class="op">=</span> hypermodel.build(hp)</span>
<span id="cb48-4"><a href="#cb48-4"></a>hypermodel.fit(hp, model, np.random.rand(<span class="dv">100</span>, <span class="dv">28</span>, <span class="dv">28</span>), np.random.rand(<span class="dv">100</span>, <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4/4 [==============================] - 1s 7ms/step - loss: 12.5933 - accuracy: 0.1000</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>&lt;keras.callbacks.History at 0x7f8cb6183be0&gt;</code></pre>
</div>
</div>
</section>
<section id="tune-data-preprocessing" class="level3" data-number="13.3.3">
<h3 data-number="13.3.3" class="anchored" data-anchor-id="tune-data-preprocessing"><span class="header-section-number">13.3.3</span> Tune data preprocessing</h3>
<p>To tune data preprocessing, we just add an additional step in <code>HyperModel.fit()</code>, where we can access the dataset from the arguments. In the following code, we tune whether to normalize the data before training the model. This time we explicitly put x and y in the function signature because we need to use them.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1218,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684902512822,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="5f058fc4-c0c9-4f97-eadc-fd5b04b28b77">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a><span class="kw">class</span> MyHyperModel(kt.HyperModel):</span>
<span id="cb51-2"><a href="#cb51-2"></a>    <span class="kw">def</span> build(<span class="va">self</span>, hp):</span>
<span id="cb51-3"><a href="#cb51-3"></a>        model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb51-4"><a href="#cb51-4"></a>        model.add(tf.keras.layers.Flatten())</span>
<span id="cb51-5"><a href="#cb51-5"></a>        model.add(</span>
<span id="cb51-6"><a href="#cb51-6"></a>            tf.keras.layers.Dense(</span>
<span id="cb51-7"><a href="#cb51-7"></a>                units<span class="op">=</span>hp.Int(<span class="st">"units"</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>),</span>
<span id="cb51-8"><a href="#cb51-8"></a>                activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb51-9"><a href="#cb51-9"></a>            )</span>
<span id="cb51-10"><a href="#cb51-10"></a>        )</span>
<span id="cb51-11"><a href="#cb51-11"></a>        model.add(tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>))</span>
<span id="cb51-12"><a href="#cb51-12"></a>        model.<span class="bu">compile</span>(</span>
<span id="cb51-13"><a href="#cb51-13"></a>            optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"categorical_crossentropy"</span>, metrics<span class="op">=</span>[<span class="st">"accuracy"</span>],</span>
<span id="cb51-14"><a href="#cb51-14"></a>        )</span>
<span id="cb51-15"><a href="#cb51-15"></a>        <span class="cf">return</span> model</span>
<span id="cb51-16"><a href="#cb51-16"></a></span>
<span id="cb51-17"><a href="#cb51-17"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, hp, model, x, y, <span class="op">**</span>kwargs):</span>
<span id="cb51-18"><a href="#cb51-18"></a>        <span class="co"># Tune whether to add normalize layer!</span></span>
<span id="cb51-19"><a href="#cb51-19"></a>        <span class="cf">if</span> hp.Boolean(<span class="st">"normalize"</span>):</span>
<span id="cb51-20"><a href="#cb51-20"></a>            x <span class="op">=</span> tf.keras.layers.Normalization()(x)</span>
<span id="cb51-21"><a href="#cb51-21"></a>        <span class="cf">return</span> model.fit(</span>
<span id="cb51-22"><a href="#cb51-22"></a>            x,</span>
<span id="cb51-23"><a href="#cb51-23"></a>            y,</span>
<span id="cb51-24"><a href="#cb51-24"></a>            shuffle<span class="op">=</span>hp.Boolean(<span class="st">"shuffle"</span>),</span>
<span id="cb51-25"><a href="#cb51-25"></a>            <span class="op">**</span>kwargs,</span>
<span id="cb51-26"><a href="#cb51-26"></a>        )</span>
<span id="cb51-27"><a href="#cb51-27"></a></span>
<span id="cb51-28"><a href="#cb51-28"></a></span>
<span id="cb51-29"><a href="#cb51-29"></a>hp <span class="op">=</span> kt.HyperParameters()</span>
<span id="cb51-30"><a href="#cb51-30"></a>hypermodel <span class="op">=</span> MyHyperModel()</span>
<span id="cb51-31"><a href="#cb51-31"></a>model <span class="op">=</span> hypermodel.build(hp)</span>
<span id="cb51-32"><a href="#cb51-32"></a>hypermodel.fit(hp, model, np.random.rand(<span class="dv">100</span>, <span class="dv">28</span>, <span class="dv">28</span>), np.random.rand(<span class="dv">100</span>, <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4/4 [==============================] - 1s 5ms/step - loss: 12.3237 - accuracy: 0.0900</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>&lt;keras.callbacks.History at 0x7f8cb619d270&gt;</code></pre>
</div>
</div>
<p>For more information, please refer to https://keras.io/keras_tuner/</p>
</section>
</section>
<section id="network-architecture-search-with-autokeras" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="network-architecture-search-with-autokeras"><span class="header-section-number">13.4</span> Network architecture search with <code>AutoKeras</code></h2>
<p>Let’s now build up an AutoML pipeline to improve the CNN structure and achieve better classification accuracy.</p>
<p>Creating an AutoML pipeline with the <code>AutoKeras</code> functional API is quite similar to building up a neural network with the <code>Keras</code> functional API. The only difference is that the <code>Keras</code> layers are replaced with <code>AutoKeras</code>’s built-in AutoML blocks. Each block contains one or more deep learning models (or preprocessing methods) and a default search space for their hyperparameters. You can also modify the search space for each hyperparameter. To build up a network, we stack multiple Keras layers by wiring together their inputs and outputs sequentially. Specifically, it often contyains the following blocks:</p>
<ul>
<li><strong>Input node</strong>: which is a placeholder for the tensor input of the pipeline, such as <code>ImageInput</code>, <code>TextInput</code>, or <code>StructuredDataInput</code>. You can also define a general tensor input with the Input class in <code>AutoKeras</code>. The input node accepts data in multiple formats, such as <code>Numpy</code> arrays, <code>Pandas</code> DataFrames, and <code>TensorFlow</code> Datasets. It will also conduct certain preprocessing operations automatically, such as extending the dimensions of images if they do not have a channel dimension. The input node does not have any hyperparameters that can be set or tuned.</li>
<li><strong>Preprocessor</strong>: which is block defines additional preprocessing operations to perform on the inputs, such as image normalization, text embedding, and so on. Depending on the operation, there may be hyperparameters to tune, such as the maximum size of the vocabulary table to use to convert text documents to their vector representations if text embedding is performed. In this block, there are no weights to be trained through backpropagation.</li>
<li><strong>Network</strong>: which is the most important type of AutoML block in <code>AutoKeras</code>. Each block represents a set of neural network models of the same structure. For example, a <code>ConvBlock</code>. The number and types of layers are treated as hyperparameters. You can select one or more network blocks to create the pipelines based on the task at hand, and specify the search space of their hyperparameters based on your requirements. Unlike the preprocessor block, there are weights to be trained through backpropagation after specifying the hyperparameters in the network block.</li>
<li><strong>Head</strong>: which is a task-specific component used to generate the final outputs, such as the <code>ClassificationHead</code> and <code>RegressionHead</code>. It reshapes each instance’s representation to a vector and applies a dense layer to transform it to the size of the target output. For example, if the head is a <code>ClassificationHead</code> and the problem is a binary classification problem, the output of each instance from the dense layer will be a vector of length two corresponding to the two labels. Each head also specifies the loss function and metrics to help compile each deep learning pipeline selected from the search space for training.</li>
</ul>
<section id="tuning-cnns-for-image-classification" class="level3" data-number="13.4.1">
<h3 data-number="13.4.1" class="anchored" data-anchor-id="tuning-cnns-for-image-classification"><span class="header-section-number">13.4.1</span> Tuning CNNs for image classification</h3>
<p>We leverage a <code>ConvBlock</code> in <code>AutoKeras</code> to tune the three main hyperparameters of the CNN: <strong>the number of filters, the number of convolutional layers, and the kernel size</strong> of the convolutional layers. A <code>ConvBlock</code> sequentially stacks multiple convolutional blocks (or convolutional cells). Each convolutional block sequentially stacks multiple convolutional layers, a max pooling layer, and a dropout layer.</p>
<p>All the convolutional blocks have the same number of convolutional layers, but there can be a different number of filters in each layer. There are seven hyperparameters in the search space of a <code>ConvBlock</code>:</p>
<ul>
<li>Number of convolutional blocks.</li>
<li>Number of convolutional layers in each block. This is the same in all the convolutional blocks.</li>
<li>Type of the convolutional layer. Each convolutional layer can be one of two types: it can be a regular 2D convolutional layer or a separable convolutional layer, which contains fewer weights than a normal convolutional layer but may achieve comparable performance.</li>
<li>Number of filters in the convolutional layer. This can be different for each layer of each block.</li>
<li>Kernel size of the convolutional layer. The kernel size of the max pooling layers is set to be the kernel size minus one. Once the kernel size is selected by the tuning algorithm for a ConvBlock in a trial, it will be applied for every pooling layer and convolutional layer in all the cells of that ConvBlock.</li>
<li>Whether to apply the max pooling layer in each cell. Once this is selected for a trial, it’s applied for every cell in the ConvBlock.</li>
<li>Whether to apply the dropout layer in each cell. Once this is selected for a trial, it’s applied for every cell in the ConvBlock.</li>
</ul>
<p>To keep this example simple, we’ll constrain the search space by fixing the number of blocks as two. We do not apply the dropout layer or use separable convolutional layers. <strong>The hyperparameters to be tuned are the number of layers, the kernel size, and the number of filters in each layer in the blocks. By default, they are selected from the lists <code>[1, 2]</code>, <code>[3, 5, 7]</code>, and <code>[16, 32, 64, 128, 256, 512]</code>, respectively.</strong></p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:507312,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684903441057,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="65229e19-142a-4510-8465-10645d354a8f">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> tf.keras.datasets.mnist.load_data()</span>
<span id="cb54-2"><a href="#cb54-2"></a></span>
<span id="cb54-3"><a href="#cb54-3"></a><span class="co"># The model</span></span>
<span id="cb54-4"><a href="#cb54-4"></a>input_node <span class="op">=</span> ak.ImageInput()</span>
<span id="cb54-5"><a href="#cb54-5"></a>output_node <span class="op">=</span> ak.Normalization()(input_node)</span>
<span id="cb54-6"><a href="#cb54-6"></a>output_node <span class="op">=</span> ak.ConvBlock(</span>
<span id="cb54-7"><a href="#cb54-7"></a>    <span class="co"># do not specify if we want to let it to search automatically</span></span>
<span id="cb54-8"><a href="#cb54-8"></a>    num_blocks<span class="op">=</span><span class="dv">2</span>, max_pooling<span class="op">=</span><span class="va">True</span>, separable<span class="op">=</span><span class="va">False</span>, dropout<span class="op">=</span><span class="fl">0.0</span></span>
<span id="cb54-9"><a href="#cb54-9"></a>)(output_node)</span>
<span id="cb54-10"><a href="#cb54-10"></a>output_node <span class="op">=</span> ak.ClassificationHead(dropout<span class="op">=</span><span class="fl">0.0</span>)(output_node)</span>
<span id="cb54-11"><a href="#cb54-11"></a>auto_model <span class="op">=</span> ak.AutoModel(</span>
<span id="cb54-12"><a href="#cb54-12"></a>    inputs<span class="op">=</span>input_node, outputs<span class="op">=</span>output_node, max_trials<span class="op">=</span><span class="dv">10</span>, overwrite<span class="op">=</span><span class="va">True</span>, seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb54-13"><a href="#cb54-13"></a>)</span>
<span id="cb54-14"><a href="#cb54-14"></a></span>
<span id="cb54-15"><a href="#cb54-15"></a><span class="co"># You may run with the full dataset, but expect a longer training time.</span></span>
<span id="cb54-16"><a href="#cb54-16"></a>auto_model.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 10 Complete [00h 00m 54s]
val_loss: 0.03022073395550251

Best val_loss So Far: 0.03022073395550251
Total elapsed time: 00h 07m 25s
Epoch 1/3
1875/1875 [==============================] - 20s 9ms/step - loss: 0.1914 - accuracy: 0.9415
Epoch 2/3
1875/1875 [==============================] - 14s 7ms/step - loss: 0.0371 - accuracy: 0.9890
Epoch 3/3
1875/1875 [==============================] - 15s 8ms/step - loss: 0.0143 - accuracy: 0.9958</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>&lt;keras.callbacks.History at 0x7f8cb1aaa7d0&gt;</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3565,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684903445137,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="4eb471e4-3ade-4531-e908-28fe9f123b48">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1"></a>test_loss, test_acc <span class="op">=</span> auto_model.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb58-2"><a href="#cb58-2"></a><span class="bu">print</span>(<span class="st">"Test accuracy: "</span>, test_acc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test accuracy:  0.9929999709129333</code></pre>
</div>
</div>
<p>The best CNN achieves 99.3% accuracy on the test set. To discover smaller architectures, we can limit the number of layers and filters in the search space. It is possible to find a smaller architecture with comparableb performance to the CNN we constructed here.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:454,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684903445588,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="d728097b-2dcc-4ff0-91a6-737c93f4cd23">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a>best_model <span class="op">=</span> auto_model.export_model()</span>
<span id="cb60-2"><a href="#cb60-2"></a>best_model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 28, 28)]          0         
                                                                 
 cast_to_float32 (CastToFloa  (None, 28, 28)           0         
 t32)                                                            
                                                                 
 expand_last_dim (ExpandLast  (None, 28, 28, 1)        0         
 Dim)                                                            
                                                                 
 normalization (Normalizatio  (None, 28, 28, 1)        3         
 n)                                                              
                                                                 
 conv2d (Conv2D)             (None, 24, 24, 256)       6656      
                                                                 
 conv2d_1 (Conv2D)           (None, 20, 20, 16)        102416    
                                                                 
 max_pooling2d (MaxPooling2D  (None, 5, 5, 16)         0         
 )                                                               
                                                                 
 conv2d_2 (Conv2D)           (None, 5, 5, 32)          12832     
                                                                 
 conv2d_3 (Conv2D)           (None, 5, 5, 128)         102528    
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 2, 2, 128)        0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 512)               0         
                                                                 
 dense (Dense)               (None, 10)                5130      
                                                                 
 classification_head_1 (Soft  (None, 10)               0         
 max)                                                            
                                                                 
=================================================================
Total params: 229,565
Trainable params: 229,562
Non-trainable params: 3
_________________________________________________________________</code></pre>
</div>
</div>
</section>
<section id="automated-pipeline-search-with-autokeras" class="level3" data-number="13.4.2">
<h3 data-number="13.4.2" class="anchored" data-anchor-id="automated-pipeline-search-with-autokeras"><span class="header-section-number">13.4.2</span> Automated pipeline search with <code>AutoKeras</code></h3>
<p>It is also possible to use <code>autoKeras</code> in AutoML applications: selecting the best types of components (models or preprocessors) to use in the deep learning pipeline. This is a more complex scenario than only tuning the hyperparameters of a specific type of model, as introduced in the previous section, because different models and preprocessors may compose different operations and have unique hyperparameters. It requires us to jointly select the combination of preprocessors and models and their coupled hyperparameters.</p>
<p>For example, in image classification, there are a lot of advanced models proposed beyond the naive CNN we used previously, such as ResNet, Xception, and so on. You’ll also need to decide on suitable preprocessing methods, such as choosing whether to use normalization or not. We’ll work through some image classification examples here to show you how to automatically select models and preprocessing methods.</p>
<section id="automated-selection-of-image-preprocessing-methods" class="level4" data-number="13.4.2.1">
<h4 data-number="13.4.2.1" class="anchored" data-anchor-id="automated-selection-of-image-preprocessing-methods"><span class="header-section-number">13.4.2.1</span> Automated selection of image preprocessing methods</h4>
<p>In fact, it is also straightforward to extend the AutoML pipeline to tune and select a suitable data augmentation method — that is, to use an AutoML block to select and evaluate various data augmentation methods. The <code>ImageBlock</code> also allows us to select among multiple data preprocessing methods, such as deciding whether to use normalization and/or data augmentation methods to prepare the data.</p>
<p>Let’s use an image classification example to illustrate how to automatically select preprocessing methods for a ResNet model. We decide whether to use data augmentation and normalization methods or not. The dataset we use here is a subset of the CIFAR-10 dataset. To make things easier, we’ll only use images from two classes, “airplane” and “automobile.”</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:6287,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684903462621,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="5bd64851-b494-4d8f-f51c-ef2209fa01c2">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1"></a><span class="co">#ssl._create_default_https_context = ssl._create_unverified_context</span></span>
<span id="cb62-2"><a href="#cb62-2"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> tf.keras.datasets.cifar10.load_data()</span>
<span id="cb62-3"><a href="#cb62-3"></a><span class="bu">print</span>(<span class="st">"Training image shape:"</span>, x_train.shape)  <span class="co"># (60000, 28, 28)</span></span>
<span id="cb62-4"><a href="#cb62-4"></a><span class="bu">print</span>(<span class="st">"Training label shape:"</span>, y_train.shape)  <span class="co"># (60000,)</span></span>
<span id="cb62-5"><a href="#cb62-5"></a><span class="bu">print</span>(<span class="st">"First five training labels:"</span>, y_train[:<span class="dv">5</span>])  <span class="co"># array([5 0 4 1 9], dtype=uint8)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
170498071/170498071 [==============================] - 2s 0us/step
Training image shape: (50000, 32, 32, 3)
Training label shape: (50000, 1)
First five training labels: [[6]
 [9]
 [9]
 [4]
 [1]]</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:252,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684903465034,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="5a751a4b-e7d2-415c-de77-c1529de0be5c">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1"></a>airplane_automobile_indices_train <span class="op">=</span> (y_train[:, <span class="dv">0</span>] <span class="op">==</span> <span class="dv">0</span>) <span class="op">|</span> (y_train[:, <span class="dv">0</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb64-2"><a href="#cb64-2"></a>airplane_automobile_indices_test <span class="op">=</span> (y_test[:, <span class="dv">0</span>] <span class="op">==</span> <span class="dv">0</span>) <span class="op">|</span> (y_test[:, <span class="dv">0</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb64-3"><a href="#cb64-3"></a>x_train, y_train <span class="op">=</span> (</span>
<span id="cb64-4"><a href="#cb64-4"></a>    x_train[airplane_automobile_indices_train],</span>
<span id="cb64-5"><a href="#cb64-5"></a>    y_train[airplane_automobile_indices_train],</span>
<span id="cb64-6"><a href="#cb64-6"></a>)</span>
<span id="cb64-7"><a href="#cb64-7"></a>x_test, y_test <span class="op">=</span> (</span>
<span id="cb64-8"><a href="#cb64-8"></a>    x_test[airplane_automobile_indices_test],</span>
<span id="cb64-9"><a href="#cb64-9"></a>    y_test[airplane_automobile_indices_test],</span>
<span id="cb64-10"><a href="#cb64-10"></a>)</span>
<span id="cb64-11"><a href="#cb64-11"></a><span class="bu">print</span>(<span class="st">"Training image shape:"</span>, x_train.shape)  <span class="co"># (60000, 28, 28)</span></span>
<span id="cb64-12"><a href="#cb64-12"></a><span class="bu">print</span>(<span class="st">"Training label shape:"</span>, y_train.shape)  <span class="co"># (60000,)</span></span>
<span id="cb64-13"><a href="#cb64-13"></a><span class="bu">print</span>(<span class="st">"First five training labels:"</span>, y_train[:<span class="dv">5</span>])  <span class="co"># array([5 0 4 1 9], dtype=uint8)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training image shape: (10000, 32, 32, 3)
Training label shape: (10000, 1)
First five training labels: [[1]
 [1]
 [0]
 [0]
 [1]]</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2211,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684903475566,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="d167e5b9-ef23-47a6-ee59-992464995c64">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1"></a><span class="co"># plot first few images</span></span>
<span id="cb66-2"><a href="#cb66-2"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):</span>
<span id="cb66-3"><a href="#cb66-3"></a>    <span class="co"># define subplot</span></span>
<span id="cb66-4"><a href="#cb66-4"></a>    plt.subplot(<span class="dv">330</span> <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> i)</span>
<span id="cb66-5"><a href="#cb66-5"></a>    <span class="co"># plot raw pixel data</span></span>
<span id="cb66-6"><a href="#cb66-6"></a>    plt.imshow(x_train[i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="13_Hyperparameter_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Let’s first create an AutoML pipeline to select the data augmentation method for the ResNet models. The pipeline has the same structure as the sequential AutoML pipelines we built in the previous section for tuning a single ResNet model. The only difference is that we add the image hyperblock (<code>ImageBlock</code>) in <code>AutoKeras</code> also contains preprocessing methods. The augmentation methods are selected along with the structure and other hyperparameters, such as the optimization method and learning rate.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1309318,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684904788450,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="03583de5-bb7f-4a5f-9a8f-69241cc9017d">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a>input_node <span class="op">=</span> ak.ImageInput()</span>
<span id="cb67-2"><a href="#cb67-2"></a>output_node <span class="op">=</span> ak.ImageBlock(</span>
<span id="cb67-3"><a href="#cb67-3"></a>    <span class="co"># do not specify if we want to use normalization and let it to search automatically</span></span>
<span id="cb67-4"><a href="#cb67-4"></a>    normalize<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb67-5"><a href="#cb67-5"></a>    <span class="co"># do not specify if we want to use adata ugmentation method and let it to search automatically</span></span>
<span id="cb67-6"><a href="#cb67-6"></a>    augment<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb67-7"><a href="#cb67-7"></a>    <span class="co"># Only search resnet architectures.</span></span>
<span id="cb67-8"><a href="#cb67-8"></a>    block_type<span class="op">=</span><span class="st">"resnet"</span>,</span>
<span id="cb67-9"><a href="#cb67-9"></a>)(input_node)</span>
<span id="cb67-10"><a href="#cb67-10"></a>output_node <span class="op">=</span> ak.ClassificationHead(dropout<span class="op">=</span><span class="fl">0.0</span>)(output_node)</span>
<span id="cb67-11"><a href="#cb67-11"></a></span>
<span id="cb67-12"><a href="#cb67-12"></a>auto_model <span class="op">=</span> ak.AutoModel(</span>
<span id="cb67-13"><a href="#cb67-13"></a>    inputs<span class="op">=</span>input_node, outputs<span class="op">=</span>output_node, max_trials<span class="op">=</span><span class="dv">10</span>, overwrite<span class="op">=</span><span class="va">True</span>, seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb67-14"><a href="#cb67-14"></a>)</span>
<span id="cb67-15"><a href="#cb67-15"></a></span>
<span id="cb67-16"><a href="#cb67-16"></a>auto_model.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 10 Complete [00h 02m 05s]
val_loss: 0.2805823087692261

Best val_loss So Far: 0.19601556658744812
Total elapsed time: 00h 19m 12s
Epoch 1/10
157/157 [==============================] - 39s 52ms/step - loss: 0.4771 - accuracy: 0.7922
Epoch 2/10
157/157 [==============================] - 7s 42ms/step - loss: 0.3570 - accuracy: 0.8460
Epoch 3/10
157/157 [==============================] - 7s 46ms/step - loss: 0.3102 - accuracy: 0.8693
Epoch 4/10
157/157 [==============================] - 7s 43ms/step - loss: 0.2904 - accuracy: 0.8785
Epoch 5/10
157/157 [==============================] - 7s 46ms/step - loss: 0.2678 - accuracy: 0.8889
Epoch 6/10
157/157 [==============================] - 7s 47ms/step - loss: 0.2402 - accuracy: 0.9012
Epoch 7/10
157/157 [==============================] - 7s 45ms/step - loss: 0.2284 - accuracy: 0.9058
Epoch 8/10
157/157 [==============================] - 7s 44ms/step - loss: 0.2169 - accuracy: 0.9135
Epoch 9/10
157/157 [==============================] - 7s 46ms/step - loss: 0.2171 - accuracy: 0.9109
Epoch 10/10
157/157 [==============================] - 7s 42ms/step - loss: 0.2014 - accuracy: 0.9168</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>&lt;keras.callbacks.History at 0x7f8c996e84f0&gt;</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:14,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684904788451,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="9642816e-88a9-4595-dd66-beb2ab8c10a7">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1"></a>auto_model.tuner.results_summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Results summary
Results in ./auto_model
Showing 10 best trials
Objective(name="val_loss", direction="min")

Trial 07 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: True
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: global_max
optimizer: adam
learning_rate: 0.001
image_block_1/image_augmentation_1/translation_factor: 0.1
image_block_1/image_augmentation_1/horizontal_flip: True
image_block_1/image_augmentation_1/vertical_flip: False
image_block_1/image_augmentation_1/rotation_factor: 0.1
image_block_1/image_augmentation_1/zoom_factor: 0.0
image_block_1/image_augmentation_1/contrast_factor: 0.1
Score: 0.19601556658744812

Trial 05 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: True
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: flatten
optimizer: adam
learning_rate: 0.001
image_block_1/image_augmentation_1/translation_factor: 0.1
image_block_1/image_augmentation_1/horizontal_flip: True
image_block_1/image_augmentation_1/vertical_flip: False
image_block_1/image_augmentation_1/rotation_factor: 0.1
image_block_1/image_augmentation_1/zoom_factor: 0.0
image_block_1/image_augmentation_1/contrast_factor: 0.1
Score: 0.2053665965795517

Trial 00 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: False
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: flatten
optimizer: adam
learning_rate: 0.001
Score: 0.25839027762413025

Trial 01 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: False
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: flatten
optimizer: adam
learning_rate: 0.1
Score: 0.2603760361671448

Trial 08 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: True
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: global_max
optimizer: adam
learning_rate: 0.001
image_block_1/image_augmentation_1/translation_factor: 0.1
image_block_1/image_augmentation_1/horizontal_flip: True
image_block_1/image_augmentation_1/vertical_flip: False
image_block_1/image_augmentation_1/rotation_factor: 0.1
image_block_1/image_augmentation_1/zoom_factor: 0.1
image_block_1/image_augmentation_1/contrast_factor: 0.1
Score: 0.2673555910587311

Trial 09 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: True
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: global_avg
optimizer: adam
learning_rate: 0.001
image_block_1/image_augmentation_1/translation_factor: 0.1
image_block_1/image_augmentation_1/horizontal_flip: True
image_block_1/image_augmentation_1/vertical_flip: False
image_block_1/image_augmentation_1/rotation_factor: 0.1
image_block_1/image_augmentation_1/zoom_factor: 0.0
image_block_1/image_augmentation_1/contrast_factor: 0.1
Score: 0.2805823087692261

Trial 04 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: True
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: flatten
optimizer: adam
learning_rate: 0.001
image_block_1/image_augmentation_1/translation_factor: 0.0
image_block_1/image_augmentation_1/horizontal_flip: True
image_block_1/image_augmentation_1/vertical_flip: True
image_block_1/image_augmentation_1/rotation_factor: 0.0
image_block_1/image_augmentation_1/zoom_factor: 0.0
image_block_1/image_augmentation_1/contrast_factor: 0.0
Score: 0.28421175479888916

Trial 03 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: False
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: global_avg
optimizer: adam
learning_rate: 0.001
Score: 0.29526445269584656

Trial 02 summary
Hyperparameters:
image_block_1/normalize: False
image_block_1/augment: False
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: global_max
optimizer: adam
learning_rate: 0.001
Score: 0.3357878029346466

Trial 06 summary
Hyperparameters:
image_block_1/normalize: True
image_block_1/augment: True
image_block_1/res_net_block_1/pretrained: False
image_block_1/res_net_block_1/version: resnet50_v2
image_block_1/res_net_block_1/imagenet_size: False
classification_head_1/spatial_reduction_1/reduction_type: flatten
optimizer: adam
learning_rate: 0.001
image_block_1/image_augmentation_1/translation_factor: 0.1
image_block_1/image_augmentation_1/horizontal_flip: True
image_block_1/image_augmentation_1/vertical_flip: False
image_block_1/image_augmentation_1/rotation_factor: 0.1
image_block_1/image_augmentation_1/zoom_factor: 0.0
image_block_1/image_augmentation_1/contrast_factor: 0.1
Score: 0.5242509245872498</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:11251,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684904799698,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="b34a661d-cb46-4036-a5fd-f364a82882ea">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1"></a>best_model <span class="op">=</span> auto_model.export_model()</span>
<span id="cb73-2"><a href="#cb73-2"></a>best_model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 32, 32, 3)]       0         
                                                                 
 cast_to_float32 (CastToFloa  (None, 32, 32, 3)        0         
 t32)                                                            
                                                                 
 random_translation (RandomT  (None, 32, 32, 3)        0         
 ranslation)                                                     
                                                                 
 random_flip (RandomFlip)    (None, 32, 32, 3)         0         
                                                                 
 random_rotation (RandomRota  (None, 32, 32, 3)        0         
 tion)                                                           
                                                                 
 random_contrast (RandomCont  (None, 32, 32, 3)        0         
 rast)                                                           
                                                                 
 resnet50v2 (Functional)     (None, 1, 1, 2048)        23564800  
                                                                 
 global_max_pooling2d (Globa  (None, 2048)             0         
 lMaxPooling2D)                                                  
                                                                 
 dense (Dense)               (None, 1)                 2049      
                                                                 
 classification_head_1 (Acti  (None, 1)                0         
 vation)                                                         
                                                                 
=================================================================
Total params: 23,566,849
Trainable params: 23,521,409
Non-trainable params: 45,440
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:13524,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684904813213,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="c5d52343-b964-4f82-b5bc-5d2806da277b">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a>test_loss, test_acc <span class="op">=</span> auto_model.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-2"><a href="#cb75-2"></a><span class="bu">print</span>(<span class="st">"Accuracy: </span><span class="sc">{accuracy}</span><span class="st">%"</span>.<span class="bu">format</span>(accuracy<span class="op">=</span><span class="bu">round</span>(test_acc <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 84.55%</code></pre>
</div>
</div>
<p>For more information, please refer to https://autokeras.com/</p>
</section>
</section>
</section>
<section id="w-b" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="w-b"><span class="header-section-number">13.5</span> W &amp; B</h2>
<p>We can use <strong><a href="https://wandb.ai/site?utm_source=intro_colab&amp;utm_medium=code&amp;utm_campaign=intro">Weights &amp; Biases</a></strong> for machine learning experiment tracking, model checkpointing, and collaboration with your team. See the full Weights &amp; Biases Documentation <strong><a href="https://docs.wandb.ai/quickstart">here</a></strong></p>
<p>Start by logging in to your account. If this is your first time using W&amp;B or you are not logged in, the link that appears after running <code>wandb.login()</code> will take you to sign-up/login page.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:4650,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684915652863,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="da8a7f0b-257e-41e6-e695-6a50d39acf36">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1"></a>wandb.login()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Currently logged in as: phonchi. Use `wandb login --relogin` to force relogin</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>True</code></pre>
</div>
</div>
<section id="normal-logging-flow" class="level3" data-number="13.5.1">
<h3 data-number="13.5.1" class="anchored" data-anchor-id="normal-logging-flow"><span class="header-section-number">13.5.1</span> Normal logging flow</h3>
<p>Let us first import the cifar10 data and define the model.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:5684,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684911043596,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="e1e35836-598f-4828-9ce7-7f6e0c9a3aff">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span>  tf.keras.datasets.cifar10.load_data()</span>
<span id="cb80-2"><a href="#cb80-2"></a></span>
<span id="cb80-3"><a href="#cb80-3"></a><span class="co"># Subsetting train data and normalizing to [0., 1.]</span></span>
<span id="cb80-4"><a href="#cb80-4"></a>x_train, x_test <span class="op">=</span> x_train[::<span class="dv">5</span>] <span class="op">/</span> <span class="fl">255.</span>, x_test <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb80-5"><a href="#cb80-5"></a>y_train <span class="op">=</span> y_train[::<span class="dv">5</span>]</span>
<span id="cb80-6"><a href="#cb80-6"></a></span>
<span id="cb80-7"><a href="#cb80-7"></a>CLASS_NAMES <span class="op">=</span> [<span class="st">"airplane"</span>, <span class="st">"automobile"</span>, <span class="st">"bird"</span>, <span class="st">"cat"</span>,</span>
<span id="cb80-8"><a href="#cb80-8"></a>               <span class="st">"deer"</span>, <span class="st">"dog"</span>, <span class="st">"frog"</span>, <span class="st">"horse"</span>, <span class="st">"ship"</span>, <span class="st">"truck"</span>]</span>
<span id="cb80-9"><a href="#cb80-9"></a></span>
<span id="cb80-10"><a href="#cb80-10"></a><span class="bu">print</span>(<span class="st">'Shape of x_train: '</span>, x_train.shape)</span>
<span id="cb80-11"><a href="#cb80-11"></a><span class="bu">print</span>(<span class="st">'Shape of y_train: '</span>, y_train.shape)</span>
<span id="cb80-12"><a href="#cb80-12"></a><span class="bu">print</span>(<span class="st">'Shape of x_test: '</span>, x_test.shape)</span>
<span id="cb80-13"><a href="#cb80-13"></a><span class="bu">print</span>(<span class="st">'Shape of y_test: '</span>, y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of x_train:  (10000, 32, 32, 3)
Shape of y_train:  (10000, 1)
Shape of x_test:  (10000, 32, 32, 3)
Shape of y_test:  (10000, 1)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1"></a><span class="kw">def</span> Model():</span>
<span id="cb82-2"><a href="#cb82-2"></a>    inputs <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>))</span>
<span id="cb82-3"><a href="#cb82-3"></a>    </span>
<span id="cb82-4"><a href="#cb82-4"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(filters<span class="op">=</span><span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb82-5"><a href="#cb82-5"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(filters<span class="op">=</span><span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb82-6"><a href="#cb82-6"></a>    x <span class="op">=</span> tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span><span class="dv">2</span>)(x)</span>
<span id="cb82-7"><a href="#cb82-7"></a>    </span>
<span id="cb82-8"><a href="#cb82-8"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(filters<span class="op">=</span><span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb82-9"><a href="#cb82-9"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(filters<span class="op">=</span><span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb82-10"><a href="#cb82-10"></a>    </span>
<span id="cb82-11"><a href="#cb82-11"></a>    x <span class="op">=</span> tf.keras.layers.GlobalAveragePooling2D()(x)</span>
<span id="cb82-12"><a href="#cb82-12"></a>    </span>
<span id="cb82-13"><a href="#cb82-13"></a>    x <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb82-14"><a href="#cb82-14"></a>    x <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb82-15"><a href="#cb82-15"></a>    </span>
<span id="cb82-16"><a href="#cb82-16"></a>    outputs <span class="op">=</span> tf.keras.layers.Dense(<span class="bu">len</span>(CLASS_NAMES), activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb82-17"><a href="#cb82-17"></a>    </span>
<span id="cb82-18"><a href="#cb82-18"></a>    <span class="cf">return</span> tf.keras.models.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="give-wandb.init-your-config" class="level4" data-number="13.5.1.1">
<h4 data-number="13.5.1.1" class="anchored" data-anchor-id="give-wandb.init-your-config"><span class="header-section-number">13.5.1.1</span> Give <code>wandb.init()</code> your <code>config</code></h4>
<p>We first initialize our <code>wandb</code> run, letting W&amp;B know some training is about to happen. <a href="https://docs.wandb.com/library/init">Check the official documentation for <code>.init</code> here</a></p>
<p>That’s when we need to set our hyperparameters. They’re passed in as a dictionary via the <code>config</code> argument, and then become available as the <code>config</code> attribute of <code>wandb</code>. Learn more about <code>config</code> in this <a href="http://wandb.me/config-colab">Colab Notebook</a></p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3286,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684911316278,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="d8ae2ca5-7050-4dba-f1ff-60afdac24535">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1"></a><span class="co"># Initialize wandb with your project name</span></span>
<span id="cb83-2"><a href="#cb83-2"></a>run <span class="op">=</span> wandb.init(project<span class="op">=</span><span class="st">'my-keras-project'</span>,</span>
<span id="cb83-3"><a href="#cb83-3"></a>                 config<span class="op">=</span>{  <span class="co"># and include hyperparameters and metadata</span></span>
<span id="cb83-4"><a href="#cb83-4"></a>                     <span class="st">"learning_rate"</span>: <span class="fl">0.005</span>,</span>
<span id="cb83-5"><a href="#cb83-5"></a>                     <span class="st">"epochs"</span>: <span class="dv">5</span>,</span>
<span id="cb83-6"><a href="#cb83-6"></a>                     <span class="st">"batch_size"</span>: <span class="dv">1024</span>,</span>
<span id="cb83-7"><a href="#cb83-7"></a>                     <span class="st">"loss_function"</span>: <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb83-8"><a href="#cb83-8"></a>                     <span class="st">"architecture"</span>: <span class="st">"CNN"</span>,</span>
<span id="cb83-9"><a href="#cb83-9"></a>                     <span class="st">"dataset"</span>: <span class="st">"CIFAR-10"</span></span>
<span id="cb83-10"><a href="#cb83-10"></a>                 })</span>
<span id="cb83-11"><a href="#cb83-11"></a>config <span class="op">=</span> wandb.config  <span class="co"># We'll use this to configure our experiment</span></span>
<span id="cb83-12"><a href="#cb83-12"></a></span>
<span id="cb83-13"><a href="#cb83-13"></a><span class="co"># Initialize model like you usually do.</span></span>
<span id="cb83-14"><a href="#cb83-14"></a>tf.keras.backend.clear_session()</span>
<span id="cb83-15"><a href="#cb83-15"></a>model <span class="op">=</span> Model()</span>
<span id="cb83-16"><a href="#cb83-16"></a>model.summary()</span>
<span id="cb83-17"><a href="#cb83-17"></a></span>
<span id="cb83-18"><a href="#cb83-18"></a><span class="co"># Compile model like you usually do.</span></span>
<span id="cb83-19"><a href="#cb83-19"></a><span class="co"># Notice that we use config, so our metadata matches what gets executed</span></span>
<span id="cb83-20"><a href="#cb83-20"></a>optimizer <span class="op">=</span> tf.keras.optimizers.Adam(config.learning_rate) </span>
<span id="cb83-21"><a href="#cb83-21"></a>model.<span class="bu">compile</span>(optimizer, config.loss_function, metrics<span class="op">=</span>[<span class="st">'acc'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Currently logged in as: phonchi. Use `wandb login --relogin` to force relogin</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230524_065507-y7peyypu</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/my-keras-project/runs/y7peyypu" target="_blank">cool-spaceship-1</a></strong> to <a href="https://wandb.ai/phonchi/my-keras-project" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/my-keras-project" target="_blank">https://wandb.ai/phonchi/my-keras-project</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/my-keras-project/runs/y7peyypu" target="_blank">https://wandb.ai/phonchi/my-keras-project/runs/y7peyypu</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 32, 32, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 30, 30, 32)        896       
                                                                 
 conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         
 )                                                               
                                                                 
 conv2d_2 (Conv2D)           (None, 12, 12, 32)        9248      
                                                                 
 conv2d_3 (Conv2D)           (None, 10, 10, 32)        9248      
                                                                 
 global_average_pooling2d (G  (None, 32)               0         
 lobalAveragePooling2D)                                          
                                                                 
 dense (Dense)               (None, 128)               4224      
                                                                 
 dense_1 (Dense)             (None, 32)                4128      
                                                                 
 dense_2 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 37,322
Trainable params: 37,322
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
</section>
<section id="pass-wandbmetricslogger-and-wandbmodelcheckpoint-to-model.fit" class="level4" data-number="13.5.1.2">
<h4 data-number="13.5.1.2" class="anchored"><span class="header-section-number">13.5.1.2</span> Pass <code>WandbMetricsLogger</code> and <code>WandbModelCheckpoint</code> to <code>model.fit()</code></h4>
<p>Keras has a <a href="https://keras.io/api/callbacks/">robust callbacks system</a> that allows users to separate model definition and the core training logic from other behaviors that occur during training and testing.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:21354,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684911423000,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="95c042f5-e4ed-4a5d-fd2b-e491c4f8b1b6">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1"></a><span class="co"># Add WandbMetricsLogger to log metrics and WandbModelCheckpoint to log model checkpoints</span></span>
<span id="cb86-2"><a href="#cb86-2"></a>wandb_callbacks <span class="op">=</span> [</span>
<span id="cb86-3"><a href="#cb86-3"></a>    WandbMetricsLogger(),</span>
<span id="cb86-4"><a href="#cb86-4"></a>    WandbModelCheckpoint(filepath<span class="op">=</span><span class="st">"my_model_</span><span class="sc">{epoch:02d}</span><span class="st">"</span>),</span>
<span id="cb86-5"><a href="#cb86-5"></a>]</span>
<span id="cb86-6"><a href="#cb86-6"></a></span>
<span id="cb86-7"><a href="#cb86-7"></a>model.fit(x_train, y_train,</span>
<span id="cb86-8"><a href="#cb86-8"></a>          epochs<span class="op">=</span>config.epochs, </span>
<span id="cb86-9"><a href="#cb86-9"></a>          batch_size<span class="op">=</span>config.batch_size,</span>
<span id="cb86-10"><a href="#cb86-10"></a>          validation_data<span class="op">=</span>(x_test, y_test),</span>
<span id="cb86-11"><a href="#cb86-11"></a>          callbacks<span class="op">=</span>wandb_callbacks)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
10/10 [==============================] - ETA: 0s - loss: 2.2830 - acc: 0.1079</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 8s 429ms/step - loss: 2.2830 - acc: 0.1079 - val_loss: 2.2013 - val_acc: 0.1579
Epoch 2/5
10/10 [==============================] - ETA: 0s - loss: 2.2821 - acc: 0.1239</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_02)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 2s 201ms/step - loss: 2.2821 - acc: 0.1239 - val_loss: 2.3022 - val_acc: 0.1023
Epoch 3/5
 9/10 [==========================&gt;...] - ETA: 0s - loss: 2.2968 - acc: 0.1159</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_03)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 4s 425ms/step - loss: 2.2951 - acc: 0.1151 - val_loss: 2.2644 - val_acc: 0.1002
Epoch 4/5
 9/10 [==========================&gt;...] - ETA: 0s - loss: 2.2085 - acc: 0.1336</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_04)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 4s 450ms/step - loss: 2.2064 - acc: 0.1388 - val_loss: 2.1812 - val_acc: 0.1477
Epoch 5/5
 9/10 [==========================&gt;...] - ETA: 0s - loss: 2.1471 - acc: 0.1798</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_05)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 3s 274ms/step - loss: 2.1420 - acc: 0.1820 - val_loss: 2.0732 - val_acc: 0.2106</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="117">
<pre><code>&lt;keras.callbacks.History at 0x7f8d4034b310&gt;</code></pre>
</div>
</div>
<p>We can use <code>wandb.log()</code> to add custom metrics. Here, we log the error rate on the test set.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:7521,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684911473031,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="b509292f-0c2d-4872-e260-e13f3d4c6cbb">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1"></a>loss, accuracy <span class="op">=</span> model.evaluate(x_test, y_test)</span>
<span id="cb99-2"><a href="#cb99-2"></a><span class="bu">print</span>(<span class="st">'Test Error Rate: '</span>, <span class="bu">round</span>((<span class="dv">1</span> <span class="op">-</span> accuracy) <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>))</span>
<span id="cb99-3"><a href="#cb99-3"></a></span>
<span id="cb99-4"><a href="#cb99-4"></a><span class="co"># With wandb.log, we can easily pass in metrics as key-value pairs.</span></span>
<span id="cb99-5"><a href="#cb99-5"></a>wandb.log({<span class="st">'Test Error Rate'</span>: <span class="bu">round</span>((<span class="dv">1</span> <span class="op">-</span> accuracy) <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)})</span>
<span id="cb99-6"><a href="#cb99-6"></a></span>
<span id="cb99-7"><a href="#cb99-7"></a>run.finish()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 [==============================] - 1s 3ms/step - loss: 2.0732 - acc: 0.2106
Test Error Rate:  78.94</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored" data-anchor-id="pass-wandbmetricslogger-and-wandbmodelcheckpoint-to-model.fit">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>Test Error Rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/acc</td>
<td>▁▃▂▄█</td>
</tr>
<tr class="odd">
<td>epoch/epoch</td>
<td>▁▃▅▆█</td>
</tr>
<tr class="even">
<td>epoch/learning_rate</td>
<td>▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/loss</td>
<td>▇▇█▄▁</td>
</tr>
<tr class="even">
<td>epoch/val_acc</td>
<td>▅▁▁▄█</td>
</tr>
<tr class="odd">
<td>epoch/val_loss</td>
<td>▅█▇▄▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.2">
<h3 data-number="13.5.2" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.2</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>Test Error Rate</td>
<td>78.94</td>
</tr>
<tr class="even">
<td>epoch/acc</td>
<td>0.182</td>
</tr>
<tr class="odd">
<td>epoch/epoch</td>
<td>4</td>
</tr>
<tr class="even">
<td>epoch/learning_rate</td>
<td>0.005</td>
</tr>
<tr class="odd">
<td>epoch/loss</td>
<td>2.14203</td>
</tr>
<tr class="even">
<td>epoch/val_acc</td>
<td>0.2106</td>
</tr>
<tr class="odd">
<td>epoch/val_loss</td>
<td>2.0732</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">cool-spaceship-1</strong> at: <a href="https://wandb.ai/phonchi/my-keras-project/runs/y7peyypu" target="_blank">https://wandb.ai/phonchi/my-keras-project/runs/y7peyypu</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 25 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_065507-y7peyypu/logs</code>
</div>
</div>
</section>
</section>
<section id="log-predictions-on-test-data-using-wandbevalcallback" class="level3" data-number="13.5.3">
<h3 data-number="13.5.3" class="anchored" data-anchor-id="log-predictions-on-test-data-using-wandbevalcallback"><span class="header-section-number">13.5.3</span> Log predictions on test data using <code>WandbEvalCallback</code></h3>
<p>The <code>WandbEvalCallback</code> is an abstract base class to build <code>Keras</code> callbacks for primarily <strong>model prediction visualization and secondarily dataset visualization</strong>.</p>
<p>This is a dataset and task agnostic abstract callback. To use this, inherit from this base callback class and implement the <code>add_ground_truth</code> and <code>add_model_prediction</code> methods. The <code>WandbEvalCallback</code> is a utility class that provides helpful methods to:</p>
<ul>
<li>create data and prediction <code>wandb.Table</code> instances,</li>
<li>log data and prediction Tables as <code>wandb.Artifact</code>,</li>
<li>logs the data table <code>on_train_begin</code>,</li>
<li>logs the prediction table <code>on_epoch_end</code>.</li>
</ul>
<p>As an example, we have implemented <code>WandbClsEvalCallback</code> below for an image classification task. This example callback: - logs the validation data (<code>data_table</code>) to W&amp;B, - performs inference and logs the prediction (<code>pred_table</code>) to W&amp;B on every epoch end.</p>
<p>We log the <code>data_table</code> to W&amp;B when the <code>on_train_begin</code> method is ivoked. Once it’s uploaded as a W&amp;B Artifact, we get a reference to this table which can be accessed using <code>data_table_ref</code> class variable. The <code>data_table_ref</code> is a 2D list that can be indexed like <code>self.data_table_ref[idx][n]</code> where <code>idx</code> is the row number while <code>n</code> is the column number. Let’s see the usage in the example below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1"></a><span class="kw">class</span> WandbClsEvalCallback(WandbEvalCallback):</span>
<span id="cb101-2"><a href="#cb101-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb101-3"><a href="#cb101-3"></a>        <span class="va">self</span>, validloader, data_table_columns, pred_table_columns, num_samples<span class="op">=</span><span class="dv">100</span></span>
<span id="cb101-4"><a href="#cb101-4"></a>    ):</span>
<span id="cb101-5"><a href="#cb101-5"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(data_table_columns, pred_table_columns)</span>
<span id="cb101-6"><a href="#cb101-6"></a></span>
<span id="cb101-7"><a href="#cb101-7"></a>        <span class="va">self</span>.val_data <span class="op">=</span> validloader.unbatch().take(num_samples)</span>
<span id="cb101-8"><a href="#cb101-8"></a></span>
<span id="cb101-9"><a href="#cb101-9"></a>    <span class="kw">def</span> add_ground_truth(<span class="va">self</span>, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb101-10"><a href="#cb101-10"></a>        <span class="cf">for</span> idx, (image, label) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.val_data):</span>
<span id="cb101-11"><a href="#cb101-11"></a>            <span class="va">self</span>.data_table.add_data(</span>
<span id="cb101-12"><a href="#cb101-12"></a>                idx,</span>
<span id="cb101-13"><a href="#cb101-13"></a>                wandb.Image(image),</span>
<span id="cb101-14"><a href="#cb101-14"></a>                np.argmax(label, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb101-15"><a href="#cb101-15"></a>            )</span>
<span id="cb101-16"><a href="#cb101-16"></a></span>
<span id="cb101-17"><a href="#cb101-17"></a>    <span class="kw">def</span> add_model_predictions(<span class="va">self</span>, epoch, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb101-18"><a href="#cb101-18"></a>        <span class="co"># Get predictions</span></span>
<span id="cb101-19"><a href="#cb101-19"></a>        preds <span class="op">=</span> <span class="va">self</span>._inference()</span>
<span id="cb101-20"><a href="#cb101-20"></a>        table_idxs <span class="op">=</span> <span class="va">self</span>.data_table_ref.get_index()</span>
<span id="cb101-21"><a href="#cb101-21"></a></span>
<span id="cb101-22"><a href="#cb101-22"></a>        <span class="cf">for</span> idx <span class="kw">in</span> table_idxs:</span>
<span id="cb101-23"><a href="#cb101-23"></a>            pred <span class="op">=</span> preds[idx]</span>
<span id="cb101-24"><a href="#cb101-24"></a>            <span class="va">self</span>.pred_table.add_data(</span>
<span id="cb101-25"><a href="#cb101-25"></a>                epoch,</span>
<span id="cb101-26"><a href="#cb101-26"></a>                <span class="va">self</span>.data_table_ref.data[idx][<span class="dv">0</span>],</span>
<span id="cb101-27"><a href="#cb101-27"></a>                <span class="va">self</span>.data_table_ref.data[idx][<span class="dv">1</span>],</span>
<span id="cb101-28"><a href="#cb101-28"></a>                <span class="va">self</span>.data_table_ref.data[idx][<span class="dv">2</span>],</span>
<span id="cb101-29"><a href="#cb101-29"></a>                pred</span>
<span id="cb101-30"><a href="#cb101-30"></a>            )</span>
<span id="cb101-31"><a href="#cb101-31"></a></span>
<span id="cb101-32"><a href="#cb101-32"></a>    <span class="kw">def</span> _inference(<span class="va">self</span>):</span>
<span id="cb101-33"><a href="#cb101-33"></a>        preds <span class="op">=</span> []</span>
<span id="cb101-34"><a href="#cb101-34"></a>        <span class="cf">for</span> image, label <span class="kw">in</span> <span class="va">self</span>.val_data:</span>
<span id="cb101-35"><a href="#cb101-35"></a>            pred <span class="op">=</span> <span class="va">self</span>.model(tf.expand_dims(image, axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb101-36"><a href="#cb101-36"></a>            argmax_pred <span class="op">=</span> tf.argmax(pred, axis<span class="op">=-</span><span class="dv">1</span>).numpy()[<span class="dv">0</span>]</span>
<span id="cb101-37"><a href="#cb101-37"></a>            preds.append(argmax_pred)</span>
<span id="cb101-38"><a href="#cb101-38"></a>          </span>
<span id="cb101-39"><a href="#cb101-39"></a>        <span class="cf">return</span> preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create Dataset processing, Dataloaders functions and the model</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1"></a>AUTOTUNE <span class="op">=</span> tf.data.AUTOTUNE</span>
<span id="cb102-2"><a href="#cb102-2"></a></span>
<span id="cb102-3"><a href="#cb102-3"></a><span class="kw">def</span> parse_data(example):</span>
<span id="cb102-4"><a href="#cb102-4"></a>    <span class="co"># Get image</span></span>
<span id="cb102-5"><a href="#cb102-5"></a>    image <span class="op">=</span> example[<span class="st">"image"</span>]</span>
<span id="cb102-6"><a href="#cb102-6"></a>    <span class="co"># Get label</span></span>
<span id="cb102-7"><a href="#cb102-7"></a>    label <span class="op">=</span> example[<span class="st">"label"</span>]</span>
<span id="cb102-8"><a href="#cb102-8"></a>    label <span class="op">=</span> tf.one_hot(label, depth<span class="op">=</span>configs[<span class="st">"num_classes"</span>])</span>
<span id="cb102-9"><a href="#cb102-9"></a></span>
<span id="cb102-10"><a href="#cb102-10"></a>    <span class="cf">return</span> image, label</span>
<span id="cb102-11"><a href="#cb102-11"></a></span>
<span id="cb102-12"><a href="#cb102-12"></a></span>
<span id="cb102-13"><a href="#cb102-13"></a><span class="kw">def</span> get_dataloader(ds, configs, dataloader_type<span class="op">=</span><span class="st">"train"</span>):</span>
<span id="cb102-14"><a href="#cb102-14"></a>    dataloader <span class="op">=</span> ds.<span class="bu">map</span>(parse_data, num_parallel_calls<span class="op">=</span>AUTOTUNE)</span>
<span id="cb102-15"><a href="#cb102-15"></a></span>
<span id="cb102-16"><a href="#cb102-16"></a>    <span class="cf">if</span> dataloader_type<span class="op">==</span><span class="st">"train"</span>:</span>
<span id="cb102-17"><a href="#cb102-17"></a>        dataloader <span class="op">=</span> dataloader.shuffle(configs[<span class="st">"shuffle_buffer"</span>])</span>
<span id="cb102-18"><a href="#cb102-18"></a>      </span>
<span id="cb102-19"><a href="#cb102-19"></a>    dataloader <span class="op">=</span> (</span>
<span id="cb102-20"><a href="#cb102-20"></a>        dataloader</span>
<span id="cb102-21"><a href="#cb102-21"></a>        .batch(configs[<span class="st">"batch_size"</span>])</span>
<span id="cb102-22"><a href="#cb102-22"></a>        .prefetch(AUTOTUNE)</span>
<span id="cb102-23"><a href="#cb102-23"></a>    )</span>
<span id="cb102-24"><a href="#cb102-24"></a></span>
<span id="cb102-25"><a href="#cb102-25"></a>    <span class="cf">return</span> dataloader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1"></a><span class="kw">def</span> get_model(configs):</span>
<span id="cb103-2"><a href="#cb103-2"></a>    backbone <span class="op">=</span> tf.keras.applications.mobilenet_v2.MobileNetV2(weights<span class="op">=</span><span class="st">'imagenet'</span>, include_top<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb103-3"><a href="#cb103-3"></a>    backbone.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb103-4"><a href="#cb103-4"></a></span>
<span id="cb103-5"><a href="#cb103-5"></a>    inputs <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>(configs[<span class="st">"image_size"</span>], configs[<span class="st">"image_size"</span>], configs[<span class="st">"image_channels"</span>]))</span>
<span id="cb103-6"><a href="#cb103-6"></a>    resize <span class="op">=</span> tf.keras.layers.Resizing(<span class="dv">32</span>, <span class="dv">32</span>)(inputs)</span>
<span id="cb103-7"><a href="#cb103-7"></a>    neck <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">3</span>, (<span class="dv">3</span>,<span class="dv">3</span>), padding<span class="op">=</span><span class="st">"same"</span>)(resize)</span>
<span id="cb103-8"><a href="#cb103-8"></a>    preprocess_input <span class="op">=</span> tf.keras.applications.mobilenet.preprocess_input(neck)</span>
<span id="cb103-9"><a href="#cb103-9"></a>    x <span class="op">=</span> backbone(preprocess_input)</span>
<span id="cb103-10"><a href="#cb103-10"></a>    x <span class="op">=</span> tf.keras.layers.GlobalAveragePooling2D()(x)</span>
<span id="cb103-11"><a href="#cb103-11"></a>    outputs <span class="op">=</span> tf.keras.layers.Dense(configs[<span class="st">"num_classes"</span>], activation<span class="op">=</span><span class="st">"softmax"</span>)(x)</span>
<span id="cb103-12"><a href="#cb103-12"></a></span>
<span id="cb103-13"><a href="#cb103-13"></a>    <span class="cf">return</span> tf.keras.models.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Set the config for the fashion MNIST dataset.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:76913,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684912043169,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="0958ecfe-9eb3-4a7e-800c-7afd4185ac4f">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1"></a>train_ds, valid_ds <span class="op">=</span> tfds.load(<span class="st">'fashion_mnist'</span>, split<span class="op">=</span>[<span class="st">'train'</span>, <span class="st">'test'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /root/tensorflow_datasets/fashion_mnist/3.0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"211c719f5e6342a3bce47d9e4535378d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"de281196308d45378139e9fcc8ca6819","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a1f127b23fe04ed1a5bb0f6205298c21","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"07c40fa86a384d24bb7f27cb6b7509b8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8797169c11ff4d7b91587933b9afb0a8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5a34a09c1ec144559292d99e2b90048d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"df4e9c9fc9b3427ab8b28c690225b4d1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"75dc88473ac14be1bc877135afc2df2f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset fashion_mnist downloaded and prepared to /root/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1"></a>configs <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb107-2"><a href="#cb107-2"></a>    num_classes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb107-3"><a href="#cb107-3"></a>    shuffle_buffer <span class="op">=</span> <span class="dv">1024</span>,</span>
<span id="cb107-4"><a href="#cb107-4"></a>    batch_size <span class="op">=</span> <span class="dv">64</span>,</span>
<span id="cb107-5"><a href="#cb107-5"></a>    image_size <span class="op">=</span> <span class="dv">28</span>,</span>
<span id="cb107-6"><a href="#cb107-6"></a>    image_channels <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb107-7"><a href="#cb107-7"></a>    earlystopping_patience <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb107-8"><a href="#cb107-8"></a>    learning_rate <span class="op">=</span> <span class="fl">1e-3</span>,</span>
<span id="cb107-9"><a href="#cb107-9"></a>    epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb107-10"><a href="#cb107-10"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1"></a>trainloader <span class="op">=</span> get_dataloader(train_ds, configs)</span>
<span id="cb108-2"><a href="#cb108-2"></a>validloader <span class="op">=</span> get_dataloader(valid_ds, configs, dataloader_type<span class="op">=</span><span class="st">"valid"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3344,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684912063801,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="5ca32e0b-91d6-41dc-e77d-4d6bbe34313b">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1"></a>tf.keras.backend.clear_session()</span>
<span id="cb109-2"><a href="#cb109-2"></a>model <span class="op">=</span> get_model(configs)</span>
<span id="cb109-3"><a href="#cb109-3"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5
9406464/9406464 [==============================] - 0s 0us/step
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 28, 28, 1)]       0         
                                                                 
 resizing (Resizing)         (None, 32, 32, 1)         0         
                                                                 
 conv2d (Conv2D)             (None, 32, 32, 3)         30        
                                                                 
 tf.math.truediv (TFOpLambda  (None, 32, 32, 3)        0         
 )                                                               
                                                                 
 tf.math.subtract (TFOpLambd  (None, 32, 32, 3)        0         
 a)                                                              
                                                                 
 mobilenetv2_1.00_224 (Funct  (None, None, None, 1280)  2257984  
 ional)                                                          
                                                                 
 global_average_pooling2d (G  (None, 1280)             0         
 lobalAveragePooling2D)                                          
                                                                 
 dense (Dense)               (None, 10)                12810     
                                                                 
=================================================================
Total params: 2,270,824
Trainable params: 12,840
Non-trainable params: 2,257,984
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb112-2"><a href="#cb112-2"></a>    optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span id="cb112-3"><a href="#cb112-3"></a>    loss <span class="op">=</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span id="cb112-4"><a href="#cb112-4"></a>    metrics <span class="op">=</span> [<span class="st">"accuracy"</span>, tf.keras.metrics.TopKCategoricalAccuracy(k<span class="op">=</span><span class="dv">5</span>, name<span class="op">=</span><span class="st">'top@5_accuracy'</span>)]</span>
<span id="cb112-5"><a href="#cb112-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="train-the-model-and-log-the-predictions-to-a-wb-table" class="level4" data-number="13.5.3.1">
<h4 data-number="13.5.3.1" class="anchored"><span class="header-section-number">13.5.3.1</span> Train the model and log the predictions to a W&amp;B Table</h4>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:619567,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684912688359,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="1d37688f-63d1-4e25-eb7a-b9d1387bde67">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1"></a><span class="co"># Initialize a W&amp;B run</span></span>
<span id="cb113-2"><a href="#cb113-2"></a>run <span class="op">=</span> wandb.init(</span>
<span id="cb113-3"><a href="#cb113-3"></a>    project <span class="op">=</span> <span class="st">"my-keras-project"</span>,</span>
<span id="cb113-4"><a href="#cb113-4"></a>    config <span class="op">=</span> configs</span>
<span id="cb113-5"><a href="#cb113-5"></a>)</span>
<span id="cb113-6"><a href="#cb113-6"></a></span>
<span id="cb113-7"><a href="#cb113-7"></a>wandb_callbacks <span class="op">=</span> [</span>
<span id="cb113-8"><a href="#cb113-8"></a>        WandbMetricsLogger(log_freq<span class="op">=</span><span class="dv">10</span>),</span>
<span id="cb113-9"><a href="#cb113-9"></a>        WandbModelCheckpoint(filepath<span class="op">=</span><span class="st">"my_model_</span><span class="sc">{epoch:02d}</span><span class="st">"</span>),</span>
<span id="cb113-10"><a href="#cb113-10"></a>        WandbClsEvalCallback(</span>
<span id="cb113-11"><a href="#cb113-11"></a>            validloader,</span>
<span id="cb113-12"><a href="#cb113-12"></a>            data_table_columns<span class="op">=</span>[<span class="st">"idx"</span>, <span class="st">"image"</span>, <span class="st">"ground_truth"</span>],</span>
<span id="cb113-13"><a href="#cb113-13"></a>            pred_table_columns<span class="op">=</span>[<span class="st">"epoch"</span>, <span class="st">"idx"</span>, <span class="st">"image"</span>, <span class="st">"ground_truth"</span>, <span class="st">"prediction"</span>]</span>
<span id="cb113-14"><a href="#cb113-14"></a>        ) </span>
<span id="cb113-15"><a href="#cb113-15"></a>    ]</span>
<span id="cb113-16"><a href="#cb113-16"></a></span>
<span id="cb113-17"><a href="#cb113-17"></a><span class="co"># Train your model</span></span>
<span id="cb113-18"><a href="#cb113-18"></a>model.fit(</span>
<span id="cb113-19"><a href="#cb113-19"></a>    trainloader,</span>
<span id="cb113-20"><a href="#cb113-20"></a>    epochs <span class="op">=</span> configs[<span class="st">"epochs"</span>],</span>
<span id="cb113-21"><a href="#cb113-21"></a>    validation_data <span class="op">=</span> validloader,</span>
<span id="cb113-22"><a href="#cb113-22"></a>    callbacks <span class="op">=</span> wandb_callbacks</span>
<span id="cb113-23"><a href="#cb113-23"></a>)</span>
<span id="cb113-24"><a href="#cb113-24"></a></span>
<span id="cb113-25"><a href="#cb113-25"></a><span class="co"># Close the W&amp;B run</span></span>
<span id="cb113-26"><a href="#cb113-26"></a>run.finish()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230524_070743-oy7pezpd</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/my-keras-project/runs/oy7pezpd" target="_blank">faithful-yogurt-2</a></strong> to <a href="https://wandb.ai/phonchi/my-keras-project" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/my-keras-project" target="_blank">https://wandb.ai/phonchi/my-keras-project</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/my-keras-project/runs/oy7pezpd" target="_blank">https://wandb.ai/phonchi/my-keras-project/runs/oy7pezpd</a>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb:   101 of 101 files downloaded.  </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
938/938 [==============================] - ETA: 0s - loss: 1.4748 - accuracy: 0.5377 - top@5_accuracy: 0.9332</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 63s 62ms/step - loss: 1.4748 - accuracy: 0.5377 - top@5_accuracy: 0.9332 - val_loss: 1.1581 - val_accuracy: 0.6125 - val_top@5_accuracy: 0.9697
Epoch 2/10
935/938 [============================&gt;.] - ETA: 0s - loss: 1.0646 - accuracy: 0.6415 - top@5_accuracy: 0.9733</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_02)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 48s 51ms/step - loss: 1.0645 - accuracy: 0.6415 - top@5_accuracy: 0.9733 - val_loss: 1.0253 - val_accuracy: 0.6412 - val_top@5_accuracy: 0.9737
Epoch 3/10
936/938 [============================&gt;.] - ETA: 0s - loss: 0.9811 - accuracy: 0.6626 - top@5_accuracy: 0.9757</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_03)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 50s 53ms/step - loss: 0.9809 - accuracy: 0.6627 - top@5_accuracy: 0.9757 - val_loss: 0.9748 - val_accuracy: 0.6609 - val_top@5_accuracy: 0.9755
Epoch 4/10
935/938 [============================&gt;.] - ETA: 0s - loss: 0.9414 - accuracy: 0.6719 - top@5_accuracy: 0.9777</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_04)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 49s 52ms/step - loss: 0.9414 - accuracy: 0.6720 - top@5_accuracy: 0.9777 - val_loss: 0.9463 - val_accuracy: 0.6672 - val_top@5_accuracy: 0.9782
Epoch 5/10
937/938 [============================&gt;.] - ETA: 0s - loss: 0.9164 - accuracy: 0.6802 - top@5_accuracy: 0.9794</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_05)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 53s 56ms/step - loss: 0.9164 - accuracy: 0.6802 - top@5_accuracy: 0.9794 - val_loss: 0.9290 - val_accuracy: 0.6730 - val_top@5_accuracy: 0.9796
Epoch 6/10
938/938 [==============================] - ETA: 0s - loss: 0.8988 - accuracy: 0.6862 - top@5_accuracy: 0.9799</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_06)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 49s 52ms/step - loss: 0.8988 - accuracy: 0.6862 - top@5_accuracy: 0.9799 - val_loss: 0.9072 - val_accuracy: 0.6822 - val_top@5_accuracy: 0.9799
Epoch 7/10
938/938 [==============================] - ETA: 0s - loss: 0.8845 - accuracy: 0.6912 - top@5_accuracy: 0.9803</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_07)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 50s 53ms/step - loss: 0.8845 - accuracy: 0.6912 - top@5_accuracy: 0.9803 - val_loss: 0.9122 - val_accuracy: 0.6801 - val_top@5_accuracy: 0.9792
Epoch 8/10
937/938 [============================&gt;.] - ETA: 0s - loss: 0.8766 - accuracy: 0.6923 - top@5_accuracy: 0.9814</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_08)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 51s 54ms/step - loss: 0.8766 - accuracy: 0.6923 - top@5_accuracy: 0.9814 - val_loss: 0.8987 - val_accuracy: 0.6842 - val_top@5_accuracy: 0.9795
Epoch 9/10
938/938 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.6953 - top@5_accuracy: 0.9815</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_09)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 51s 55ms/step - loss: 0.8687 - accuracy: 0.6953 - top@5_accuracy: 0.9815 - val_loss: 0.8967 - val_accuracy: 0.6876 - val_top@5_accuracy: 0.9802
Epoch 10/10
936/938 [============================&gt;.] - ETA: 0s - loss: 0.8632 - accuracy: 0.6976 - top@5_accuracy: 0.9819</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_10)... Done. 0.1s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 49s 52ms/step - loss: 0.8632 - accuracy: 0.6976 - top@5_accuracy: 0.9819 - val_loss: 0.8845 - val_accuracy: 0.6908 - val_top@5_accuracy: 0.9799</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e4bdc4b02c8b416ca6b0ab9b2572a145","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored" data-anchor-id="train-the-model-and-log-the-predictions-to-a-wb-table">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▃▄▅▇▇▇▇█▇▇▇████████████████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>█▇▆▅▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>batch/top@5_accuracy</td>
<td>▁▄▆▆████████████████████████████████████</td>
</tr>
<tr class="even">
<td>epoch/accuracy</td>
<td>▁▆▆▇▇█████</td>
</tr>
<tr class="odd">
<td>epoch/epoch</td>
<td>▁▂▃▃▄▅▆▆▇█</td>
</tr>
<tr class="even">
<td>epoch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/loss</td>
<td>█▃▂▂▂▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>epoch/top@5_accuracy</td>
<td>▁▇▇▇██████</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁▄▅▆▆▇▇▇██</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>█▅▃▃▂▂▂▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/val_top@5_accuracy</td>
<td>▁▄▅▇██▇███</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.4">
<h3 data-number="13.5.4" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.4</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.69742</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>9390</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.001</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.8639</td>
</tr>
<tr class="odd">
<td>batch/top@5_accuracy</td>
<td>0.98187</td>
</tr>
<tr class="even">
<td>epoch/accuracy</td>
<td>0.69758</td>
</tr>
<tr class="odd">
<td>epoch/epoch</td>
<td>9</td>
</tr>
<tr class="even">
<td>epoch/learning_rate</td>
<td>0.001</td>
</tr>
<tr class="odd">
<td>epoch/loss</td>
<td>0.86324</td>
</tr>
<tr class="even">
<td>epoch/top@5_accuracy</td>
<td>0.98192</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.6908</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.88455</td>
</tr>
<tr class="odd">
<td>epoch/val_top@5_accuracy</td>
<td>0.9799</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">faithful-yogurt-2</strong> at: <a href="https://wandb.ai/phonchi/my-keras-project/runs/oy7pezpd" target="_blank">https://wandb.ai/phonchi/my-keras-project/runs/oy7pezpd</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 161 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_070743-oy7pezpd/logs</code>
</div>
</div>
<p>We can see a table from our database as follows:</p>
<p align="center">
<img src="https://drive.google.com/uc?id=1zftkBrPAg9pulQYcHhcSUKFxakhBBUPu" alt="drawing" width="1200">
</p>
</section>
</section>
<section id="introduction-to-hyperparameter-sweeps-using-wb-and-keras" class="level3" data-number="13.5.5">
<h3 data-number="13.5.5" class="anchored" data-anchor-id="introduction-to-hyperparameter-sweeps-using-wb-and-keras"><span class="header-section-number">13.5.5</span> Introduction to Hyperparameter Sweeps using W&amp;B and <code>Keras</code></h3>
<p>Searching through high dimensional hyperparameter spaces to find the most performant model can get unwieldy very fast. Hyperparameter sweeps provide an organized and efficient way to conduct a battle royale of models and pick the most accurate model. They enable this by automatically searching through combinations of hyperparameter values (e.g.&nbsp;learning rate, batch size, number of hidden layers, optimizer type) to find the most optimal values.</p>
<section id="sweeps-an-overview" class="level4" data-number="13.5.5.1">
<h4 data-number="13.5.5.1" class="anchored" data-anchor-id="sweeps-an-overview"><span class="header-section-number">13.5.5.1</span> Sweeps: An Overview</h4>
<p>Running a hyperparameter sweep with Weights &amp; Biases is very easy. There are just 3 simple steps:</p>
<ol type="1">
<li><p><strong>Define the sweep:</strong> we do this by creating a dictionary or a <a href="https://docs.wandb.com/library/sweeps/configuration">YAML file</a> that specifies the parameters to search through, the search strategy, the optimization metric et. al.</p></li>
<li><p><strong>Initialize the sweep:</strong> with one line of code we initialize the sweep and pass in the dictionary of sweep configurations: <code>sweep_id = wandb.sweep(sweep_config)</code></p></li>
<li><p><strong>Run the sweep agent:</strong> also accomplished with one line of code, we call <code>wandb.agent()</code> and pass the <code>sweep_id</code> to run, along with a function that defines your model architecture and trains it: <code>wandb.agent(sweep_id, function=train)</code></p></li>
</ol>
<p>And voila! That’s all there is to running a hyperparameter sweep! In the notebook below, we’ll walk through these 3 steps in more detail.</p>
<p>We will use MNIST directly from <code>tf.keras.datasets</code></p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:783,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248920950,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="4c0aa59c-b879-4b40-b8a6-6659a8093710" data-execution_count="6">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1"></a><span class="co"># Get the dataset</span></span>
<span id="cb136-2"><a href="#cb136-2"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> tf.keras.datasets.mnist.load_data()</span>
<span id="cb136-3"><a href="#cb136-3"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(np.unique(y_train))</span>
<span id="cb136-4"><a href="#cb136-4"></a>input_shape <span class="op">=</span> x_train.shape[<span class="op">-</span><span class="dv">2</span>:] <span class="op">+</span> (<span class="dv">1</span>,)</span>
<span id="cb136-5"><a href="#cb136-5"></a></span>
<span id="cb136-6"><a href="#cb136-6"></a><span class="co"># Scale</span></span>
<span id="cb136-7"><a href="#cb136-7"></a>x_train <span class="op">=</span> x_train <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb136-8"><a href="#cb136-8"></a>x_test <span class="op">=</span> x_test <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb136-9"><a href="#cb136-9"></a></span>
<span id="cb136-10"><a href="#cb136-10"></a><span class="co"># Make sure images have shape (28, 28, 1)</span></span>
<span id="cb136-11"><a href="#cb136-11"></a>x_train <span class="op">=</span> np.expand_dims(x_train, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb136-12"><a href="#cb136-12"></a>x_test <span class="op">=</span> np.expand_dims(x_test, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb136-13"><a href="#cb136-13"></a></span>
<span id="cb136-14"><a href="#cb136-14"></a><span class="co"># convert class vectors to binary class matrices</span></span>
<span id="cb136-15"><a href="#cb136-15"></a>y_train <span class="op">=</span> tf.keras.utils.to_categorical(y_train, num_classes)</span>
<span id="cb136-16"><a href="#cb136-16"></a>y_test <span class="op">=</span> tf.keras.utils.to_categorical(y_test, num_classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 [==============================] - 0s 0us/step</code></pre>
</div>
</div>
<p>Define a simple model</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3342,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248927076,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="36712f22-5365-4901-dbe6-934d91e1a502" data-execution_count="7">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1"></a><span class="kw">def</span> ConvNet(dropout<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb138-2"><a href="#cb138-2"></a>    <span class="cf">return</span> tf.keras.Sequential(</span>
<span id="cb138-3"><a href="#cb138-3"></a>    [</span>
<span id="cb138-4"><a href="#cb138-4"></a>        tf.keras.Input(shape<span class="op">=</span>input_shape),</span>
<span id="cb138-5"><a href="#cb138-5"></a>        tf.keras.layers.Conv2D(<span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb138-6"><a href="#cb138-6"></a>        tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb138-7"><a href="#cb138-7"></a>        tf.keras.layers.Conv2D(<span class="dv">64</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb138-8"><a href="#cb138-8"></a>        tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb138-9"><a href="#cb138-9"></a>        tf.keras.layers.Flatten(),</span>
<span id="cb138-10"><a href="#cb138-10"></a>        tf.keras.layers.Dropout(dropout),</span>
<span id="cb138-11"><a href="#cb138-11"></a>        tf.keras.layers.Dense(num_classes, activation<span class="op">=</span><span class="st">"softmax"</span>),</span>
<span id="cb138-12"><a href="#cb138-12"></a>    ]</span>
<span id="cb138-13"><a href="#cb138-13"></a>)</span>
<span id="cb138-14"><a href="#cb138-14"></a></span>
<span id="cb138-15"><a href="#cb138-15"></a>model <span class="op">=</span> ConvNet()</span>
<span id="cb138-16"><a href="#cb138-16"></a></span>
<span id="cb138-17"><a href="#cb138-17"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 26, 26, 32)        320       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 1600)              0         
                                                                 
 dropout (Dropout)           (None, 1600)              0         
                                                                 
 dense (Dense)               (None, 10)                16010     
                                                                 
=================================================================
Total params: 34,826
Trainable params: 34,826
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<p>The training script is as follows:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:303,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248933413,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1"></a><span class="kw">def</span> get_optimizer(lr<span class="op">=</span><span class="fl">1e-3</span>, optimizer<span class="op">=</span><span class="st">"adam"</span>):</span>
<span id="cb140-2"><a href="#cb140-2"></a>    <span class="co">"Select optmizer between adam and sgd with momentum"</span></span>
<span id="cb140-3"><a href="#cb140-3"></a>    <span class="cf">if</span> optimizer.lower() <span class="op">==</span> <span class="st">"adam"</span>:</span>
<span id="cb140-4"><a href="#cb140-4"></a>        <span class="cf">return</span> tf.keras.optimizers.Adam(learning_rate<span class="op">=</span>lr)</span>
<span id="cb140-5"><a href="#cb140-5"></a>    <span class="cf">if</span> optimizer.lower() <span class="op">==</span> <span class="st">"sgd"</span>:</span>
<span id="cb140-6"><a href="#cb140-6"></a>        <span class="cf">return</span> tf.keras.optimizers.SGD(learning_rate<span class="op">=</span>lr, momentum<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb140-7"><a href="#cb140-7"></a></span>
<span id="cb140-8"><a href="#cb140-8"></a><span class="kw">def</span> train(model, batch_size<span class="op">=</span><span class="dv">64</span>, epochs<span class="op">=</span><span class="dv">10</span>, lr<span class="op">=</span><span class="fl">1e-3</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, log_freq<span class="op">=</span><span class="dv">10</span>):  </span>
<span id="cb140-9"><a href="#cb140-9"></a>    </span>
<span id="cb140-10"><a href="#cb140-10"></a>    <span class="co"># Compile model like you usually do.</span></span>
<span id="cb140-11"><a href="#cb140-11"></a>    tf.keras.backend.clear_session()</span>
<span id="cb140-12"><a href="#cb140-12"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"categorical_crossentropy"</span>, </span>
<span id="cb140-13"><a href="#cb140-13"></a>                  optimizer<span class="op">=</span>get_optimizer(lr, optimizer), </span>
<span id="cb140-14"><a href="#cb140-14"></a>                  metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb140-15"><a href="#cb140-15"></a></span>
<span id="cb140-16"><a href="#cb140-16"></a>    <span class="co"># callback setup</span></span>
<span id="cb140-17"><a href="#cb140-17"></a>    wandb_callbacks <span class="op">=</span> [</span>
<span id="cb140-18"><a href="#cb140-18"></a>        WandbMetricsLogger(log_freq<span class="op">=</span>log_freq),</span>
<span id="cb140-19"><a href="#cb140-19"></a>        WandbModelCheckpoint(filepath<span class="op">=</span><span class="st">"my_model_</span><span class="sc">{epoch:02d}</span><span class="st">"</span>)</span>
<span id="cb140-20"><a href="#cb140-20"></a>    ]</span>
<span id="cb140-21"><a href="#cb140-21"></a></span>
<span id="cb140-22"><a href="#cb140-22"></a>    model.fit(x_train, </span>
<span id="cb140-23"><a href="#cb140-23"></a>              y_train, </span>
<span id="cb140-24"><a href="#cb140-24"></a>              batch_size<span class="op">=</span>batch_size, </span>
<span id="cb140-25"><a href="#cb140-25"></a>              epochs<span class="op">=</span>epochs, </span>
<span id="cb140-26"><a href="#cb140-26"></a>              validation_data<span class="op">=</span>(x_test, y_test), </span>
<span id="cb140-27"><a href="#cb140-27"></a>              callbacks<span class="op">=</span>wandb_callbacks)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="define-the-sweep" class="level4" data-number="13.5.5.2">
<h4 data-number="13.5.5.2" class="anchored" data-anchor-id="define-the-sweep"><span class="header-section-number">13.5.5.2</span> Define the Sweep</h4>
<p>Fundamentally, a Sweep combines a strategy for trying out a bunch of hyperparameter values with the code that evalutes them. Whether that strategy is as simple as trying every option or as complex as <a href="https://arxiv.org/abs/1807.01774">BOHB</a>, Weights &amp; Biases Sweeps have you covered. You just need to <em>define your strategy</em> in the form of a <a href="https://docs.wandb.com/sweeps/configuration">configuration</a>.</p>
<p>When you’re setting up a Sweep in a notebook like this, that config object is a nested dictionary. When you run a Sweep via the command line, the config object is a <a href="https://docs.wandb.com/sweeps/quickstart#2-sweep-config">YAML file</a>. Let’s walk through the definition of a Sweep config together. We’ll do it slowly, so we get a chance to explain each component. In a typical Sweep pipeline, this step would be done in a single assignment.</p>
<p>The first thing we need to define is the <code>method</code> for choosing new parameter values.</p>
<p>We provide the following search <code>methods</code>: * <strong>Grid Search</strong> – Iterate over every combination of hyperparameter values. Very effective, but can be computationally costly. * <strong>Random Search</strong> – Select each new combination at random according to provided distributions. Surprisingly effective! * <strong>Bayesian Search</strong> – Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.</p>
<p>We’ll stick with <code>bayes</code> here.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:285,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248936615,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1"></a>sweep_config <span class="op">=</span> {</span>
<span id="cb141-2"><a href="#cb141-2"></a>    <span class="st">'method'</span>: <span class="st">'bayes'</span></span>
<span id="cb141-3"><a href="#cb141-3"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For <code>bayes</code> Sweeps, you also need to tell it a bit about your <code>metric</code>. W&amp;B need to know its <code>name</code>, so it can find it in the model outputs and it need to know whether your <code>goal</code> is to <code>minimize</code> it (e.g.&nbsp;if it’s the squared error) or to <code>maximize</code> it (e.g.&nbsp;if it’s the accuracy).</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248937455,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1"></a>metric <span class="op">=</span> {</span>
<span id="cb142-2"><a href="#cb142-2"></a>    <span class="st">'name'</span>: <span class="st">'val_loss'</span>,</span>
<span id="cb142-3"><a href="#cb142-3"></a>    <span class="st">'goal'</span>: <span class="st">'minimize'</span>   </span>
<span id="cb142-4"><a href="#cb142-4"></a>    }</span>
<span id="cb142-5"><a href="#cb142-5"></a></span>
<span id="cb142-6"><a href="#cb142-6"></a>sweep_config[<span class="st">'metric'</span>] <span class="op">=</span> metric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If you’re not running a <code>bayes</code> Sweep, you don’t have to, but it’s not a bad idea to include this in your <code>sweep_config</code> anyway, in case you change your mind later. It’s also good reproducibility practice to keep note of things like this, in case you, or someone else, come back to your Sweep in 6 months and don’t know whether <code>val_G_batch</code> is supposed to be high or low.</p>
<p>Once you’ve picked a <code>method</code> to try out new values of the hyperparameters, you need to define what those <code>parameters</code> are. Most of the time, this step is straightforward: you just give the <code>parameter</code> a name and specify a list of legal <code>values</code> of the parameter.</p>
<p>For example, when we choose the <code>optimizer</code> for our network, there’s only a finite number of options. Here we stick with the two most popular choices, <code>adam</code> and <code>sgd</code>. Even for hyperparameters that have potentially infinite options, it usually only makes sense to try out a few select <code>values</code>, as we do here with <code>dropout</code>:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248942893,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1"></a>parameters_dict <span class="op">=</span> {</span>
<span id="cb143-2"><a href="#cb143-2"></a>    <span class="st">'optimizer'</span>: {</span>
<span id="cb143-3"><a href="#cb143-3"></a>        <span class="st">'values'</span>: [<span class="st">'adam'</span>, <span class="st">'sgd'</span>]</span>
<span id="cb143-4"><a href="#cb143-4"></a>        },</span>
<span id="cb143-5"><a href="#cb143-5"></a>    <span class="st">'dropout'</span>: {</span>
<span id="cb143-6"><a href="#cb143-6"></a>          <span class="st">'values'</span>: [<span class="fl">0.1</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>]</span>
<span id="cb143-7"><a href="#cb143-7"></a>        },</span>
<span id="cb143-8"><a href="#cb143-8"></a>    }</span>
<span id="cb143-9"><a href="#cb143-9"></a></span>
<span id="cb143-10"><a href="#cb143-10"></a>sweep_config[<span class="st">'parameters'</span>] <span class="op">=</span> parameters_dict</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It’s often the case that there are hyperparameters that we don’t want to vary in this Sweep, but which we still want to set in our <code>sweep_config</code>. In that case, we just set the <code>value</code> directly:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248943289,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1"></a>parameters_dict.update({</span>
<span id="cb144-2"><a href="#cb144-2"></a>    <span class="st">'epochs'</span>: {</span>
<span id="cb144-3"><a href="#cb144-3"></a>        <span class="st">'value'</span>: <span class="dv">1</span>}</span>
<span id="cb144-4"><a href="#cb144-4"></a>    })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For a <code>grid</code> search, that’s all you ever need. For a <code>random</code> search, all the <code>values</code> of a parameter are equally likely to be chosen on a given run.</p>
<p>If that just won’t do, you can instead specify a named <code>distribution</code>, plus its parameters, like the mean <code>mu</code> and standard deviation <code>sigma</code> of a <code>normal</code> distribution. See more on how to set the distributions of your random variables <a href="https://docs.wandb.com/sweeps/configuration#distributions">here</a>.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248945886,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1"></a>parameters_dict.update({</span>
<span id="cb145-2"><a href="#cb145-2"></a>    <span class="st">'learning_rate'</span>: {</span>
<span id="cb145-3"><a href="#cb145-3"></a>        <span class="co"># a flat distribution between 0 and 0.1</span></span>
<span id="cb145-4"><a href="#cb145-4"></a>        <span class="st">'distribution'</span>: <span class="st">'uniform'</span>,</span>
<span id="cb145-5"><a href="#cb145-5"></a>        <span class="st">'min'</span>: <span class="fl">0.001</span>,</span>
<span id="cb145-6"><a href="#cb145-6"></a>        <span class="st">'max'</span>: <span class="fl">0.1</span></span>
<span id="cb145-7"><a href="#cb145-7"></a>      },</span>
<span id="cb145-8"><a href="#cb145-8"></a>    <span class="st">'batch_size'</span>: {</span>
<span id="cb145-9"><a href="#cb145-9"></a>        <span class="st">'values'</span>: [<span class="dv">64</span>, <span class="dv">128</span>]</span>
<span id="cb145-10"><a href="#cb145-10"></a>      }</span>
<span id="cb145-11"><a href="#cb145-11"></a>    })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When we’re finished, <code>sweep_config</code> is a nested dictionary that specifies exactly which <code>parameters</code> we’re interested in trying and what <code>method</code> we’re going to use to try them.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248947945,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="4aed6e4c-1917-40ae-b272-9c20edd3b1f3" data-execution_count="14">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1"></a>pprint.pprint(sweep_config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'method': 'bayes',
 'metric': {'goal': 'minimize', 'name': 'val_loss'},
 'parameters': {'batch_size': {'values': [64, 128]},
                'dropout': {'values': [0.1, 0.3, 0.5]},
                'epochs': {'value': 1},
                'learning_rate': {'distribution': 'uniform',
                                  'max': 0.1,
                                  'min': 0.001},
                'optimizer': {'values': ['adam', 'sgd']}}}</code></pre>
</div>
</div>
<p>But that’s not all of the configuration options! For example, we also offer the option to <code>early_terminate</code> your runs with the <a href="https://arxiv.org/pdf/1603.06560.pdf">HyperBand</a> scheduling algorithm. See more <a href="https://docs.wandb.com/sweeps/configuration#stopping-criteria">here</a>. You can find a list of all configuration options <a href="https://docs.wandb.com/library/sweeps/configuration">here</a> and a big collection of examples in YAML format <a href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">here</a>.</p>
</section>
<section id="wrap-the-training-loop" class="level4" data-number="13.5.5.3">
<h4 data-number="13.5.5.3" class="anchored"><span class="header-section-number">13.5.5.3</span> Wrap the Training Loop</h4>
<p>You’ll need a function, like <code>sweep_train()</code> below, that uses <code>wandb.config</code> to set the hyperparameters before <code>train</code> gets called.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:572,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248959558,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1"></a><span class="kw">def</span> sweep_train(config_defaults<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb148-2"><a href="#cb148-2"></a>    <span class="co"># Initialize wandb with a sample project name</span></span>
<span id="cb148-3"><a href="#cb148-3"></a>    <span class="cf">with</span> wandb.init(config<span class="op">=</span>config_defaults):  <span class="co"># this gets over-written in the Sweep</span></span>
<span id="cb148-4"><a href="#cb148-4"></a></span>
<span id="cb148-5"><a href="#cb148-5"></a>        <span class="co"># Specify the other hyperparameters to the configuration, if any</span></span>
<span id="cb148-6"><a href="#cb148-6"></a>        wandb.config.architecture_name <span class="op">=</span> <span class="st">"ConvNet"</span></span>
<span id="cb148-7"><a href="#cb148-7"></a>        wandb.config.dataset_name <span class="op">=</span> <span class="st">"MNIST"</span></span>
<span id="cb148-8"><a href="#cb148-8"></a></span>
<span id="cb148-9"><a href="#cb148-9"></a>        <span class="co"># initialize model</span></span>
<span id="cb148-10"><a href="#cb148-10"></a>        model <span class="op">=</span> ConvNet(wandb.config.dropout)</span>
<span id="cb148-11"><a href="#cb148-11"></a></span>
<span id="cb148-12"><a href="#cb148-12"></a>        train(model, </span>
<span id="cb148-13"><a href="#cb148-13"></a>              wandb.config.batch_size, </span>
<span id="cb148-14"><a href="#cb148-14"></a>              wandb.config.epochs,</span>
<span id="cb148-15"><a href="#cb148-15"></a>              wandb.config.learning_rate,</span>
<span id="cb148-16"><a href="#cb148-16"></a>              wandb.config.optimizer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:10538,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685248975028,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="4c5d23b3-57a4-4491-9b65-d1aad0c8e121" data-execution_count="16">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1"></a>sweep_id <span class="op">=</span> wandb.sweep(sweep_config, project<span class="op">=</span><span class="st">"sweeps-keras-test"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/javascript">

        window._wandbApiKey = new Promise((resolve, reject) => {
            function loadScript(url) {
            return new Promise(function(resolve, reject) {
                let newScript = document.createElement("script");
                newScript.onerror = reject;
                newScript.onload = resolve;
                document.body.appendChild(newScript);
                newScript.src = url;
            });
            }
            loadScript("https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js").then(() => {
            const iframe = document.createElement('iframe')
            iframe.style.cssText = "width:0;height:0;border:none"
            document.body.appendChild(iframe)
            const handshake = new Postmate({
                container: iframe,
                url: 'https://wandb.ai/authorize'
            });
            const timeout = setTimeout(() => reject("Couldn't auto authenticate"), 5000)
            handshake.then(function(child) {
                child.on('authorize', data => {
                    clearTimeout(timeout)
                    resolve(data)
                });
            });
            })
        });
    
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Create sweep with ID: 3jg0srrt
Sweep URL: https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</code></pre>
</div>
</div>
<p>You can limit the number of total runs with the <code>count</code> parameter, we will limit a 10 to make the script run fast, feel free to increase the number of runs and see what happens.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:301764,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1685249291700,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="701ff1a1-5c85-4c86-9f75-f28d0a977263" data-execution_count="17">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1"></a>wandb.agent(sweep_id, function<span class="op">=</span>sweep_train, count<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: w3yo9n5b with config:
wandb:  batch_size: 128
wandb:  dropout: 0.1
wandb:  epochs: 1
wandb:  learning_rate: 0.06930189510244192
wandb:  optimizer: adam
wandb: Currently logged in as: phonchi. Use `wandb login --relogin` to force relogin</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044309-w3yo9n5b</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/w3yo9n5b" target="_blank">spring-sweep-1</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/w3yo9n5b" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/w3yo9n5b</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - ETA: 0s - loss: 2.4057 - accuracy: 0.1047</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - 14s 9ms/step - loss: 2.4057 - accuracy: 0.1047 - val_loss: 2.3041 - val_accuracy: 0.1028</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b685e4b9b8bb4d95b02f11bd6aa609b8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored" data-anchor-id="wrap-the-training-loop">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▇▁█▆▄▅▄▃▄▂▂▂▃▃▃▄▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>▁█▅▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.6">
<h3 data-number="13.5.6" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.6</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.10461</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>460</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.0693</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>2.40738</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.1047</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.0693</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>2.40567</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.1028</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>2.30411</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">spring-sweep-1</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/w3yo9n5b" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/w3yo9n5b</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044309-w3yo9n5b/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: avxmaq9k with config:
wandb:  batch_size: 64
wandb:  dropout: 0.3
wandb:  epochs: 1
wandb:  learning_rate: 0.004034650060468464
wandb:  optimizer: adam</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044339-avxmaq9k</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/avxmaq9k" target="_blank">wild-sweep-2</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/avxmaq9k" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/avxmaq9k</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9578</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 8s 8ms/step - loss: 0.1364 - accuracy: 0.9578 - val_loss: 0.0560 - val_accuracy: 0.9808</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"45b7fb95f0104d4f864f8c4b86c1e6e0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▅▆▇▇▇▇▇▇███████████████████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>█▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.7">
<h3 data-number="13.5.7" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.7</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.95762</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>930</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.00403</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.13691</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.95778</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.00403</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.13635</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9808</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.05604</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">wild-sweep-2</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/avxmaq9k" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/avxmaq9k</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044339-avxmaq9k/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: jsucsgpn with config:
wandb:  batch_size: 64
wandb:  dropout: 0.1
wandb:  epochs: 1
wandb:  learning_rate: 0.06346304009072952
wandb:  optimizer: sgd</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044405-jsucsgpn</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/jsucsgpn" target="_blank">happy-sweep-3</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/jsucsgpn" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/jsucsgpn</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.9157</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 7s 7ms/step - loss: 0.2785 - accuracy: 0.9157 - val_loss: 0.0945 - val_accuracy: 0.9715</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"38308b0b2adf40a3a5690f2e98fff5b3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.8">
<h3 data-number="13.5.8" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.8</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.9154</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>930</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.06346</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.27971</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.91573</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.06346</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.27853</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9715</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.09455</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">happy-sweep-3</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/jsucsgpn" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/jsucsgpn</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044405-jsucsgpn/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jiiph0o0 with config:
wandb:  batch_size: 128
wandb:  dropout: 0.5
wandb:  epochs: 1
wandb:  learning_rate: 0.04159232096092625
wandb:  optimizer: adam</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044438-jiiph0o0</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/jiiph0o0" target="_blank">silver-sweep-4</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/jiiph0o0" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/jiiph0o0</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>464/469 [============================&gt;.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8901</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - 5s 8ms/step - loss: 0.3705 - accuracy: 0.8906 - val_loss: 0.1096 - val_accuracy: 0.9697</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b5578096b4044a9d8e92e121a4a52614","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▂▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>▆█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.9">
<h3 data-number="13.5.9" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.9</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.88976</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>460</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.04159</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.37278</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.89058</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.04159</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.3705</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9697</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.10964</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">silver-sweep-4</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/jiiph0o0" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/jiiph0o0</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044438-jiiph0o0/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: nmat1qcr with config:
wandb:  batch_size: 128
wandb:  dropout: 0.5
wandb:  epochs: 1
wandb:  learning_rate: 0.05519859429843507
wandb:  optimizer: sgd</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044501-nmat1qcr</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/nmat1qcr" target="_blank">glamorous-sweep-5</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/nmat1qcr" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/nmat1qcr</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.8305</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - 5s 10ms/step - loss: 0.5343 - accuracy: 0.8305 - val_loss: 0.1431 - val_accuracy: 0.9573</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"aed8ccb9afae4f36a676f4acb47a791b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▂▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>███▇▇▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.10">
<h3 data-number="13.5.10" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.10</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.82862</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>460</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.0552</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.54003</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.8305</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.0552</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.5343</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9573</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.14307</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">glamorous-sweep-5</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/nmat1qcr" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/nmat1qcr</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044501-nmat1qcr/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8qocqbjb with config:
wandb:  batch_size: 128
wandb:  dropout: 0.1
wandb:  epochs: 1
wandb:  learning_rate: 0.042115826914488744
wandb:  optimizer: sgd</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044546-8qocqbjb</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/8qocqbjb" target="_blank">fearless-sweep-6</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/8qocqbjb" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/8qocqbjb</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>458/469 [============================&gt;.] - ETA: 0s - loss: 0.5663 - accuracy: 0.8294</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - 4s 8ms/step - loss: 0.5578 - accuracy: 0.8319 - val_loss: 0.1772 - val_accuracy: 0.9485</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▂▃▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>███▇▇▇▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.11">
<h3 data-number="13.5.11" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.11</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.82994</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>460</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.04212</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.56409</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.83188</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.04212</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.55776</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9485</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.17717</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">fearless-sweep-6</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/8qocqbjb" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/8qocqbjb</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044546-8qocqbjb/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: fzf3w5ev with config:
wandb:  batch_size: 128
wandb:  dropout: 0.3
wandb:  epochs: 1
wandb:  learning_rate: 0.08608979253191129
wandb:  optimizer: sgd</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044619-fzf3w5ev</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/fzf3w5ev" target="_blank">rosy-sweep-7</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/fzf3w5ev" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/fzf3w5ev</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>460/469 [============================&gt;.] - ETA: 0s - loss: 0.4030 - accuracy: 0.8767</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - 8s 15ms/step - loss: 0.3984 - accuracy: 0.8782 - val_loss: 0.1189 - val_accuracy: 0.9655</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▂▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>██▇▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.12">
<h3 data-number="13.5.12" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.12</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.8769</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>460</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.08609</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.4025</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.87817</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.08609</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.39843</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9655</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.1189</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">rosy-sweep-7</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/fzf3w5ev" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/fzf3w5ev</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044619-fzf3w5ev/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: h9nyuncw with config:
wandb:  batch_size: 128
wandb:  dropout: 0.5
wandb:  epochs: 1
wandb:  learning_rate: 0.05812571512662621
wandb:  optimizer: sgd</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044656-h9nyuncw</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/h9nyuncw" target="_blank">dashing-sweep-8</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/h9nyuncw" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/h9nyuncw</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>461/469 [============================&gt;.] - ETA: 0s - loss: 0.5099 - accuracy: 0.8407</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>469/469 [==============================] - 5s 10ms/step - loss: 0.5048 - accuracy: 0.8424 - val_loss: 0.1392 - val_accuracy: 0.9599</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cbe9e82d8c56486db07b194bddc10728","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▂▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>███▇▇▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.13">
<h3 data-number="13.5.13" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.13</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.8407</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>460</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.05813</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.5099</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.84237</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.05813</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.50481</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9599</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.13917</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">dashing-sweep-8</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/h9nyuncw" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/h9nyuncw</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044656-h9nyuncw/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: q6w4eo98 with config:
wandb:  batch_size: 64
wandb:  dropout: 0.5
wandb:  epochs: 1
wandb:  learning_rate: 0.0840398624399258
wandb:  optimizer: sgd</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044722-q6w4eo98</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/q6w4eo98" target="_blank">giddy-sweep-9</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/q6w4eo98" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/q6w4eo98</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>933/938 [============================&gt;.] - ETA: 0s - loss: 0.3203 - accuracy: 0.9004</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 7s 7ms/step - loss: 0.3192 - accuracy: 0.9007 - val_loss: 0.0900 - val_accuracy: 0.9729</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4d9e414eb0c54ee398895e8015784f34","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▂▃▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>██▇▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.14">
<h3 data-number="13.5.14" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.14</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.90024</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>930</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.08404</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.32056</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.90068</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.08404</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.31923</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.9729</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.09002</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">giddy-sweep-9</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/q6w4eo98" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/q6w4eo98</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044722-q6w4eo98/logs</code>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Agent Starting Run: 0u2eenmd with config:
wandb:  batch_size: 64
wandb:  dropout: 0.5
wandb:  epochs: 1
wandb:  learning_rate: 0.06016121976975345
wandb:  optimizer: adam</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230528_044747-0u2eenmd</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/0u2eenmd" target="_blank">toasty-sweep-10</a></strong> to <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>Sweep page: <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/sweeps-keras-test" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test</a>
</div>
<div class="cell-output cell-output-display">
 View sweep at <a href="https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/sweeps/3jg0srrt</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/0u2eenmd" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/0u2eenmd</a>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>935/938 [============================&gt;.] - ETA: 0s - loss: 0.4499 - accuracy: 0.8718</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./my_model_01)... Done. 0.0s</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>938/938 [==============================] - 8s 7ms/step - loss: 0.4496 - accuracy: 0.8718 - val_loss: 0.1438 - val_accuracy: 0.9590</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>▁▄▅▆▇▇▇▇▇▇██████████████████████████████</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>▇█▅▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.15">
<h3 data-number="13.5.15" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.15</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>batch/accuracy</td>
<td>0.87161</td>
</tr>
<tr class="even">
<td>batch/batch_step</td>
<td>930</td>
</tr>
<tr class="odd">
<td>batch/learning_rate</td>
<td>0.06016</td>
</tr>
<tr class="even">
<td>batch/loss</td>
<td>0.45045</td>
</tr>
<tr class="odd">
<td>epoch/accuracy</td>
<td>0.87183</td>
</tr>
<tr class="even">
<td>epoch/epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>epoch/learning_rate</td>
<td>0.06016</td>
</tr>
<tr class="even">
<td>epoch/loss</td>
<td>0.44964</td>
</tr>
<tr class="odd">
<td>epoch/val_accuracy</td>
<td>0.959</td>
</tr>
<tr class="even">
<td>epoch/val_loss</td>
<td>0.14376</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">toasty-sweep-10</strong> at: <a href="https://wandb.ai/phonchi/sweeps-keras-test/runs/0u2eenmd" target="_blank">https://wandb.ai/phonchi/sweeps-keras-test/runs/0u2eenmd</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230528_044747-0u2eenmd/logs</code>
</div>
</div>
</section>
</section>
<section id="model-and-data-versioning" class="level3" data-number="13.5.16">
<h3 data-number="13.5.16" class="anchored" data-anchor-id="model-and-data-versioning"><span class="header-section-number">13.5.16</span> Model and data versioning</h3>
<p>Choose one of the three dataset size options below to run the rest of the demo. With fewer images, you’ll run through the demo much faster and use less storage space. With more images, you’ll get more realistic model training and more interesting results and examples to explore.</p>
<p>Note: <strong>for the largest dataset, this stage might take a few minutes</strong>. If you end up needing to rerun a cell, comment out the first capture line (change <code>%%capture</code> to <code>#%%capture</code> ) so you can respond to the prompt about re-downloading the dataset (and see the progress bar). Each zipped directory contains randomly sampled images from the <a href="https://github.com/visipedia/inat_comp">iNaturalist dataset</a>, evenly distributed across 10 classes of living things like birds, insects, plants, and mammals (names given in Latin—so Aves, Insecta, Plantae, etc :).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1"></a><span class="co"># set SIZE to "TINY", "MEDIUM", or "LARGE"</span></span>
<span id="cb193-2"><a href="#cb193-2"></a><span class="co"># to select one of these three datasets</span></span>
<span id="cb193-3"><a href="#cb193-3"></a><span class="co"># TINY dataset: 100 images, 30MB</span></span>
<span id="cb193-4"><a href="#cb193-4"></a><span class="co"># MEDIUM dataset: 1000 images, 312MB</span></span>
<span id="cb193-5"><a href="#cb193-5"></a><span class="co"># LARGE datast: 12,000 images, 3.6GB</span></span>
<span id="cb193-6"><a href="#cb193-6"></a></span>
<span id="cb193-7"><a href="#cb193-7"></a>SIZE <span class="op">=</span> <span class="st">"TINY"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb194"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1"></a><span class="cf">if</span> SIZE <span class="op">==</span> <span class="st">"TINY"</span>:</span>
<span id="cb194-2"><a href="#cb194-2"></a>    src_url <span class="op">=</span> <span class="st">"https://storage.googleapis.com/wandb_datasets/nature_100.zip"</span></span>
<span id="cb194-3"><a href="#cb194-3"></a>    src_zip <span class="op">=</span> <span class="st">"nature_100.zip"</span></span>
<span id="cb194-4"><a href="#cb194-4"></a>    DATA_SRC <span class="op">=</span> <span class="st">"nature_100"</span></span>
<span id="cb194-5"><a href="#cb194-5"></a>    IMAGES_PER_LABEL <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb194-6"><a href="#cb194-6"></a>    BALANCED_SPLITS <span class="op">=</span> {<span class="st">"train"</span> : <span class="dv">8</span>, <span class="st">"val"</span> : <span class="dv">1</span>, <span class="st">"test"</span>: <span class="dv">1</span>}</span>
<span id="cb194-7"><a href="#cb194-7"></a><span class="cf">elif</span> SIZE <span class="op">==</span> <span class="st">"MEDIUM"</span>:</span>
<span id="cb194-8"><a href="#cb194-8"></a>    src_url <span class="op">=</span> <span class="st">"https://storage.googleapis.com/wandb_datasets/nature_1K.zip"</span></span>
<span id="cb194-9"><a href="#cb194-9"></a>    src_zip <span class="op">=</span> <span class="st">"nature_1K.zip"</span></span>
<span id="cb194-10"><a href="#cb194-10"></a>    DATA_SRC <span class="op">=</span> <span class="st">"nature_1K"</span></span>
<span id="cb194-11"><a href="#cb194-11"></a>    IMAGES_PER_LABEL <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb194-12"><a href="#cb194-12"></a>    BALANCED_SPLITS <span class="op">=</span> {<span class="st">"train"</span> : <span class="dv">80</span>, <span class="st">"val"</span> : <span class="dv">10</span>, <span class="st">"test"</span>: <span class="dv">10</span>}</span>
<span id="cb194-13"><a href="#cb194-13"></a><span class="cf">elif</span> SIZE <span class="op">==</span> <span class="st">"LARGE"</span>:</span>
<span id="cb194-14"><a href="#cb194-14"></a>    src_url <span class="op">=</span> <span class="st">"https://storage.googleapis.com/wandb_datasets/nature_12K.zip"</span></span>
<span id="cb194-15"><a href="#cb194-15"></a>    src_zip <span class="op">=</span> <span class="st">"nature_12K.zip"</span></span>
<span id="cb194-16"><a href="#cb194-16"></a>    DATA_SRC <span class="op">=</span> <span class="st">"inaturalist_12K/train"</span> <span class="co"># (technically a subset of only 10K images)</span></span>
<span id="cb194-17"><a href="#cb194-17"></a>    IMAGES_PER_LABEL <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb194-18"><a href="#cb194-18"></a>    BALANCED_SPLITS <span class="op">=</span> {<span class="st">"train"</span> : <span class="dv">800</span>, <span class="st">"val"</span> : <span class="dv">100</span>, <span class="st">"test"</span>: <span class="dv">100</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1"></a><span class="op">%%</span>capture</span>
<span id="cb195-2"><a href="#cb195-2"></a><span class="op">!</span>curl <span class="op">-</span>SL $src_url <span class="op">&gt;</span> $src_zip</span>
<span id="cb195-3"><a href="#cb195-3"></a><span class="op">!</span>unzip $src_zip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb196"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1"></a><span class="co"># source directory for all raw data</span></span>
<span id="cb196-2"><a href="#cb196-2"></a>SRC <span class="op">=</span> DATA_SRC</span>
<span id="cb196-3"><a href="#cb196-3"></a><span class="co"># number of images per class label</span></span>
<span id="cb196-4"><a href="#cb196-4"></a><span class="co"># the total number of images is 10X this (10 classes)</span></span>
<span id="cb196-5"><a href="#cb196-5"></a>TOTAL_IMAGES <span class="op">=</span> IMAGES_PER_LABEL <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb196-6"><a href="#cb196-6"></a>PROJECT_NAME <span class="op">=</span> <span class="st">"artifacts_demo"</span></span>
<span id="cb196-7"><a href="#cb196-7"></a>PREFIX <span class="op">=</span> <span class="st">"inat"</span> <span class="co"># convenient for tracking local data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="upload-raw-data" class="level4" data-number="13.5.16.1">
<h4 data-number="13.5.16.1" class="anchored" data-anchor-id="upload-raw-data"><span class="header-section-number">13.5.16.1</span> Upload raw data</h4>
<p>You can use <code>log_artifact()</code> to upload the data to the database.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:15825,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684919675839,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="3f182f17-541d-4902-d2e6-63e0e675cdeb">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1"></a>RAW_DATA_AT <span class="op">=</span> <span class="st">"_"</span>.join([PREFIX, <span class="st">"raw_data"</span>, <span class="bu">str</span>(TOTAL_IMAGES)])</span>
<span id="cb197-2"><a href="#cb197-2"></a>run <span class="op">=</span> wandb.init(project<span class="op">=</span>PROJECT_NAME, job_type<span class="op">=</span><span class="st">"upload"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/javascript">

        window._wandbApiKey = new Promise((resolve, reject) => {
            function loadScript(url) {
            return new Promise(function(resolve, reject) {
                let newScript = document.createElement("script");
                newScript.onerror = reject;
                newScript.onload = resolve;
                document.body.appendChild(newScript);
                newScript.src = url;
            });
            }
            loadScript("https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js").then(() => {
            const iframe = document.createElement('iframe')
            iframe.style.cssText = "width:0;height:0;border:none"
            document.body.appendChild(iframe)
            const handshake = new Postmate({
                container: iframe,
                url: 'https://wandb.ai/authorize'
            });
            const timeout = setTimeout(() => reject("Couldn't auto authenticate"), 5000)
            handshake.then(function(child) {
                child.on('authorize', data => {
                    clearTimeout(timeout)
                    resolve(data)
                });
            });
            })
        });
    
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc</code></pre>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230524_091424-n767hv0i</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/artifacts_demo/runs/n767hv0i" target="_blank">iconic-serenity-1</a></strong> to <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">https://wandb.ai/phonchi/artifacts_demo</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/artifacts_demo/runs/n767hv0i" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/n767hv0i</a>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:13164,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684919701468,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="74be4fc1-4cc9-470f-e163-235f34df9c72">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1"></a><span class="co"># create an artifact for all the raw data</span></span>
<span id="cb199-2"><a href="#cb199-2"></a>raw_data_at <span class="op">=</span> wandb.Artifact(RAW_DATA_AT, <span class="bu">type</span><span class="op">=</span><span class="st">"raw_data"</span>)</span>
<span id="cb199-3"><a href="#cb199-3"></a></span>
<span id="cb199-4"><a href="#cb199-4"></a><span class="co"># SRC_DIR contains 10 folders, one for each of 10 class labels</span></span>
<span id="cb199-5"><a href="#cb199-5"></a><span class="co"># each folder contains images of the corresponding class</span></span>
<span id="cb199-6"><a href="#cb199-6"></a>labels <span class="op">=</span> os.listdir(SRC)</span>
<span id="cb199-7"><a href="#cb199-7"></a><span class="cf">for</span> l <span class="kw">in</span> labels:</span>
<span id="cb199-8"><a href="#cb199-8"></a>    imgs_per_label <span class="op">=</span> os.path.join(SRC, l)</span>
<span id="cb199-9"><a href="#cb199-9"></a>    <span class="cf">if</span> os.path.isdir(imgs_per_label):</span>
<span id="cb199-10"><a href="#cb199-10"></a>        imgs <span class="op">=</span> os.listdir(imgs_per_label)</span>
<span id="cb199-11"><a href="#cb199-11"></a>        <span class="co"># randomize the order</span></span>
<span id="cb199-12"><a href="#cb199-12"></a>        shuffle(imgs)</span>
<span id="cb199-13"><a href="#cb199-13"></a>        img_file_ids <span class="op">=</span> imgs[:IMAGES_PER_LABEL]</span>
<span id="cb199-14"><a href="#cb199-14"></a>        <span class="cf">for</span> f <span class="kw">in</span> img_file_ids:</span>
<span id="cb199-15"><a href="#cb199-15"></a>            file_path <span class="op">=</span> os.path.join(SRC, l, f)</span>
<span id="cb199-16"><a href="#cb199-16"></a>            <span class="co"># add file to artifact by full path</span></span>
<span id="cb199-17"><a href="#cb199-17"></a>            raw_data_at.add_file(file_path, name<span class="op">=</span>l <span class="op">+</span> <span class="st">"/"</span> <span class="op">+</span> f)</span>
<span id="cb199-18"><a href="#cb199-18"></a></span>
<span id="cb199-19"><a href="#cb199-19"></a><span class="co"># save artifact to W&amp;B</span></span>
<span id="cb199-20"><a href="#cb199-20"></a>run.log_artifact(raw_data_at)</span>
<span id="cb199-21"><a href="#cb199-21"></a>run.finish()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">iconic-serenity-1</strong> at: <a href="https://wandb.ai/phonchi/artifacts_demo/runs/n767hv0i" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/n767hv0i</a><br>Synced 4 W&amp;B file(s), 0 media file(s), 100 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_091424-n767hv0i/logs</code>
</div>
</div>
<p>Now we prepare a data split:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:30763,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684919745362,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="fd2c938c-f3bd-488f-f77f-d024f5059227">
<div class="sourceCode cell-code" id="cb200"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1"></a>run <span class="op">=</span> wandb.init(project<span class="op">=</span>PROJECT_NAME, job_type<span class="op">=</span><span class="st">"data_split"</span>)</span>
<span id="cb200-2"><a href="#cb200-2"></a></span>
<span id="cb200-3"><a href="#cb200-3"></a><span class="co"># find the most recent ("latest") version of the full raw data</span></span>
<span id="cb200-4"><a href="#cb200-4"></a><span class="co"># you can of course pass around programmatic aliases and not string literals</span></span>
<span id="cb200-5"><a href="#cb200-5"></a>data_at <span class="op">=</span> run.use_artifact(RAW_DATA_AT <span class="op">+</span> <span class="st">":latest"</span>)</span>
<span id="cb200-6"><a href="#cb200-6"></a><span class="co"># download it locally (for illustration purposes/across hardware; you can</span></span>
<span id="cb200-7"><a href="#cb200-7"></a><span class="co"># also sync/version artifacts by reference)</span></span>
<span id="cb200-8"><a href="#cb200-8"></a>data_dir <span class="op">=</span> data_at.download()</span>
<span id="cb200-9"><a href="#cb200-9"></a></span>
<span id="cb200-10"><a href="#cb200-10"></a><span class="co"># create balanced train, val, test splits</span></span>
<span id="cb200-11"><a href="#cb200-11"></a><span class="co"># each count is the number of images per label</span></span>
<span id="cb200-12"><a href="#cb200-12"></a>DATA_SPLITS <span class="op">=</span> BALANCED_SPLITS</span>
<span id="cb200-13"><a href="#cb200-13"></a></span>
<span id="cb200-14"><a href="#cb200-14"></a>ats <span class="op">=</span> {}</span>
<span id="cb200-15"><a href="#cb200-15"></a><span class="co"># wrap artifacts in dictionary for convenience</span></span>
<span id="cb200-16"><a href="#cb200-16"></a><span class="cf">for</span> split, count <span class="kw">in</span> DATA_SPLITS.items():</span>
<span id="cb200-17"><a href="#cb200-17"></a>    ats[split] <span class="op">=</span> wandb.Artifact(<span class="st">"_"</span>.join([PREFIX, split, <span class="st">"data"</span>, <span class="bu">str</span>(count<span class="op">*</span><span class="dv">10</span>)]), </span>
<span id="cb200-18"><a href="#cb200-18"></a>                                <span class="st">"_"</span>.join([split, <span class="st">"data"</span>]))</span>
<span id="cb200-19"><a href="#cb200-19"></a></span>
<span id="cb200-20"><a href="#cb200-20"></a>labels <span class="op">=</span> os.listdir(data_dir)</span>
<span id="cb200-21"><a href="#cb200-21"></a><span class="cf">for</span> l <span class="kw">in</span> labels:</span>
<span id="cb200-22"><a href="#cb200-22"></a>    <span class="cf">if</span> l.startswith(<span class="st">"."</span>): <span class="co"># skip non-label file</span></span>
<span id="cb200-23"><a href="#cb200-23"></a>        <span class="cf">continue</span></span>
<span id="cb200-24"><a href="#cb200-24"></a>    imgs_per_label <span class="op">=</span> os.listdir(os.path.join(data_dir, l))</span>
<span id="cb200-25"><a href="#cb200-25"></a>    shuffle(imgs_per_label)</span>
<span id="cb200-26"><a href="#cb200-26"></a>    start_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb200-27"><a href="#cb200-27"></a>    <span class="cf">for</span> split, count <span class="kw">in</span> DATA_SPLITS.items():</span>
<span id="cb200-28"><a href="#cb200-28"></a>        <span class="co"># take a subset</span></span>
<span id="cb200-29"><a href="#cb200-29"></a>        split_imgs <span class="op">=</span> imgs_per_label[start_id:start_id<span class="op">+</span>count]</span>
<span id="cb200-30"><a href="#cb200-30"></a>        <span class="cf">for</span> img_file <span class="kw">in</span> split_imgs:</span>
<span id="cb200-31"><a href="#cb200-31"></a>            full_path <span class="op">=</span> os.path.join(data_dir, l, img_file)</span>
<span id="cb200-32"><a href="#cb200-32"></a>            <span class="co"># add file to artifact by full path</span></span>
<span id="cb200-33"><a href="#cb200-33"></a>            <span class="co"># note: pass the label to the name parameter to retain it in</span></span>
<span id="cb200-34"><a href="#cb200-34"></a>            <span class="co"># the data structure </span></span>
<span id="cb200-35"><a href="#cb200-35"></a>            ats[split].add_file(full_path, name <span class="op">=</span> os.path.join(l, img_file))</span>
<span id="cb200-36"><a href="#cb200-36"></a>        start_id <span class="op">+=</span> count</span>
<span id="cb200-37"><a href="#cb200-37"></a></span>
<span id="cb200-38"><a href="#cb200-38"></a><span class="co"># save all three artifacts to W&amp;B</span></span>
<span id="cb200-39"><a href="#cb200-39"></a><span class="co"># note: yes, in this example, we are cheating and have labels for the "test" data ;)</span></span>
<span id="cb200-40"><a href="#cb200-40"></a><span class="cf">for</span> split, artifact <span class="kw">in</span> ats.items():</span>
<span id="cb200-41"><a href="#cb200-41"></a>    run.log_artifact(artifact)</span>
<span id="cb200-42"><a href="#cb200-42"></a></span>
<span id="cb200-43"><a href="#cb200-43"></a>run.finish()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Currently logged in as: phonchi. Use `wandb login --relogin` to force relogin</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6720304378d64903a5921606504f9610","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230524_091509-ppnqommz</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/artifacts_demo/runs/ppnqommz" target="_blank">pretty-puddle-2</a></strong> to <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">https://wandb.ai/phonchi/artifacts_demo</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/artifacts_demo/runs/ppnqommz" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/ppnqommz</a>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb:   100 of 100 files downloaded.  </code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">pretty-puddle-2</strong> at: <a href="https://wandb.ai/phonchi/artifacts_demo/runs/ppnqommz" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/ppnqommz</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 100 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_091509-ppnqommz/logs</code>
</div>
</div>
</section>
<section id="train-with-artifacts-and-save-model" class="level4" data-number="13.5.16.2">
<h4 data-number="13.5.16.2" class="anchored"><span class="header-section-number">13.5.16.2</span> Train with artifacts and save model</h4>
<p>You can use <code>use_artifact()</code> to download and use stored artifact.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1"></a><span class="co"># EXPERIMENT CONFIG</span></span>
<span id="cb203-2"><a href="#cb203-2"></a><span class="co">#---------------------------</span></span>
<span id="cb203-3"><a href="#cb203-3"></a><span class="co"># if you modify these, make sure the total count is less than or equal to</span></span>
<span id="cb203-4"><a href="#cb203-4"></a><span class="co"># the number of files uploaded for that split in the train/val data artifact</span></span>
<span id="cb203-5"><a href="#cb203-5"></a>NUM_TRAIN <span class="op">=</span> BALANCED_SPLITS[<span class="st">"train"</span>] <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb203-6"><a href="#cb203-6"></a>NUM_VAL <span class="op">=</span> BALANCED_SPLITS[<span class="st">"val"</span>] <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb203-7"><a href="#cb203-7"></a>NUM_EPOCHS <span class="op">=</span> <span class="dv">1</span> <span class="co"># set low for demo purposes; try 3, 5, or as many as you like</span></span>
<span id="cb203-8"><a href="#cb203-8"></a></span>
<span id="cb203-9"><a href="#cb203-9"></a><span class="co"># model name</span></span>
<span id="cb203-10"><a href="#cb203-10"></a><span class="co"># if you want to train a sufficiently different model, give this a new name</span></span>
<span id="cb203-11"><a href="#cb203-11"></a><span class="co"># to start a new lineage for the model, instead of just incrementing the</span></span>
<span id="cb203-12"><a href="#cb203-12"></a><span class="co"># version of the old model</span></span>
<span id="cb203-13"><a href="#cb203-13"></a>MODEL_NAME <span class="op">=</span> <span class="st">"iv3_trained"</span></span>
<span id="cb203-14"><a href="#cb203-14"></a></span>
<span id="cb203-15"><a href="#cb203-15"></a><span class="co"># folder in which to save initial, untrained model</span></span>
<span id="cb203-16"><a href="#cb203-16"></a>INIT_MODEL_DIR <span class="op">=</span> <span class="st">"init_model_keras_iv3"</span></span>
<span id="cb203-17"><a href="#cb203-17"></a></span>
<span id="cb203-18"><a href="#cb203-18"></a><span class="co"># folder in which to save the final, trained model</span></span>
<span id="cb203-19"><a href="#cb203-19"></a><span class="co"># if you want to train a sufficiently different model, give this a new name</span></span>
<span id="cb203-20"><a href="#cb203-20"></a><span class="co"># to start a new lineage for the model, instead of just incrementing the</span></span>
<span id="cb203-21"><a href="#cb203-21"></a><span class="co"># version of the old model</span></span>
<span id="cb203-22"><a href="#cb203-22"></a>FINAL_MODEL_DIR <span class="op">=</span> <span class="st">"trained_keras_model_iv3"</span></span>
<span id="cb203-23"><a href="#cb203-23"></a></span>
<span id="cb203-24"><a href="#cb203-24"></a><span class="co"># experiment configuration saved to W&amp;B</span></span>
<span id="cb203-25"><a href="#cb203-25"></a>config_defaults <span class="op">=</span> {</span>
<span id="cb203-26"><a href="#cb203-26"></a>    <span class="st">"num_train"</span> : NUM_TRAIN,</span>
<span id="cb203-27"><a href="#cb203-27"></a>    <span class="st">"num_val"</span> : NUM_VAL,</span>
<span id="cb203-28"><a href="#cb203-28"></a>    <span class="st">"epochs"</span> : NUM_EPOCHS,</span>
<span id="cb203-29"><a href="#cb203-29"></a>    <span class="st">"num_classes"</span> : <span class="dv">10</span>,</span>
<span id="cb203-30"><a href="#cb203-30"></a>    <span class="st">"fc_size"</span> : <span class="dv">1024</span>,</span>
<span id="cb203-31"><a href="#cb203-31"></a>    <span class="co"># inceptionV3 settings</span></span>
<span id="cb203-32"><a href="#cb203-32"></a>    <span class="st">"img_width"</span> : <span class="dv">299</span>,</span>
<span id="cb203-33"><a href="#cb203-33"></a>    <span class="st">"img_height"</span>: <span class="dv">299</span>,</span>
<span id="cb203-34"><a href="#cb203-34"></a>    <span class="st">"batch_size"</span> : <span class="dv">32</span></span>
<span id="cb203-35"><a href="#cb203-35"></a>}</span>
<span id="cb203-36"><a href="#cb203-36"></a></span>
<span id="cb203-37"><a href="#cb203-37"></a><span class="kw">def</span> finetune_inception_model(fc_size, num_classes):</span>
<span id="cb203-38"><a href="#cb203-38"></a>    <span class="co">"""Load InceptionV3 with ImageNet weights, freeze it,</span></span>
<span id="cb203-39"><a href="#cb203-39"></a><span class="co">    and attach a finetuning top for this classification task"""</span></span>
<span id="cb203-40"><a href="#cb203-40"></a>    <span class="co"># load InceptionV3 as base</span></span>
<span id="cb203-41"><a href="#cb203-41"></a>    base <span class="op">=</span> tf.keras.applications.inception_v3.InceptionV3(weights<span class="op">=</span><span class="st">"imagenet"</span>, include_top<span class="op">=</span><span class="st">"False"</span>)</span>
<span id="cb203-42"><a href="#cb203-42"></a>    <span class="co"># freeze base layers</span></span>
<span id="cb203-43"><a href="#cb203-43"></a>    <span class="cf">for</span> layer <span class="kw">in</span> base.layers:</span>
<span id="cb203-44"><a href="#cb203-44"></a>      layer.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb203-45"><a href="#cb203-45"></a>    x <span class="op">=</span> base.get_layer(<span class="st">'mixed10'</span>).output </span>
<span id="cb203-46"><a href="#cb203-46"></a>    </span>
<span id="cb203-47"><a href="#cb203-47"></a>    <span class="co"># attach a fine-tuning layer</span></span>
<span id="cb203-48"><a href="#cb203-48"></a>    x <span class="op">=</span> tf.keras.layers.GlobalAveragePooling2D()(x)</span>
<span id="cb203-49"><a href="#cb203-49"></a>    x <span class="op">=</span> tf.keras.layers.Dense(fc_size, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb203-50"><a href="#cb203-50"></a>    guesses <span class="op">=</span> tf.keras.layers.Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb203-51"><a href="#cb203-51"></a>    </span>
<span id="cb203-52"><a href="#cb203-52"></a>    model <span class="op">=</span> tf.keras.models.Model(inputs<span class="op">=</span>base.<span class="bu">input</span>, outputs<span class="op">=</span>guesses)</span>
<span id="cb203-53"><a href="#cb203-53"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'rmsprop'</span>, loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb203-54"><a href="#cb203-54"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb204"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1"></a><span class="kw">def</span> train():</span>
<span id="cb204-2"><a href="#cb204-2"></a>    <span class="co">""" Main training loop. This is called pretrain because it freezes</span></span>
<span id="cb204-3"><a href="#cb204-3"></a><span class="co">    the InceptionV3 layers of the model and only trains the new top layers</span></span>
<span id="cb204-4"><a href="#cb204-4"></a><span class="co">    on the new data.   subsequent training phase would unfreeze all the layers</span></span>
<span id="cb204-5"><a href="#cb204-5"></a><span class="co">    and finetune the whole model on the new data"""</span> </span>
<span id="cb204-6"><a href="#cb204-6"></a>    <span class="co"># track this experiment with wandb: all runs will be sent</span></span>
<span id="cb204-7"><a href="#cb204-7"></a>    <span class="co"># to the given project name</span></span>
<span id="cb204-8"><a href="#cb204-8"></a>    run <span class="op">=</span> wandb.init(project<span class="op">=</span>PROJECT_NAME, job_type<span class="op">=</span><span class="st">"train"</span>, config<span class="op">=</span>config_defaults)</span>
<span id="cb204-9"><a href="#cb204-9"></a>    cfg <span class="op">=</span> wandb.config</span>
<span id="cb204-10"><a href="#cb204-10"></a>    </span>
<span id="cb204-11"><a href="#cb204-11"></a>    <span class="co"># artifact names</span></span>
<span id="cb204-12"><a href="#cb204-12"></a>    train_at <span class="op">=</span> os.path.join(PROJECT_NAME, PREFIX <span class="op">+</span> <span class="st">"_train_data_"</span> <span class="op">+</span> <span class="bu">str</span>(NUM_TRAIN)) <span class="op">+</span> <span class="st">":latest"</span></span>
<span id="cb204-13"><a href="#cb204-13"></a>    val_at <span class="op">=</span> os.path.join(PROJECT_NAME, PREFIX <span class="op">+</span> <span class="st">"_val_data_"</span> <span class="op">+</span> <span class="bu">str</span>(NUM_VAL)) <span class="op">+</span> <span class="st">":latest"</span></span>
<span id="cb204-14"><a href="#cb204-14"></a>    </span>
<span id="cb204-15"><a href="#cb204-15"></a>    train_data <span class="op">=</span> run.use_artifact(train_at, <span class="bu">type</span><span class="op">=</span><span class="st">'train_data'</span>)</span>
<span id="cb204-16"><a href="#cb204-16"></a>    train_dir <span class="op">=</span> train_data.download()</span>
<span id="cb204-17"><a href="#cb204-17"></a>    val_data <span class="op">=</span> run.use_artifact(val_at, <span class="bu">type</span><span class="op">=</span><span class="st">'val_data'</span>)</span>
<span id="cb204-18"><a href="#cb204-18"></a>    val_dir <span class="op">=</span> val_data.download()</span>
<span id="cb204-19"><a href="#cb204-19"></a>    </span>
<span id="cb204-20"><a href="#cb204-20"></a>    <span class="co"># create train and validation data generators</span></span>
<span id="cb204-21"><a href="#cb204-21"></a>    train_datagen <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb204-22"><a href="#cb204-22"></a>        rescale<span class="op">=</span><span class="fl">1.</span> <span class="op">/</span> <span class="dv">255</span>,</span>
<span id="cb204-23"><a href="#cb204-23"></a>        shear_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb204-24"><a href="#cb204-24"></a>        zoom_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb204-25"><a href="#cb204-25"></a>        horizontal_flip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb204-26"><a href="#cb204-26"></a>    val_datagen <span class="op">=</span> ImageDataGenerator(rescale<span class="op">=</span><span class="fl">1.</span> <span class="op">/</span> <span class="dv">255</span>)</span>
<span id="cb204-27"><a href="#cb204-27"></a>    </span>
<span id="cb204-28"><a href="#cb204-28"></a>    train_generator <span class="op">=</span> train_datagen.flow_from_directory(</span>
<span id="cb204-29"><a href="#cb204-29"></a>      train_dir,</span>
<span id="cb204-30"><a href="#cb204-30"></a>      target_size<span class="op">=</span>(cfg.img_width, cfg.img_height),</span>
<span id="cb204-31"><a href="#cb204-31"></a>      batch_size<span class="op">=</span>cfg.batch_size,</span>
<span id="cb204-32"><a href="#cb204-32"></a>      class_mode<span class="op">=</span><span class="st">'categorical'</span>)</span>
<span id="cb204-33"><a href="#cb204-33"></a>    </span>
<span id="cb204-34"><a href="#cb204-34"></a>    val_generator <span class="op">=</span> val_datagen.flow_from_directory(</span>
<span id="cb204-35"><a href="#cb204-35"></a>      val_dir,</span>
<span id="cb204-36"><a href="#cb204-36"></a>      target_size<span class="op">=</span>(cfg.img_width, cfg.img_height),</span>
<span id="cb204-37"><a href="#cb204-37"></a>      batch_size<span class="op">=</span>cfg.batch_size,</span>
<span id="cb204-38"><a href="#cb204-38"></a>      class_mode<span class="op">=</span><span class="st">'categorical'</span>)</span>
<span id="cb204-39"><a href="#cb204-39"></a>    </span>
<span id="cb204-40"><a href="#cb204-40"></a>    <span class="co"># instantiate model and callbacks</span></span>
<span id="cb204-41"><a href="#cb204-41"></a>    model <span class="op">=</span> finetune_inception_model(cfg.fc_size, cfg.num_classes)</span>
<span id="cb204-42"><a href="#cb204-42"></a>    </span>
<span id="cb204-43"><a href="#cb204-43"></a>    <span class="co"># log initial model before training</span></span>
<span id="cb204-44"><a href="#cb204-44"></a>    model_artifact <span class="op">=</span> wandb.Artifact(</span>
<span id="cb204-45"><a href="#cb204-45"></a>              <span class="st">"iv3"</span>, <span class="bu">type</span><span class="op">=</span><span class="st">"model"</span>,</span>
<span id="cb204-46"><a href="#cb204-46"></a>              description<span class="op">=</span><span class="st">"unmodified inception v3"</span>,</span>
<span id="cb204-47"><a href="#cb204-47"></a>              metadata<span class="op">=</span><span class="bu">dict</span>(cfg))</span>
<span id="cb204-48"><a href="#cb204-48"></a>    </span>
<span id="cb204-49"><a href="#cb204-49"></a>    model.save(INIT_MODEL_DIR)</span>
<span id="cb204-50"><a href="#cb204-50"></a>    model_artifact.add_dir(INIT_MODEL_DIR)</span>
<span id="cb204-51"><a href="#cb204-51"></a>    run.log_artifact(model_artifact)</span>
<span id="cb204-52"><a href="#cb204-52"></a>    callbacks <span class="op">=</span> [WandbCallback()]</span>
<span id="cb204-53"><a href="#cb204-53"></a>    </span>
<span id="cb204-54"><a href="#cb204-54"></a>    <span class="co"># train!</span></span>
<span id="cb204-55"><a href="#cb204-55"></a>    model.fit(</span>
<span id="cb204-56"><a href="#cb204-56"></a>        train_generator,</span>
<span id="cb204-57"><a href="#cb204-57"></a>        steps_per_epoch <span class="op">=</span> cfg.num_train <span class="op">//</span> cfg.batch_size,</span>
<span id="cb204-58"><a href="#cb204-58"></a>        epochs<span class="op">=</span>cfg.epochs,</span>
<span id="cb204-59"><a href="#cb204-59"></a>        validation_data<span class="op">=</span>val_generator,</span>
<span id="cb204-60"><a href="#cb204-60"></a>        callbacks <span class="op">=</span> callbacks,</span>
<span id="cb204-61"><a href="#cb204-61"></a>        validation_steps<span class="op">=</span>cfg.num_val <span class="op">//</span> cfg.batch_size)</span>
<span id="cb204-62"><a href="#cb204-62"></a>    </span>
<span id="cb204-63"><a href="#cb204-63"></a>    <span class="co"># save trained model as artifact</span></span>
<span id="cb204-64"><a href="#cb204-64"></a>    trained_model_artifact <span class="op">=</span> wandb.Artifact(</span>
<span id="cb204-65"><a href="#cb204-65"></a>              MODEL_NAME, <span class="bu">type</span><span class="op">=</span><span class="st">"model"</span>,</span>
<span id="cb204-66"><a href="#cb204-66"></a>              description<span class="op">=</span><span class="st">"trained inception v3"</span>,</span>
<span id="cb204-67"><a href="#cb204-67"></a>              metadata<span class="op">=</span><span class="bu">dict</span>(cfg))</span>
<span id="cb204-68"><a href="#cb204-68"></a>    </span>
<span id="cb204-69"><a href="#cb204-69"></a>    model.save(FINAL_MODEL_DIR)</span>
<span id="cb204-70"><a href="#cb204-70"></a>    trained_model_artifact.add_dir(FINAL_MODEL_DIR)</span>
<span id="cb204-71"><a href="#cb204-71"></a>    run.log_artifact(trained_model_artifact)</span>
<span id="cb204-72"><a href="#cb204-72"></a>    run.finish()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:148389,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684919902213,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="a015e4b4-73c4-4d5c-8ef6-ca4d75bb8f6f">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1"></a>train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230524_091548-er1z6hnx</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/artifacts_demo/runs/er1z6hnx" target="_blank">giddy-smoke-3</a></strong> to <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">https://wandb.ai/phonchi/artifacts_demo</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/artifacts_demo/runs/er1z6hnx" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/er1z6hnx</a>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb:   80 of 80 files downloaded.  
wandb:   10 of 10 files downloaded.  </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 80 images belonging to 10 classes.
Found 10 images belonging to 10 classes.
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5
96112376/96112376 [==============================] - 5s 0us/step</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 95). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./init_model_keras_iv3)... Done. 0.3s
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&amp;B files and the SavedModel as W&amp;B Artifacts.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>2/2 [==============================] - 21s 5s/step - loss: 5.9535 - accuracy: 0.1250</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (./trained_keras_model_iv3)... Done. 0.3s</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">

<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3 class="anchored" data-anchor-id="train-with-artifacts-and-save-model">Run history:</h3><br>
<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>accuracy</td>
<td>▁</td>
</tr>
<tr class="even">
<td>epoch</td>
<td>▁</td>
</tr>
<tr class="odd">
<td>loss</td>
<td>▁</td>
</tr>
</tbody>
</table>
<br>

<section id="run-summary" class="level3 wandb-col" data-number="13.5.17">
<h3 data-number="13.5.17" class="anchored" data-anchor-id="run-summary"><span class="header-section-number">13.5.17</span> Run summary:</h3>
<br>

<table class="wandb table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td>accuracy</td>
<td>0.125</td>
</tr>
<tr class="even">
<td>epoch</td>
<td>0</td>
</tr>
<tr class="odd">
<td>loss</td>
<td>5.95346</td>
</tr>
</tbody>
</table>
</section>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">giddy-smoke-3</strong> at: <a href="https://wandb.ai/phonchi/artifacts_demo/runs/er1z6hnx" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/er1z6hnx</a><br>Synced 5 W&amp;B file(s), 1 media file(s), 10 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_091548-er1z6hnx/logs</code>
</div>
</div>
</section>
<section id="load-model-for-inference" class="level4" data-number="13.5.17.1">
<h4 data-number="13.5.17.1" class="anchored" data-anchor-id="load-model-for-inference"><span class="header-section-number">13.5.17.1</span> Load model for inference</h4>
<p>You can use <code>use_artifact()</code> to download and use stored artifact.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:40582,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1684919999474,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="f6ded9ad-0f4e-424e-e0d6-386d02c86f75">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1"></a>run <span class="op">=</span> wandb.init(project<span class="op">=</span>PROJECT_NAME, job_type<span class="op">=</span><span class="st">"inference"</span>)</span>
<span id="cb211-2"><a href="#cb211-2"></a><span class="co"># use the latest version of the model</span></span>
<span id="cb211-3"><a href="#cb211-3"></a>model_at <span class="op">=</span> run.use_artifact(MODEL_NAME <span class="op">+</span> <span class="st">":latest"</span>)</span>
<span id="cb211-4"><a href="#cb211-4"></a><span class="co"># download the directory in which the model is saved</span></span>
<span id="cb211-5"><a href="#cb211-5"></a>model_dir<span class="op">=</span> model_at.download()</span>
<span id="cb211-6"><a href="#cb211-6"></a><span class="bu">print</span>(<span class="st">"model: "</span>, model_dir)</span>
<span id="cb211-7"><a href="#cb211-7"></a>model <span class="op">=</span> tf.keras.models.load_model(model_dir)</span>
<span id="cb211-8"><a href="#cb211-8"></a></span>
<span id="cb211-9"><a href="#cb211-9"></a>TEST_DATA_AT <span class="op">=</span> PREFIX <span class="op">+</span> <span class="st">"_test_data_"</span> <span class="op">+</span> <span class="bu">str</span>(BALANCED_SPLITS[<span class="st">"test"</span>]<span class="op">*</span><span class="dv">10</span>) <span class="op">+</span> <span class="st">":latest"</span></span>
<span id="cb211-10"><a href="#cb211-10"></a>test_data_at <span class="op">=</span> run.use_artifact(TEST_DATA_AT)</span>
<span id="cb211-11"><a href="#cb211-11"></a>test_dir <span class="op">=</span> test_data_at.download()</span>
<span id="cb211-12"><a href="#cb211-12"></a></span>
<span id="cb211-13"><a href="#cb211-13"></a>imgs <span class="op">=</span> []</span>
<span id="cb211-14"><a href="#cb211-14"></a>class_labels <span class="op">=</span> os.listdir(test_dir)</span>
<span id="cb211-15"><a href="#cb211-15"></a><span class="cf">for</span> l <span class="kw">in</span> class_labels:</span>
<span id="cb211-16"><a href="#cb211-16"></a>    <span class="cf">if</span> l.startswith(<span class="st">"."</span>):</span>
<span id="cb211-17"><a href="#cb211-17"></a>      <span class="cf">continue</span></span>
<span id="cb211-18"><a href="#cb211-18"></a>    imgs_per_class <span class="op">=</span> os.listdir(os.path.join(test_dir, l))</span>
<span id="cb211-19"><a href="#cb211-19"></a>    <span class="cf">for</span> img <span class="kw">in</span> imgs_per_class:</span>
<span id="cb211-20"><a href="#cb211-20"></a>      img_path <span class="op">=</span> os.path.join(test_dir, l, img)</span>
<span id="cb211-21"><a href="#cb211-21"></a>      img <span class="op">=</span> tf.keras.preprocessing.image.load_img(img_path, target_size<span class="op">=</span>(<span class="dv">299</span>, <span class="dv">299</span>))</span>
<span id="cb211-22"><a href="#cb211-22"></a>      img <span class="op">=</span> tf.keras.preprocessing.image.img_to_array(img)</span>
<span id="cb211-23"><a href="#cb211-23"></a>      <span class="co"># don't forget to rescale test images to match the range of inputs</span></span>
<span id="cb211-24"><a href="#cb211-24"></a>      <span class="co"># to the network</span></span>
<span id="cb211-25"><a href="#cb211-25"></a>      img <span class="op">=</span> np.expand_dims(img<span class="op">/</span><span class="fl">255.0</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb211-26"><a href="#cb211-26"></a>      imgs.append(img)</span>
<span id="cb211-27"><a href="#cb211-27"></a></span>
<span id="cb211-28"><a href="#cb211-28"></a>preds <span class="op">=</span> {}</span>
<span id="cb211-29"><a href="#cb211-29"></a>imgs <span class="op">=</span> np.vstack(imgs)</span>
<span id="cb211-30"><a href="#cb211-30"></a>classes <span class="op">=</span> model.predict(imgs, batch_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb211-31"><a href="#cb211-31"></a><span class="cf">for</span> c <span class="kw">in</span> classes:</span>
<span id="cb211-32"><a href="#cb211-32"></a>    class_id <span class="op">=</span> np.argmax(c)</span>
<span id="cb211-33"><a href="#cb211-33"></a>    <span class="cf">if</span> class_id <span class="kw">in</span> preds:</span>
<span id="cb211-34"><a href="#cb211-34"></a>      preds[class_id] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb211-35"><a href="#cb211-35"></a>    <span class="cf">else</span>:</span>
<span id="cb211-36"><a href="#cb211-36"></a>      preds[class_id] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb211-37"><a href="#cb211-37"></a></span>
<span id="cb211-38"><a href="#cb211-38"></a><span class="co"># print the counts of predicted labels as a quick sanity check</span></span>
<span id="cb211-39"><a href="#cb211-39"></a><span class="co"># note that for tiny/medium datasets, this won't be very meaningful</span></span>
<span id="cb211-40"><a href="#cb211-40"></a><span class="bu">print</span>(preds)</span>
<span id="cb211-41"><a href="#cb211-41"></a>run.finish()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
Finishing last run (ID:fo7u8bx6) before initializing another...
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4a22fedc697346f98ac4ba83469765e9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">quiet-grass-4</strong> at: <a href="https://wandb.ai/phonchi/artifacts_demo/runs/fo7u8bx6" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/fo7u8bx6</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_091836-fo7u8bx6/logs</code>
</div>
<div class="cell-output cell-output-display">
Successfully finished last run (ID:fo7u8bx6). Initializing new run:<br>
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.15.3
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/content/wandb/run-20230524_091913-7y1vt7qq</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/phonchi/artifacts_demo/runs/7y1vt7qq" target="_blank">genial-wind-5</a></strong> to <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/phonchi/artifacts_demo" target="_blank">https://wandb.ai/phonchi/artifacts_demo</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/phonchi/artifacts_demo/runs/7y1vt7qq" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/7y1vt7qq</a>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Downloading large artifact iv3_trained:latest, 104.85MB. 5 files... 
wandb:   5 of 5 files downloaded.  
Done. 0:0:0.2</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>model:  ./artifacts/iv3_trained:v0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb:   10 of 10 files downloaded.  </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 6s 6s/step
{7: 10}</code></pre>
</div>
<div class="cell-output cell-output-display">
Waiting for W&amp;B process to finish... <strong style="color:green">(success).</strong>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c8244541ba404065bafca41c1bc2a394","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">genial-wind-5</strong> at: <a href="https://wandb.ai/phonchi/artifacts_demo/runs/7y1vt7qq" target="_blank">https://wandb.ai/phonchi/artifacts_demo/runs/7y1vt7qq</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20230524_091913-7y1vt7qq/logs</code>
</div>
</div>
</section>
</section>
</section>
<section id="references" class="level2" data-number="13.6">
<h2 data-number="13.6" class="anchored" data-anchor-id="references"><span class="header-section-number">13.6</span> References</h2>
<ol type="1">
<li><a href="https://github.com/fchollet/deep-learning-with-python-notebooks_">https://github.com/fchollet/deep-learning-with-python-notebooks_</a></li>
<li><a href="https://keras.io/guides/keras_tuner/getting_started/">https://keras.io/guides/keras_tuner/getting_started/</a></li>
<li><a href="https://github.com/datamllab/automl-in-action-notebooks/blob/master/5.2.2-Tuning-CNNs-Image-Classification.ipynb">https://github.com/datamllab/automl-in-action-notebooks/blob/master/5.2.2-Tuning-CNNs-Image-Classification.ipynb</a></li>
<li><a href="https://towardsdatascience.com/grid-search-vs-random-search-vs-bayesian-optimization-2e68f57c3c46">https://towardsdatascience.com/grid-search-vs-random-search-vs-bayesian-optimization-2e68f57c3c46</a></li>
<li><a href="https://github.com/wandb/examples">https://github.com/wandb/examples</a></li>
</ol>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"010199f2d12b47f4b90a6219dc36b65c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"051d33dc7b284f1c85a724c92cac9926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"054569fc34184ef3a868ef1712e1736d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07c40fa86a384d24bb7f27cb6b7509b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_771c4c26d783484d9909bd8a91b825f0","IPY_MODEL_ddb3acb203d54fca8e914c70715ea10d","IPY_MODEL_6fe04380aada44b9bfaaf67390c541f8"],"layout":"IPY_MODEL_d0814e0604854ef69c189aaae4eac37e"}},"07dc706d3ee444e69b76fe25cd96f79c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c77ae238d2a5406ca9d955d9a85a8c4a","placeholder":"​","style":"IPY_MODEL_5be8bf0ffe6d4cbbb3cedc80a752fb67","value":" 29/29 [00:02&lt;00:00, 21.85 MiB/s]"}},"0807118d92864e499ad0c67d85c2fac8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08fd7ebe0e0846cd8144e2bf4b45d4c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c268ba2e4204ad49f0c6264922ea2c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ca8176ca4bf47c4b4bf84354ade7297":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cb963a50de343909cc1a524a0e4e258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11a671c63b62427d95839e3ae27bc07f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cba92804432456d8971e5e01f6fd202","placeholder":"​","style":"IPY_MODEL_87f924111f314c688f17701ebfffcf03","value":"0.558 MB of 0.558 MB uploaded (0.000 MB deduped)\r"}},"11b3c7e99c014ab1921c91a3f31d80da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4b4181be57f44ab951f910030eaaf72","max":60000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ee9c7f31616488d82a566399ae9f479","value":60000}},"138812f70e8a480486441eb4af01e08e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15323315dacf4bcdbe31251eea6107cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1746adab78764cabac2df6b2c7e3606a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1845746356694f4bae2c0bef4b78dfb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18bdadc2dab7420e9ffe8b2f3b888937":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81d9abaa883144ef805e08b935449791","placeholder":"​","style":"IPY_MODEL_78cddb5300aa410d8655da70a59ab6d6","value":"Dl Size...: 100%"}},"1e972c6463e84c8fbeaa9a21630cfae5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20d873acfa57432887a95c7265db7217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ca8176ca4bf47c4b4bf84354ade7297","placeholder":"​","style":"IPY_MODEL_258b270e75d84ef58e0f8baaa4f0aa29","value":" 108/108 [03:56&lt;00:00,  2.15s/it]"}},"211c719f5e6342a3bce47d9e4535378d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0c00e34ffed47cbb1f6b57287028b48","IPY_MODEL_ae3806317c14413291b9865183c651dc","IPY_MODEL_2a18db4b97cf462cadeb1a54637c5712"],"layout":"IPY_MODEL_0cb963a50de343909cc1a524a0e4e258"}},"2238dc58939e4c1a95b5b2f0200bfb39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_138812f70e8a480486441eb4af01e08e","placeholder":"​","style":"IPY_MODEL_eaaebfccd43643eca52cae967b6a125e","value":"0.413 MB of 0.413 MB uploaded (0.000 MB deduped)\r"}},"224383963d2940a88613ded92dcd61f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2262f16813d74aecadd3b045aff80c4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23b570bd35b94248a5a2383ab8e21d64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d4e4e81f234b059a9139d5f0f6fb2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c751707d054411f9c5561d6d5f4d15b","placeholder":"​","style":"IPY_MODEL_fd999d703a54440db93b2841a3bdc6e4","value":"Best trial: 12. Best value: 0.93096: 100%"}},"23d9dd5446214bd598a36f317c06536c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"258b270e75d84ef58e0f8baaa4f0aa29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2597922d130d45b5ba9ae03d75843e9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"261fb5f8416c4d3ca998478965eee45f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27e3edcafcc04e368dbe56a1bf1c8ddc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"286dd0e1257742f4ac0162606c35a5ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28a2dc12679f491695e28a7e5cb817ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a18db4b97cf462cadeb1a54637c5712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_667fcabe05cc47388fd0ef04dff97c6f","placeholder":"​","style":"IPY_MODEL_e62576e36a8c4ef6a62c635d0806d65b","value":" 4/4 [00:02&lt;00:00,  1.58 url/s]"}},"2bd6faafeecb48558d7638bbe283df7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33cfbf44750b4993b1e19b67a89c8e6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b49ee39f70314933b31a1607aa3a2b6a","placeholder":"​","style":"IPY_MODEL_970e677fc93d4c0ca3da0b5a98c393cd","value":" 50/50 [01:39&lt;00:00,  2.35s/it]"}},"34cc9277585b4a2d9dcfe2c16684af38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34f53226f77c4f03bdcdcd3d17abb2f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35b5734d896c4c5c82543ff9cd75fc94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38308b0b2adf40a3a5690f2e98fff5b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ae9af59097a14cebb71956a2f64a9d52","IPY_MODEL_7e0b64910ba041c4b331f6545fd5d357"],"layout":"IPY_MODEL_a4b658b43bec4b5f97ba375358767a1a"}},"396c5c711b344dae8bb394bd95ea3769":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9dec9dad484f4a81b249deb4a38d170c","IPY_MODEL_4e7a8a17cd1542e781e6ff3b63427be7","IPY_MODEL_20d873acfa57432887a95c7265db7217"],"layout":"IPY_MODEL_591f9b95747e4dc1a7a7ffdab62db621"}},"39c82537d7174fe29ecd0e4066d860ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39f9509bd2e7402aa74fa0ebef2c4c63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b4f896e17c5430a87e92190fd63ff0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5da24d9c5f4b6e8eddf4e5f4ef7a62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d91608e5968489c8286fb696d389ea5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_617df18f97304528bbc9f0587ec95e36","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db834ac272d44004a5d2f7b3191a7f6e","value":0.9998877301423617}},"3d9d20739cf7487dab28238065216a2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dc63a90c72d4039ab5b34c3d16f0d10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c46d3fd08e584bba8e535e16b9019e7a","placeholder":"​","style":"IPY_MODEL_5a52c3143e494224ba4ae751f646b489","value":" 59995/60000 [01:02&lt;00:00, 1375.93 examples/s]"}},"42545f885ba84947aafa04218d044661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"45b7fb95f0104d4f864f8c4b86c1e6e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_11a671c63b62427d95839e3ae27bc07f","IPY_MODEL_fd9114b495684e799ac0740b51e05a19"],"layout":"IPY_MODEL_616b3767e94d4829b9e105a17e612ffe"}},"4680576525e84ded8c26a40f17febdfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_15323315dacf4bcdbe31251eea6107cf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0807118d92864e499ad0c67d85c2fac8","value":1}},"46e52340bad84ee2872587c906d595df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75f3bb5f60054690aa4db5317b3732a5","placeholder":"​","style":"IPY_MODEL_7af168f7fe4442a5a065151606608d4d","value":" 9977/10000 [00:10&lt;00:00, 948.69 examples/s]"}},"478da94a66ae4da2942100615115a397":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a22fedc697346f98ac4ba83469765e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e9c689b836db43f18278eeb2e828819e","IPY_MODEL_fce18283bf994241b823792025c6846f"],"layout":"IPY_MODEL_ac76743a1ca14e179ceca9529ceb46af"}},"4c751707d054411f9c5561d6d5f4d15b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cba92804432456d8971e5e01f6fd202":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d9e414eb0c54ee398895e8015784f34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_a2f399667f2c49a99b26160e5f709112","IPY_MODEL_d2aff4add8c34bf38f96f938a6dfd5c5"],"layout":"IPY_MODEL_b23e63387da64960a1859413e1fb18dc"}},"4e7a8a17cd1542e781e6ff3b63427be7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b98629ed54504bf4bfc025e9ddba1c59","max":108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62d7fdeaa812444ca2ed5e9e2fc645d8","value":108}},"544a53f829924b2ea897cd7a69fe47a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b4f896e17c5430a87e92190fd63ff0c","placeholder":"​","style":"IPY_MODEL_599533fea8e045e99c1ac5c95d2dd7a3","value":" 4/4 [00:02&lt;00:00,  1.28 file/s]"}},"556d72457a2d43e886b74b6c92898a52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_67cdf944ec1b49d4ae9cb1066d6c98a4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de415dd7b6584f7f9337c7acf08f748f","value":1}},"585beda71d714aac87605705d7f9ae2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e734efb46fe148d3b130c0ebca4ef6ce","IPY_MODEL_756b63d2a8e6426cb9474e81df9c54af","IPY_MODEL_5a3d291f4fca4687898b1e3644b09c5c"],"layout":"IPY_MODEL_e32e1e9fbee74b318a7d425d2a25221f"}},"58796a1da158479c93405a6eef94ebfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a2dc12679f491695e28a7e5cb817ad","placeholder":"​","style":"IPY_MODEL_d35707178569480a96c122b5d01d9244","value":"128.575 MB of 128.589 MB uploaded (4.704 MB deduped)\r"}},"5884f51b64784a48aaedbfe8bbdec79e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"591f9b95747e4dc1a7a7ffdab62db621":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"599533fea8e045e99c1ac5c95d2dd7a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a3075cced484decad8d5bca7830ba6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a34a09c1ec144559292d99e2b90048d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1ed622743bc40b9b92804681f5fff40","IPY_MODEL_11b3c7e99c014ab1921c91a3f31d80da","IPY_MODEL_89c2f5bab5fa4216b3fdb023f699d674"],"layout":"IPY_MODEL_877b253d9ef04b259c21ffee41c8ab46"}},"5a3d291f4fca4687898b1e3644b09c5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd832f745314cc2883341830be889ad","placeholder":"​","style":"IPY_MODEL_677c61261d4e4c3f8c783305f7256d8f","value":" 50/50 [01:44&lt;00:00,  1.60s/it]"}},"5a52c3143e494224ba4ae751f646b489":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5be8bf0ffe6d4cbbb3cedc80a752fb67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bfd115f1b2f41e3ae843e7b54315e40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23d4e4e81f234b059a9139d5f0f6fb2a","IPY_MODEL_b365788e058a4883b1a3d1787b7539ef","IPY_MODEL_33cfbf44750b4993b1e19b67a89c8e6f"],"layout":"IPY_MODEL_e52f6e1b90d949f2a39db2815d54c224"}},"5e217a61376346eaa82731b5141b86ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5934ea4e6b546ef8ed436ef94b15d68","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82304b208d3549468217d306ecb4d74e","value":0.11950897839099117}},"5e664e7998684067958abe6721b48c6d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5edd7628b66b402aae6f16f0bc8666c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd6faafeecb48558d7638bbe283df7a","placeholder":"​","style":"IPY_MODEL_b0580fa521f14ff5ba08cfb82ca0a715","value":" 0/10000 [00:00&lt;?, ? examples/s]"}},"616b3767e94d4829b9e105a17e612ffe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"617df18f97304528bbc9f0587ec95e36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62d7fdeaa812444ca2ed5e9e2fc645d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"667fcabe05cc47388fd0ef04dff97c6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6720304378d64903a5921606504f9610":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_8b1282516fb3453c8b502aa2929a3274","IPY_MODEL_eee0b95342c54298ae0725f9aaecb0e5"],"layout":"IPY_MODEL_2262f16813d74aecadd3b045aff80c4a"}},"677c61261d4e4c3f8c783305f7256d8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67cdf944ec1b49d4ae9cb1066d6c98a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6853539f39864b6c87cbb1d259ecaf1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6862327b356e4e2ca25f0513c7e9d6f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"68a2ddb2d5364f3c91bb9f70473ffe5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69bdc15372c2431fb3eb7a5f27c9fe65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a6ccd7c24524d7da6b0a744dda205a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af7ee08db7e4ea8924c0a85e6bd4063":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b45eeca789e445eb72e97daf5693fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c68ab6097cf45c59aac0d4025c6109d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a6ccd7c24524d7da6b0a744dda205a9","placeholder":"​","style":"IPY_MODEL_8713a57b5ef54d7ba6c923dda916e00a","value":"Shuffling /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete67ZFKH/fashion_mnist-test.tfrecord*...:   0%"}},"6d35f08936ab40ddacb26c10b4ae24f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ebe49746719417ca1c10382e2566f4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_054569fc34184ef3a868ef1712e1736d","placeholder":"​","style":"IPY_MODEL_3d9d20739cf7487dab28238065216a2b","value":"0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\r"}},"6ee9c7f31616488d82a566399ae9f479":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f098a7d302b4b4eb6cddb783f341927":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fe04380aada44b9bfaaf67390c541f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97782d3036594839b79f8a643b8f594b","placeholder":"​","style":"IPY_MODEL_6b45eeca789e445eb72e97daf5693fd0","value":" 2/2 [01:13&lt;00:00, 32.20s/ splits]"}},"70cfac8edc924ea8a2a1407dd338e229":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_69bdc15372c2431fb3eb7a5f27c9fe65","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39f9509bd2e7402aa74fa0ebef2c4c63","value":1}},"73904512ee7148d1a0cf5c726e1eca56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"741413001d3f42de8400a16b6a555e08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"756b63d2a8e6426cb9474e81df9c54af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed626d35b7bf4c6e90713bd41380ceca","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83a937eaf40247eeaddfac2d02005f98","value":50}},"75dc88473ac14be1bc877135afc2df2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c68ab6097cf45c59aac0d4025c6109d","IPY_MODEL_7bc90a727f044091adc951a0dc082570","IPY_MODEL_5edd7628b66b402aae6f16f0bc8666c1"],"layout":"IPY_MODEL_f323825e55814f5f932492a729b6342a"}},"75f3bb5f60054690aa4db5317b3732a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76108914fcb74eb29b58d94506a990dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76c0943a65ff487caa28ad27ffbaf6a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"771c4c26d783484d9909bd8a91b825f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6853539f39864b6c87cbb1d259ecaf1e","placeholder":"​","style":"IPY_MODEL_d382bc788b3b4f36ac9f9edd9e9c9e78","value":"Generating splits...: 100%"}},"78cddb5300aa410d8655da70a59ab6d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7af168f7fe4442a5a065151606608d4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b6d3b8fe02a4533b48b5dcd982cc090":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bc90a727f044091adc951a0dc082570":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1845746356694f4bae2c0bef4b78dfb2","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e972c6463e84c8fbeaa9a21630cfae5","value":10000}},"7cd832f745314cc2883341830be889ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e0b64910ba041c4b331f6545fd5d357":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a3075cced484decad8d5bca7830ba6e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76108914fcb74eb29b58d94506a990dc","value":1}},"81d9abaa883144ef805e08b935449791":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82304b208d3549468217d306ecb4d74e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83a937eaf40247eeaddfac2d02005f98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85adbe13266d4d19bc96c87bc383959f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85e18f981fe34d97917f277e12a17e31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86caf9d5f4dd49f0b4203ca42f98ea4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86e34552596d4c0b969c15928d2dc49a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8713a57b5ef54d7ba6c923dda916e00a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"877b253d9ef04b259c21ffee41c8ab46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"8797169c11ff4d7b91587933b9afb0a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9db72da89ea847d1b160c2c1de40d3d2","IPY_MODEL_eb66ffb75c4d4b65ac4da4ffcb54290a","IPY_MODEL_3dc63a90c72d4039ab5b34c3d16f0d10"],"layout":"IPY_MODEL_6862327b356e4e2ca25f0513c7e9d6f3"}},"87f924111f314c688f17701ebfffcf03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89c2f5bab5fa4216b3fdb023f699d674":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91c0aa2cc0424747a99dc3bfd8087613","placeholder":"​","style":"IPY_MODEL_6af7ee08db7e4ea8924c0a85e6bd4063","value":" 56311/60000 [00:00&lt;00:00, 187793.92 examples/s]"}},"8b1282516fb3453c8b502aa2929a3274":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2597922d130d45b5ba9ae03d75843e9f","placeholder":"​","style":"IPY_MODEL_95f0e0f4dc73475995b93c36a8b29a18","value":"Waiting for wandb.init()...\r"}},"8d5f679f9edf4555a61c0f40234403fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91c0aa2cc0424747a99dc3bfd8087613":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"943855f9dc514fb79bf5db00bb843e63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5da59c84ecf4d45973f33ef8c842ef4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d35f08936ab40ddacb26c10b4ae24f6","value":1}},"95f0e0f4dc73475995b93c36a8b29a18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"970e677fc93d4c0ca3da0b5a98c393cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97782d3036594839b79f8a643b8f594b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98a9696582a7438a9b17d57d79176433":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a858ddcb2564a59a81724b5756666ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a981d182d0f49e98c4c0f05f721dae1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9a995e8c9a8548afa60d3dedfab4a31d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b1bc654d61c4ece846a81ad0fe7dea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9db72da89ea847d1b160c2c1de40d3d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afab0a05229c4028ba5661a11e3d1965","placeholder":"​","style":"IPY_MODEL_35b5734d896c4c5c82543ff9cd75fc94","value":"Generating train examples...: 100%"}},"9dec9dad484f4a81b249deb4a38d170c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73e08aa70fc4d04836ba49afb2a7d70","placeholder":"​","style":"IPY_MODEL_98a9696582a7438a9b17d57d79176433","value":"Best trial: 106. Best value: 0.935426: 100%"}},"9df361fba0ea4dee8ce42cdd83a21e09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a06fb6f2550c4427b2491cb040cdc0c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0b5126559ef420781ad1d733085c89a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a981d182d0f49e98c4c0f05f721dae1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85adbe13266d4d19bc96c87bc383959f","value":1}},"a0c00e34ffed47cbb1f6b57287028b48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23d9dd5446214bd598a36f317c06536c","placeholder":"​","style":"IPY_MODEL_27e3edcafcc04e368dbe56a1bf1c8ddc","value":"Dl Completed...: 100%"}},"a1f127b23fe04ed1a5bb0f6205298c21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e53e489923b841af898e41edab78bdb1","IPY_MODEL_bd2c97ca4d0f4cc38affe7064b87257f","IPY_MODEL_544a53f829924b2ea897cd7a69fe47a2"],"layout":"IPY_MODEL_224383963d2940a88613ded92dcd61f7"}},"a2f399667f2c49a99b26160e5f709112":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34cc9277585b4a2d9dcfe2c16684af38","placeholder":"​","style":"IPY_MODEL_76c0943a65ff487caa28ad27ffbaf6a1","value":"0.413 MB of 0.413 MB uploaded (0.000 MB deduped)\r"}},"a4b4181be57f44ab951f910030eaaf72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4b658b43bec4b5f97ba375358767a1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5da59c84ecf4d45973f33ef8c842ef4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac76743a1ca14e179ceca9529ceb46af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae3806317c14413291b9865183c651dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb609c72b6b54c529300aa1de26e85ff","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73904512ee7148d1a0cf5c726e1eca56","value":1}},"ae9af59097a14cebb71956a2f64a9d52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc135857c72541538f252d370c13d98e","placeholder":"​","style":"IPY_MODEL_e7c762e75ef6405aa15fe490f6cfa12e","value":"0.413 MB of 0.413 MB uploaded (0.000 MB deduped)\r"}},"aed8ccb9afae4f36a676f4acb47a791b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_bf4d7c377027456e9bb482c2ee314e08","IPY_MODEL_943855f9dc514fb79bf5db00bb843e63"],"layout":"IPY_MODEL_5884f51b64784a48aaedbfe8bbdec79e"}},"afab0a05229c4028ba5661a11e3d1965":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0580fa521f14ff5ba08cfb82ca0a715":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b23e63387da64960a1859413e1fb18dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b365788e058a4883b1a3d1787b7539ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b48ebb1a6ebb46379a7bbe8afbc02ef1","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a995e8c9a8548afa60d3dedfab4a31d","value":50}},"b48ebb1a6ebb46379a7bbe8afbc02ef1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49ee39f70314933b31a1607aa3a2b6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4fc5f9ace9949bd954c47730aa47c30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e77b274e9e3043419766364332584685","placeholder":"​","style":"IPY_MODEL_0c268ba2e4204ad49f0c6264922ea2c4","value":"0.558 MB of 0.558 MB uploaded (0.000 MB deduped)\r"}},"b5578096b4044a9d8e92e121a4a52614":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_c52b97aed80e4a7ea6defff4cd38c6e6","IPY_MODEL_556d72457a2d43e886b74b6c92898a52"],"layout":"IPY_MODEL_9df361fba0ea4dee8ce42cdd83a21e09"}},"b685e4b9b8bb4d95b02f11bd6aa609b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b4fc5f9ace9949bd954c47730aa47c30","IPY_MODEL_70cfac8edc924ea8a2a1407dd338e229"],"layout":"IPY_MODEL_daee404e504b44abbde9a25e5611949e"}},"b84125e7cc6f4ec3a845ada81a3d6d31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b98629ed54504bf4bfc025e9ddba1c59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad2de081a834264853cd1c7e7b018f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc3fc2bddd984167a4c19c77b9e1df5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd2c97ca4d0f4cc38affe7064b87257f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42545f885ba84947aafa04218d044661","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85e18f981fe34d97917f277e12a17e31","value":1}},"bf4d7c377027456e9bb482c2ee314e08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a06fb6f2550c4427b2491cb040cdc0c3","placeholder":"​","style":"IPY_MODEL_bf8960642f2f4f2893ee4da887065df3","value":"0.413 MB of 0.413 MB uploaded (0.000 MB deduped)\r"}},"bf8960642f2f4f2893ee4da887065df3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c23ae61b42a948b9944c03450a973436":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c46d3fd08e584bba8e535e16b9019e7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52b97aed80e4a7ea6defff4cd38c6e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39c82537d7174fe29ecd0e4066d860ff","placeholder":"​","style":"IPY_MODEL_6f098a7d302b4b4eb6cddb783f341927","value":"0.558 MB of 0.558 MB uploaded (0.000 MB deduped)\r"}},"c5934ea4e6b546ef8ed436ef94b15d68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77ae238d2a5406ca9d955d9a85a8c4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8244541ba404065bafca41c1bc2a394":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_6ebe49746719417ca1c10382e2566f4f","IPY_MODEL_5e217a61376346eaa82731b5141b86ff"],"layout":"IPY_MODEL_34f53226f77c4f03bdcdcd3d17abb2f7"}},"c8286619f3af40738ea7756802f19fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e664e7998684067958abe6721b48c6d","placeholder":"​","style":"IPY_MODEL_b84125e7cc6f4ec3a845ada81a3d6d31","value":"Generating test examples...: 100%"}},"cbe9e82d8c56486db07b194bddc10728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_2238dc58939e4c1a95b5b2f0200bfb39","IPY_MODEL_4680576525e84ded8c26a40f17febdfb"],"layout":"IPY_MODEL_86caf9d5f4dd49f0b4203ca42f98ea4e"}},"cd51f0066c434788b9d473791b145933":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_08fd7ebe0e0846cd8144e2bf4b45d4c5","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68a2ddb2d5364f3c91bb9f70473ffe5b","value":10000}},"d0814e0604854ef69c189aaae4eac37e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d1ed622743bc40b9b92804681f5fff40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bad2de081a834264853cd1c7e7b018f4","placeholder":"​","style":"IPY_MODEL_3d5da24d9c5f4b6e8eddf4e5f4ef7a62","value":"Shuffling /root/tensorflow_datasets/fashion_mnist/3.0.1.incomplete67ZFKH/fashion_mnist-train.tfrecord*...:  94%"}},"d2aff4add8c34bf38f96f938a6dfd5c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_86e34552596d4c0b969c15928d2dc49a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_261fb5f8416c4d3ca998478965eee45f","value":1}},"d35707178569480a96c122b5d01d9244":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d382bc788b3b4f36ac9f9edd9e9c9e78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6695f7408124c60978d9e50845dc8b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"daee404e504b44abbde9a25e5611949e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db834ac272d44004a5d2f7b3191a7f6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc135857c72541538f252d370c13d98e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddb3acb203d54fca8e914c70715ea10d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_010199f2d12b47f4b90a6219dc36b65c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc3fc2bddd984167a4c19c77b9e1df5b","value":2}},"de281196308d45378139e9fcc8ca6819":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18bdadc2dab7420e9ffe8b2f3b888937","IPY_MODEL_a0b5126559ef420781ad1d733085c89a","IPY_MODEL_07dc706d3ee444e69b76fe25cd96f79c"],"layout":"IPY_MODEL_741413001d3f42de8400a16b6a555e08"}},"de415dd7b6584f7f9337c7acf08f748f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df4e9c9fc9b3427ab8b28c690225b4d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8286619f3af40738ea7756802f19fd0","IPY_MODEL_cd51f0066c434788b9d473791b145933","IPY_MODEL_46e52340bad84ee2872587c906d595df"],"layout":"IPY_MODEL_f5d018a4ceb843daa9c1898d0582a957"}},"e32e1e9fbee74b318a7d425d2a25221f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e397ccd738c8498097c17b957494ba95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4bdc4b02c8b416ca6b0ab9b2572a145":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_58796a1da158479c93405a6eef94ebfc","IPY_MODEL_3d91608e5968489c8286fb696d389ea5"],"layout":"IPY_MODEL_286dd0e1257742f4ac0162606c35a5ba"}},"e52f6e1b90d949f2a39db2815d54c224":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53e489923b841af898e41edab78bdb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_478da94a66ae4da2942100615115a397","placeholder":"​","style":"IPY_MODEL_8d5f679f9edf4555a61c0f40234403fd","value":"Extraction completed...: 100%"}},"e62576e36a8c4ef6a62c635d0806d65b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e734efb46fe148d3b130c0ebca4ef6ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b1bc654d61c4ece846a81ad0fe7dea5","placeholder":"​","style":"IPY_MODEL_f74582142cff4fb4b1543bdf61f61a8d","value":"Best trial: 47. Best value: 0.934685: 100%"}},"e77b274e9e3043419766364332584685":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c762e75ef6405aa15fe490f6cfa12e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9c689b836db43f18278eeb2e828819e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_051d33dc7b284f1c85a724c92cac9926","placeholder":"​","style":"IPY_MODEL_c23ae61b42a948b9944c03450a973436","value":"0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\r"}},"eaaebfccd43643eca52cae967b6a125e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb609c72b6b54c529300aa1de26e85ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"eb66ffb75c4d4b65ac4da4ffcb54290a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_23b570bd35b94248a5a2383ab8e21d64","max":60000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ecd0eafac1374c6f8922f824e5e3fd3f","value":60000}},"ecd0eafac1374c6f8922f824e5e3fd3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed626d35b7bf4c6e90713bd41380ceca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee0b95342c54298ae0725f9aaecb0e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e397ccd738c8498097c17b957494ba95","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6695f7408124c60978d9e50845dc8b3","value":1}},"f14aa51d4cc44b6ea282f852a8629f69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f323825e55814f5f932492a729b6342a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f5d018a4ceb843daa9c1898d0582a957":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f73e08aa70fc4d04836ba49afb2a7d70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74582142cff4fb4b1543bdf61f61a8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fce18283bf994241b823792025c6846f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a858ddcb2564a59a81724b5756666ee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b6d3b8fe02a4533b48b5dcd982cc090","value":0.12012655644008982}},"fd9114b495684e799ac0740b51e05a19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f14aa51d4cc44b6ea282f852a8629f69","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1746adab78764cabac2df6b2c7e3606a","value":1}},"fd999d703a54440db93b2841a3bdc6e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./12_Representation_learning.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Representation learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./NumPy_tutorial.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Numpy - multidimensional data arrays for python</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>