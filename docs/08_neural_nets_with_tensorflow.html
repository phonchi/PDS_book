<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.306">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="phonchi">
<meta name="dcterms.date" content="2023-04-24">

<title>Practical and Innovative Analytics in Data Science - 8&nbsp; Introduction to Artificial Neural Networks - Tensorflow</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./09_Convolutional_NeuralNetworks_tensorflow.html" rel="next">
<link href="./07_Deploy.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./08_neural_nets_with_tensorflow.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to Artificial Neural Networks - Tensorflow</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Practical and Innovative Analytics in Data Science</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_end_to_end_machine_learning_project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">End-to-end Machine Learning project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Framing the problem and constructing the dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Relational_Database_and_data_wrangling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Relational Database and data wrangling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Clean_feature_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data cleaning and feature engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Feature_selection_extraction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Feature selection and extraction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_XAI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Explainable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Deploy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Deploy and monitoring</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_neural_nets_with_tensorflow.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to Artificial Neural Networks - Tensorflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_Convolutional_NeuralNetworks_tensorflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Image processing with Convolutional Neural Networks - Tensorflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_Recurrent_Neural_Networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence Processing with RNNs and Attention - Tensforflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./NumPy_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Numpy - multidimensional data arrays for python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Colab_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Introduction to Colab</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kaggle-explore.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Introduction to Kaggle</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_neural_nets_with_pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Introduction to Artificial Neural Networks - Pytorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_Convolutional_NeuralNetworks_pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Image processing with Convolutional Neural Networks - Pytorch</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#setup" id="toc-setup" class="nav-link active" data-scroll-target="#setup"><span class="header-section-number">8.1</span> Setup</a></li>
  <li><a href="#perceptrons" id="toc-perceptrons" class="nav-link" data-scroll-target="#perceptrons"><span class="header-section-number">8.2</span> Perceptrons</a></li>
  <li><a href="#tensorflow-playground" id="toc-tensorflow-playground" class="nav-link" data-scroll-target="#tensorflow-playground"><span class="header-section-number">8.3</span> Tensorflow Playground</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">8.3.1</span> Introduction</a></li>
  <li><a href="#try-it" id="toc-try-it" class="nav-link" data-scroll-target="#try-it"><span class="header-section-number">8.3.2</span> Try it</a></li>
  </ul></li>
  <li><a href="#building-an-image-classifier-using-the-sequential-api" id="toc-building-an-image-classifier-using-the-sequential-api" class="nav-link" data-scroll-target="#building-an-image-classifier-using-the-sequential-api"><span class="header-section-number">8.4</span> Building an Image Classifier Using the Sequential API</a>
  <ul class="collapse">
  <li><a href="#creating-the-model-using-the-sequential-api" id="toc-creating-the-model-using-the-sequential-api" class="nav-link" data-scroll-target="#creating-the-model-using-the-sequential-api"><span class="header-section-number">8.4.1</span> Creating the Model Using the Sequential API</a></li>
  <li><a href="#compiling-the-model" id="toc-compiling-the-model" class="nav-link" data-scroll-target="#compiling-the-model"><span class="header-section-number">8.4.2</span> Compiling the Model</a></li>
  <li><a href="#training-and-evaluating-the-model" id="toc-training-and-evaluating-the-model" class="nav-link" data-scroll-target="#training-and-evaluating-the-model"><span class="header-section-number">8.4.3</span> Training and Evaluating the Model</a></li>
  <li><a href="#using-the-model-to-make-predictions" id="toc-using-the-model-to-make-predictions" class="nav-link" data-scroll-target="#using-the-model-to-make-predictions"><span class="header-section-number">8.4.4</span> Using the Model to Make Predictions</a></li>
  <li><a href="#try-different-network-architecture-and-hyperparameters" id="toc-try-different-network-architecture-and-hyperparameters" class="nav-link" data-scroll-target="#try-different-network-architecture-and-hyperparameters"><span class="header-section-number">8.4.5</span> Try different network architecture and hyperparameters</a></li>
  </ul></li>
  <li><a href="#building-a-regression-mlp-using-the-sequential-api" id="toc-building-a-regression-mlp-using-the-sequential-api" class="nav-link" data-scroll-target="#building-a-regression-mlp-using-the-sequential-api"><span class="header-section-number">8.5</span> Building a Regression MLP Using the Sequential API</a></li>
  <li><a href="#building-complex-models-using-the-functional-api-optional" id="toc-building-complex-models-using-the-functional-api-optional" class="nav-link" data-scroll-target="#building-complex-models-using-the-functional-api-optional"><span class="header-section-number">8.6</span> Building Complex Models Using the Functional API (Optional)</a></li>
  <li><a href="#building-dynamic-models-using-the-subclassing-api-optional" id="toc-building-dynamic-models-using-the-subclassing-api-optional" class="nav-link" data-scroll-target="#building-dynamic-models-using-the-subclassing-api-optional"><span class="header-section-number">8.7</span> Building Dynamic Models Using the Subclassing API (Optional)</a></li>
  <li><a href="#saving-and-restoring" id="toc-saving-and-restoring" class="nav-link" data-scroll-target="#saving-and-restoring"><span class="header-section-number">8.8</span> Saving and Restoring</a></li>
  <li><a href="#using-callbacks-during-training" id="toc-using-callbacks-during-training" class="nav-link" data-scroll-target="#using-callbacks-during-training"><span class="header-section-number">8.9</span> Using Callbacks during Training</a></li>
  <li><a href="#tensorboard" id="toc-tensorboard" class="nav-link" data-scroll-target="#tensorboard"><span class="header-section-number">8.10</span> TensorBoard</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">8.11</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to Artificial Neural Networks - Tensorflow</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>phonchi </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 24, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>


<table align="left">
<tbody><tr><td>
<a href="https://colab.research.google.com/github/phonchi/nsysu-math608/blob/master/static_files/presentations/08_neural_nets_with_tensorflow.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
</td>
<td>
<a target="_blank" href="https://kaggle.com/kernels/welcome?src=https://github.com/phonchi/nsysu-math608/blob/master/static_files/presentations/08_neural_nets_with_tensorflow.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg"></a>
</td>

</tr></tbody></table>
<p><br></p>
<section id="setup" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="setup"><span class="header-section-number">8.1</span> Setup</h2>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:8105,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307503889,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Python ≥3.7 is recommended</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> sys</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="cf">assert</span> sys.version_info <span class="op">&gt;=</span> (<span class="dv">3</span>, <span class="dv">7</span>)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> os</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> time <span class="im">import</span> strftime</span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co"># Scikit-Learn ≥1.01 is recommended</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">from</span> packaging <span class="im">import</span> version</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">import</span> sklearn</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Perceptron</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="cf">assert</span> version.parse(sklearn.__version__) <span class="op">&gt;=</span> version.parse(<span class="st">"1.0.1"</span>)</span>
<span id="cb1-17"><a href="#cb1-17"></a></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co"># Tensorflow ≥2.8.0 is recommended</span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="cf">assert</span> version.parse(tf.__version__) <span class="op">&gt;=</span> version.parse(<span class="st">"2.8.0"</span>)</span>
<span id="cb1-21"><a href="#cb1-21"></a></span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="co"># Common imports</span></span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> ListedColormap</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>plt.rc(<span class="st">'font'</span>, size<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb1-29"><a href="#cb1-29"></a>plt.rc(<span class="st">'axes'</span>, labelsize<span class="op">=</span><span class="dv">14</span>, titlesize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb1-30"><a href="#cb1-30"></a>plt.rc(<span class="st">'legend'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb1-31"><a href="#cb1-31"></a>plt.rc(<span class="st">'xtick'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb1-32"><a href="#cb1-32"></a>plt.rc(<span class="st">'ytick'</span>, labelsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb1-33"><a href="#cb1-33"></a></span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="co"># to make this notebook's output stable across runs</span></span>
<span id="cb1-35"><a href="#cb1-35"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-36"><a href="#cb1-36"></a>tf.random.set_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:15640,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307519484,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="e3b7514c-52cd-4191-b325-2628a5545b37" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="cf">if</span> <span class="st">"google.colab"</span> <span class="kw">in</span> sys.modules:  <span class="co"># extra code</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span class="op">%</span>pip install <span class="op">-</span>q <span class="op">-</span>U tensorboard<span class="op">-</span>plugin<span class="op">-</span>profile</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 17.4 MB/s eta 0:00:00</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1163,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307520638,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="cf">if</span> <span class="kw">not</span> tf.config.list_physical_devices(<span class="st">'GPU'</span>):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="bu">print</span>(<span class="st">"No GPU was detected. Neural nets can be very slow without a GPU."</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="cf">if</span> <span class="st">"google.colab"</span> <span class="kw">in</span> sys.modules:</span>
<span id="cb4-4"><a href="#cb4-4"></a>        <span class="bu">print</span>(<span class="st">"Go to Runtime &gt; Change runtime and select a GPU hardware "</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>              <span class="st">"accelerator."</span>)</span>
<span id="cb4-6"><a href="#cb4-6"></a>    <span class="cf">if</span> <span class="st">"kaggle_secrets"</span> <span class="kw">in</span> sys.modules:</span>
<span id="cb4-7"><a href="#cb4-7"></a>        <span class="bu">print</span>(<span class="st">"Go to Settings &gt; Accelerator and select GPU."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="perceptrons" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="perceptrons"><span class="header-section-number">8.2</span> Perceptrons</h2>
<p>Let’s use the iris dataset from openml. This is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica</p>
<center>
<img src="https://drive.google.com/uc?id=1YdzLV9grRNMQaaDz7JHEhj_TbTzr9NDJ" alt="drawing" width="600">
</center>
<p>You can find more information about the dataset <a href="https://api.openml.org/d/61">here</a>.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:23,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307520640,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="056b663e-72a6-485b-88eb-5dcd37fdc1fb" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>iris <span class="op">=</span> load_iris(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="bu">print</span>(iris.data.shape)</span>
<span id="cb5-3"><a href="#cb5-3"></a>iris.data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(150, 4)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">

  <div id="df-dfba33aa-1524-459f-b9a0-0fed4eb8a415">
    <div class="colab-df-container">
      <div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal length (cm)</th>
<th data-quarto-table-cell-role="th">sepal width (cm)</th>
<th data-quarto-table-cell-role="th">petal length (cm)</th>
<th data-quarto-table-cell-role="th">petal width (cm)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
</tr>
</tbody>
</table>


</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-dfba33aa-1524-459f-b9a0-0fed4eb8a415')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-dfba33aa-1524-459f-b9a0-0fed4eb8a415 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-dfba33aa-1524-459f-b9a0-0fed4eb8a415');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<p>For simplicity, here we perform binary classification based on two features.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:239,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307558906,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="8bafd4c5-ca72-4f6d-b151-bb78d9f11cc0" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Choose two features and setup a binary classification problem</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>X <span class="op">=</span> iris.data[[<span class="st">"petal length (cm)"</span>, <span class="st">"petal width (cm)"</span>]].to_numpy()</span>
<span id="cb7-3"><a href="#cb7-3"></a>y <span class="op">=</span> (iris.target <span class="op">==</span> <span class="dv">0</span>)  <span class="co"># Iris setosa</span></span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="co"># Build Perceptron model</span></span>
<span id="cb7-6"><a href="#cb7-6"></a>per_clf <span class="op">=</span> Perceptron(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-7"><a href="#cb7-7"></a>per_clf.fit(X, y)</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co"># Test on two new instances</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>X_new <span class="op">=</span> [[<span class="dv">2</span>, <span class="fl">0.5</span>], [<span class="dv">3</span>, <span class="dv">1</span>]]</span>
<span id="cb7-11"><a href="#cb7-11"></a>y_pred <span class="op">=</span> per_clf.predict(X_new)  <span class="co"># predicts True and False for these 2 flowers</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>array([ True, False])</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:793,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307576920,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="a6114c98-d4c3-4daf-fbad-02503288ad0e" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Plot the decision boundary</span></span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a>a <span class="op">=</span> <span class="op">-</span>per_clf.coef_[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">/</span> per_clf.coef_[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb9-4"><a href="#cb9-4"></a>b <span class="op">=</span> <span class="op">-</span>per_clf.intercept_ <span class="op">/</span> per_clf.coef_[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb9-5"><a href="#cb9-5"></a>axes <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">0</span>, <span class="dv">2</span>]</span>
<span id="cb9-6"><a href="#cb9-6"></a>x0, x1 <span class="op">=</span> np.meshgrid(</span>
<span id="cb9-7"><a href="#cb9-7"></a>    np.linspace(axes[<span class="dv">0</span>], axes[<span class="dv">1</span>], <span class="dv">500</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb9-8"><a href="#cb9-8"></a>    np.linspace(axes[<span class="dv">2</span>], axes[<span class="dv">3</span>], <span class="dv">200</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb9-9"><a href="#cb9-9"></a>)</span>
<span id="cb9-10"><a href="#cb9-10"></a>X_new <span class="op">=</span> np.c_[x0.ravel(), x1.ravel()]</span>
<span id="cb9-11"><a href="#cb9-11"></a>y_predict <span class="op">=</span> per_clf.predict(X_new)</span>
<span id="cb9-12"><a href="#cb9-12"></a>zz <span class="op">=</span> y_predict.reshape(x0.shape)</span>
<span id="cb9-13"><a href="#cb9-13"></a>custom_cmap <span class="op">=</span> ListedColormap([<span class="st">'#9898ff'</span>, <span class="st">'#fafab0'</span>])</span>
<span id="cb9-14"><a href="#cb9-14"></a></span>
<span id="cb9-15"><a href="#cb9-15"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">3</span>))</span>
<span id="cb9-16"><a href="#cb9-16"></a>plt.plot(X[y <span class="op">==</span> <span class="dv">0</span>, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">0</span>, <span class="dv">1</span>], <span class="st">"bs"</span>, label<span class="op">=</span><span class="st">"Not Iris setosa"</span>)</span>
<span id="cb9-17"><a href="#cb9-17"></a>plt.plot(X[y <span class="op">==</span> <span class="dv">1</span>, <span class="dv">0</span>], X[y <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], <span class="st">"yo"</span>, label<span class="op">=</span><span class="st">"Iris setosa"</span>)</span>
<span id="cb9-18"><a href="#cb9-18"></a>plt.plot([axes[<span class="dv">0</span>], axes[<span class="dv">1</span>]], [a <span class="op">*</span> axes[<span class="dv">0</span>] <span class="op">+</span> b, a <span class="op">*</span> axes[<span class="dv">1</span>] <span class="op">+</span> b], <span class="st">"k-"</span>,</span>
<span id="cb9-19"><a href="#cb9-19"></a>         linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb9-20"><a href="#cb9-20"></a>plt.contourf(x0, x1, zz, cmap<span class="op">=</span>custom_cmap)</span>
<span id="cb9-21"><a href="#cb9-21"></a>plt.xlabel(<span class="st">"Petal length"</span>)</span>
<span id="cb9-22"><a href="#cb9-22"></a>plt.ylabel(<span class="st">"Petal width"</span>)</span>
<span id="cb9-23"><a href="#cb9-23"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb9-24"><a href="#cb9-24"></a>plt.axis(axes)</span>
<span id="cb9-25"><a href="#cb9-25"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="08_neural_nets_with_tensorflow_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="tensorflow-playground" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="tensorflow-playground"><span class="header-section-number">8.3</span> Tensorflow Playground</h2>
<p><a href="http://playground.tensorflow.org/">http://playground.tensorflow.org/</a></p>
<section id="introduction" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">8.3.1</span> Introduction</h3>
<p>The Playground provides mainly 6 different types of datasets. 1. Classification: Circle, Exclusive or, Gaussian, spiral. 2. Regression: Plane, Multi Gaussian.</p>
<p>Small circle points are represented as data points that correspond to Positive (+) and Negative (-). Positive represented by blue, Negative represented by orange. These same colours are used in representing Data, Neuron, Weight values.</p>
<p>The datasets all have 2 input features and 1 output label. The 2 input features, <code>X1</code> and <code>X2</code>, are represented by the coordinates.</p>
<ul>
<li><p>The data points (represented by small circles) are initially colored orange or blue, which correspond to positive one and negative one.</p></li>
<li><p>In the hidden layers, the lines are colored by the weights of the connections between neurons. Blue shows a positive weight, which means the network is using that output of the neuron as given. An orange line shows that the network is assiging a negative weight.</p></li>
<li><p>In the output layer, the dots are colored orange or blue depending on their original values. The background color shows what the network is predicting for a particular area. <strong>The intensity of the color shows how confident that prediction is</strong></p></li>
</ul>
</section>
<section id="try-it" class="level3" data-number="8.3.2">
<h3 data-number="8.3.2" class="anchored" data-anchor-id="try-it"><span class="header-section-number">8.3.2</span> Try it</h3>
<ul>
<li><p><strong>Layers and patterns</strong>: try training the default neural network by clicking the “Run” button (top left). Notice how it quickly finds a good solution for the classification task. Notice that the neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns). In general, the more layers, the more complex the patterns can be.</p></li>
<li><p><strong>Activation function</strong>: try replacing the Tanh activation function with the ReLU activation function, and train the network again. Notice that it finds a solution even faster.</p></li>
<li><p><strong>Local minima</strong>: modify the network architecture to have just one hidden layer with three neurons. Train it multiple times (to reset the network weights, just add and remove a neuron). Notice that the training time varies a lot, and sometimes it even gets stuck in a local minimum.</p></li>
<li><p><strong>Too small</strong>: now remove one neuron to keep just 2. Notice that the neural network is now incapable of finding a good solution, even if you try multiple times. The model has too few parameters and it systematically underfits the training set.</p></li>
<li><p><strong>Large enough</strong>: next, set the number of neurons to 8 and train the network several times. Notice that it is now consistently fast and never gets stuck. This highlights an important finding in neural network theory: large neural networks almost never get stuck in local minima, and even when they do these local optima are almost as good as the global optimum. However, they can still get stuck on long plateaus for a long time.</p></li>
<li><p><strong>Deep net and vanishing gradients</strong>: now change the dataset to be the spiral (bottom right dataset under “DATA”). Change the network architecture to have 4 hidden layers with 4 neurons each. Notice that training takes much longer, and often gets stuck on plateaus for long periods of time. Also notice that the neurons in the highest layers (i.e.&nbsp;on the right) tend to evolve faster than the neurons in the lowest layers (i.e.&nbsp;on the left). This problem, called the “vanishing gradients” problem, can be alleviated using better weight initialization and other techniques, better optimizers (such as AdaGrad or Adam), or using Batch Normalization.</p></li>
</ul>
</section>
</section>
<section id="building-an-image-classifier-using-the-sequential-api" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="building-an-image-classifier-using-the-sequential-api"><span class="header-section-number">8.4</span> Building an Image Classifier Using the Sequential API</h2>
<p>First let’s import TensorFlow and Keras.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:234,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307789931,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="29864767-b9bd-4d84-c284-b8f7cb3b6761" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>tf.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>'2.12.0'</code></pre>
</div>
</div>
<center>
<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cf69072577204457bcb409e686b11e28~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp" alt="drawing" width="600">
</center>
<div data-align="center">
source: https://juejin.cn/post/7096480975512666142
</div>
<p>First, we need to load a dataset. We will tackle Fashion MNIST, which is a drop-in replacement of MNIST. It has the exact same format as MNIST (70,000 grayscale images of <span class="math inline">\(28 \times 28\)</span> pixels each, with 10 classes), but the images represent fashion items rather than handwritten digits, so each class is more diverse and the problem turns out to be significantly more challenging than MNIST. <strong>For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST.</strong></p>
<p>You can find more built-in dataset <a href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets">here</a>.</p>
<p>Let’s start by loading the fashion MNIST dataset. <code>tf.Keras</code> has a number of functions to load popular datasets in <code>tf.keras.datasets</code>. The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1026,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307848318,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="e68ad21f-c0bf-4b6f-96a6-3f1c54f5be8a" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>fashion_mnist <span class="op">=</span> tf.keras.datasets.fashion_mnist.load_data() <span class="co"># use tf.keras not keras.io (multibackend keras)</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>(X_train_full, y_train_full), (X_test, y_test) <span class="op">=</span> fashion_mnist</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
29515/29515 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26421880/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
5148/5148 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4422102/4422102 [==============================] - 0s 0us/step</code></pre>
</div>
</div>
<p>The training set contains 60,000 grayscale images, each 28x28 pixels. Notice that the order of Tensorflow is <code>[batch, height, width, channel]</code>.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:252,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307862275,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="fbcacfdc-7539-41b4-cbd9-7bc18892bca4" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>X_train_full.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(60000, 28, 28)</code></pre>
</div>
</div>
<p>Each pixel intensity is represented as a byte (0 to 255):</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:351,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307922417,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="9d07271e-8fde-4981-ba8c-d5e0b031bf2e" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>X_train_full.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>dtype('uint8')</code></pre>
</div>
</div>
<p>Let’s split the full training set into a validation set and a (smaller) training set. Now the validation set contains 5,000 images, and the test set contains 10,000 images. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:254,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307937369,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>X_train, y_train <span class="op">=</span> X_train_full[:<span class="op">-</span><span class="dv">5000</span>], y_train_full[:<span class="op">-</span><span class="dv">5000</span>]</span>
<span id="cb18-2"><a href="#cb18-2"></a>X_valid, y_valid <span class="op">=</span> X_train_full[<span class="op">-</span><span class="dv">5000</span>:], y_train_full[<span class="op">-</span><span class="dv">5000</span>:]</span>
<span id="cb18-3"><a href="#cb18-3"></a>X_train, X_valid, X_test <span class="op">=</span> X_train <span class="op">/</span> <span class="fl">255.</span>, X_valid <span class="op">/</span> <span class="fl">255.</span>, X_test <span class="op">/</span> <span class="fl">255.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The labels are the class IDs (represented as <code>uint8</code>), from 0 to 9:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:239,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307940724,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="211a8ffc-4c4c-47b9-e75a-9f1e4f48e0a1" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>y_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>array([9, 0, 0, ..., 9, 0, 2], dtype=uint8)</code></pre>
</div>
</div>
<p>Here are the corresponding class names:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:248,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307949216,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>class_names <span class="op">=</span> [<span class="st">"T-shirt/top"</span>, <span class="st">"Trouser"</span>, <span class="st">"Pullover"</span>, <span class="st">"Dress"</span>, <span class="st">"Coat"</span>,</span>
<span id="cb21-2"><a href="#cb21-2"></a>               <span class="st">"Sandal"</span>, <span class="st">"Shirt"</span>, <span class="st">"Sneaker"</span>, <span class="st">"Bag"</span>, <span class="st">"Ankle boot"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So the first image in the training set is a ankle boot:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:236,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307951064,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="f21e9428-088b-47c5-a3bb-81f88d8b00b5" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>class_names[y_train[<span class="dv">0</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>'Ankle boot'</code></pre>
</div>
</div>
<p>Let’s take a look at a sample of the images in the dataset:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2911,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682307955172,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="afb059e9-ae56-403f-9454-351b2f8163b8" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>n_rows <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb24-2"><a href="#cb24-2"></a>n_cols <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb24-3"><a href="#cb24-3"></a>plt.figure(figsize<span class="op">=</span>(n_cols <span class="op">*</span> <span class="fl">1.5</span>, n_rows <span class="op">*</span> <span class="fl">1.5</span>))</span>
<span id="cb24-4"><a href="#cb24-4"></a><span class="cf">for</span> row <span class="kw">in</span> <span class="bu">range</span>(n_rows):</span>
<span id="cb24-5"><a href="#cb24-5"></a>    <span class="cf">for</span> col <span class="kw">in</span> <span class="bu">range</span>(n_cols):</span>
<span id="cb24-6"><a href="#cb24-6"></a>        index <span class="op">=</span> n_cols <span class="op">*</span> row <span class="op">+</span> col</span>
<span id="cb24-7"><a href="#cb24-7"></a>        plt.subplot(n_rows, n_cols, index <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb24-8"><a href="#cb24-8"></a>        plt.imshow(X_train[index], cmap<span class="op">=</span><span class="st">"binary"</span>, interpolation<span class="op">=</span><span class="st">"nearest"</span>)</span>
<span id="cb24-9"><a href="#cb24-9"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb24-10"><a href="#cb24-10"></a>        plt.title(class_names[y_train[index]])</span>
<span id="cb24-11"><a href="#cb24-11"></a>plt.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb24-12"><a href="#cb24-12"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="08_neural_nets_with_tensorflow_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="creating-the-model-using-the-sequential-api" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="creating-the-model-using-the-sequential-api"><span class="header-section-number">8.4.1</span> Creating the Model Using the Sequential API</h3>
<p>Now let’s build the neural network! Here is a classification MLP with two hidden layers:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2993,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308059717,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># This is the simplest kind of Keras model, for neural networks that are just </span></span>
<span id="cb25-2"><a href="#cb25-2"></a><span class="co"># composed of a single stack of layers, connected sequentially</span></span>
<span id="cb25-3"><a href="#cb25-3"></a></span>
<span id="cb25-4"><a href="#cb25-4"></a>model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb25-5"><a href="#cb25-5"></a>model.add(tf.keras.layers.InputLayer(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]))</span>
<span id="cb25-6"><a href="#cb25-6"></a>model.add(tf.keras.layers.Flatten())</span>
<span id="cb25-7"><a href="#cb25-7"></a>model.add(tf.keras.layers.Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>))</span>
<span id="cb25-8"><a href="#cb25-8"></a>model.add(tf.keras.layers.Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>))</span>
<span id="cb25-9"><a href="#cb25-9"></a>model.add(tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>We build the first layer and add it to the model. It is a <code>Flatten</code> layer whose role is simply to convert each input image into a 1D array: if it receives input data <code>X</code>, it computes <code>X.reshape(-1, 1)</code>. This layer does not have any parameters, it is just there to do some simple preprocessing. Since it is the first layer in the model, <strong>you should specify the input_shape</strong>: this does not include the batch size, only the shape of the instances.</li>
<li>Next we add a <code>Dense</code> hidden layer with 300 neurons. It will use the <code>ReLU</code> activation function. Each <code>Dense</code> layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of weight bias terms (one per neuron in the next layer).</li>
<li>Next we add a second <code>Dense</code> hidden layer with 100 neurons, also using the <code>ReLU</code> activation function.</li>
<li>Finally, we add a <code>Dense</code> output layer with 10 neurons (one per class), using the <code>softmax</code> activation function.</li>
</ul>
<p>You can find different activation functions <a href="https://keras.io/api/layers/activations/">here</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>[m <span class="cf">for</span> m <span class="kw">in</span> <span class="bu">dir</span>(tf.keras.activations) <span class="cf">if</span> <span class="kw">not</span> m.startswith(<span class="st">"_"</span>)], [m <span class="cf">for</span> m <span class="kw">in</span> <span class="bu">dir</span>(tf.keras.layers) <span class="cf">if</span> <span class="st">"relu"</span> <span class="kw">in</span> m.lower()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:231,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308071428,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># clear the session to reset the name counters</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>tf.keras.backend.clear_session()</span>
<span id="cb27-3"><a href="#cb27-3"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb27-4"><a href="#cb27-4"></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb27-5"><a href="#cb27-5"></a></span>
<span id="cb27-6"><a href="#cb27-6"></a><span class="co"># An alternative way to specify the sequential model</span></span>
<span id="cb27-7"><a href="#cb27-7"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb27-8"><a href="#cb27-8"></a>    tf.keras.layers.Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]),</span>
<span id="cb27-9"><a href="#cb27-9"></a>    tf.keras.layers.Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb27-10"><a href="#cb27-10"></a>    tf.keras.layers.Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb27-11"><a href="#cb27-11"></a>    tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb27-12"><a href="#cb27-12"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The model’s <code>summary()</code> method displays all the model’s layers, including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (None means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. Here we only have trainable parameters.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:247,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308077671,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="42597424-52c6-40cb-f7d7-08caf6e247eb" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 300)               235500    
                                                                 
 dense_1 (Dense)             (None, 100)               30100     
                                                                 
 dense_2 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 266,610
Trainable params: 266,610
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<p>Note that <code>Dense</code> layers often have a lot of parameters. For example, the first hidden layer has <code>784×300</code> connection weights, plus 300 bias terms, which adds up to 235,500 parameters! This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data!</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:562,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308097194,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="bceb6f5f-5f01-4a2d-889f-f7eac9785a45" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>tf.keras.utils.plot_model(model, <span class="st">"my_fashion_mnist_model.png"</span>, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<p><img src="08_neural_nets_with_tensorflow_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:426,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308108705,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="992fe23d-5ef5-4b46-c4cd-2fd4acbb7ce1" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>model.layers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>[&lt;keras.layers.reshaping.flatten.Flatten at 0x7f4eabcf41c0&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7f4eabc49c40&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7f4eabc490a0&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7f4eabc495e0&gt;]</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:9,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308108707,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="48ffedf5-00ac-4d68-f393-957bfc761194" data-execution_count="21">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>hidden1 <span class="op">=</span> model.layers[<span class="dv">1</span>]</span>
<span id="cb33-2"><a href="#cb33-2"></a>hidden1.name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>'dense'</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:2,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308109067,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="e1c2b0f6-6c2b-4462-805f-a54c9995e428" data-execution_count="22">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>model.get_layer(<span class="st">'dense_1'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>&lt;keras.layers.core.dense.Dense at 0x7f4eabc490a0&gt;</code></pre>
</div>
</div>
<p>All the parameters of a layer can be accessed using its <code>get_weights()</code> and <code>set_weights()</code> method. For a Dense layer, this includes both the connection weights and the bias terms:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:242,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308113906,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a>weights, biases <span class="op">=</span> hidden1.get_weights()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:4,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308116407,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="b8aa1b0d-aac6-45aa-d1b6-ecfe75554697" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a>weights, biases</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>(array([[-0.04090392,  0.05212015,  0.06563495, ..., -0.06813569,
         -0.07277503,  0.06356135],
        [-0.02273986, -0.03733981, -0.01904616, ...,  0.07051966,
         -0.03919001, -0.02506971],
        [ 0.06158407,  0.03164114,  0.04348575, ..., -0.07112216,
          0.047318  ,  0.01152001],
        ...,
        [-0.05140251, -0.0742506 ,  0.0284429 , ...,  0.04885727,
         -0.02155429, -0.05590397],
        [-0.07400953,  0.05923583, -0.02156794, ...,  0.03335793,
          0.01330438, -0.01484616],
        [-0.05129209, -0.01325566,  0.00971705, ...,  0.05628417,
         -0.04696462, -0.03978037]], dtype=float32),
 array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:235,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308128621,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="b426d837-ac3d-4b29-ec45-fd2410edce04" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>weights.shape, biases.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>((784, 300), (300,))</code></pre>
</div>
</div>
<p>Notice that the Dense layer initialized the connection weights randomly (which is needed to break symmetry), and the biases were just initialized to zeros, which is fine. If you ever want to use a different initialization method, you can set <code>kernel_initializer</code> (<strong>kernel is another name for the matrix of connection weights</strong>) or <code>bias_initializer</code> when creating the layer.</p>
<p>You can find more information <a href="https://keras.io/initializers/">here</a>.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:247,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308139127,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="108959d3-52fc-4c53-8b04-d1ab904d318c" data-execution_count="26">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>[name <span class="cf">for</span> name <span class="kw">in</span> <span class="bu">dir</span>(tf.keras.initializers) <span class="cf">if</span> <span class="kw">not</span> name.startswith(<span class="st">"_"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>['Constant',
 'GlorotNormal',
 'GlorotUniform',
 'HeNormal',
 'HeUniform',
 'Identity',
 'Initializer',
 'LecunNormal',
 'LecunUniform',
 'Ones',
 'Orthogonal',
 'RandomNormal',
 'RandomUniform',
 'TruncatedNormal',
 'VarianceScaling',
 'Zeros',
 'constant',
 'deserialize',
 'get',
 'glorot_normal',
 'glorot_uniform',
 'he_normal',
 'he_uniform',
 'identity',
 'lecun_normal',
 'lecun_uniform',
 'ones',
 'orthogonal',
 'random_normal',
 'random_uniform',
 'serialize',
 'truncated_normal',
 'variance_scaling',
 'zeros']</code></pre>
</div>
</div>
</section>
<section id="compiling-the-model" class="level3" data-number="8.4.2">
<h3 data-number="8.4.2" class="anchored" data-anchor-id="compiling-the-model"><span class="header-section-number">8.4.2</span> Compiling the Model</h3>
<p>After a model is created, you must call its <code>compile()</code> method to specify the loss function and the optimizer to use.</p>
<p>First, we use the <code>"sparse_categorical_crossentropy"</code> loss because we have sparse labels (i.e., for each instance there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. <strong>If instead we had one target probability per class for each instance</strong> (such as one-hot vectors, e.g.&nbsp;<code>[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]</code> to represent class 3), then we would need to use the <code>"categorical_crossentropy"</code> loss instead. If we were doing binary classification, then we would use the <code>"sigmoid"</code> activation function in the output layer instead of the <code>"softmax"</code> activation function, and we would use the <code>"binary_crossentropy"</code> loss.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:236,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308186828,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="27">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="co">#since this is a classifier, it’s useful to measure its "accuracy" during training</span></span>
<span id="cb44-2"><a href="#cb44-2"></a></span>
<span id="cb44-3"><a href="#cb44-3"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span>tf.keras.losses.sparse_categorical_crossentropy,</span>
<span id="cb44-4"><a href="#cb44-4"></a>              optimizer<span class="op">=</span>tf.keras.optimizers.SGD(),</span>
<span id="cb44-5"><a href="#cb44-5"></a>              metrics<span class="op">=</span>[tf.keras.metrics.sparse_categorical_accuracy])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is equivalent to:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb45-2"><a href="#cb45-2"></a>              optimizer<span class="op">=</span><span class="st">"sgd"</span>,</span>
<span id="cb45-3"><a href="#cb45-3"></a>              metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can easily convert between one-hot vector and class ID.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:244,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308196863,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="1908210a-d3de-4bf3-ef5b-0f8536209254" data-execution_count="28">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a>tf.keras.utils.to_categorical([<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">0</span>], num_classes<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:1,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308197212,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="b42f788a-0465-417b-9681-fb1db6c7d83b" data-execution_count="29">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>np.argmax(</span>
<span id="cb48-2"><a href="#cb48-2"></a>    [[<span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>],</span>
<span id="cb48-3"><a href="#cb48-3"></a>     [<span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>],</span>
<span id="cb48-4"><a href="#cb48-4"></a>     [<span class="fl">0.</span>, <span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>],</span>
<span id="cb48-5"><a href="#cb48-5"></a>     [<span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>]],</span>
<span id="cb48-6"><a href="#cb48-6"></a>    axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb48-7"><a href="#cb48-7"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>array([0, 5, 1, 0])</code></pre>
</div>
</div>
</section>
<section id="training-and-evaluating-the-model" class="level3" data-number="8.4.3">
<h3 data-number="8.4.3" class="anchored" data-anchor-id="training-and-evaluating-the-model"><span class="header-section-number">8.4.3</span> Training and Evaluating the Model</h3>
<p>Now the model is ready to be trained. For this we simply need to call its <code>fit()</code> method. We pass it the input features (<code>X_train</code>) and the target classes (<code>y_train</code>), as well as the number of epochs to train. We also pass a validation set (this is optional): Keras will measure the loss and the extra metrics on this set at the end of each epoch.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:203015,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308420173,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="414eac49-9d92-4d6a-821e-ae31d99aadbc" data-execution_count="30">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a><span class="co"># Instead of passing a validation set using the validation_data</span></span>
<span id="cb50-2"><a href="#cb50-2"></a><span class="co"># argument, you could instead set validation_split to the ratio of</span></span>
<span id="cb50-3"><a href="#cb50-3"></a><span class="co"># the training set that you want Keras to use for validation (e.g., 0.1).</span></span>
<span id="cb50-4"><a href="#cb50-4"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb50-5"><a href="#cb50-5"></a>                    validation_data<span class="op">=</span>(X_valid, y_valid))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/30
1719/1719 [==============================] - 10s 3ms/step - loss: 0.7154 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.4979 - val_sparse_categorical_accuracy: 0.8282
Epoch 2/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.4833 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.8326
Epoch 3/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.4374 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.4222 - val_sparse_categorical_accuracy: 0.8514
Epoch 4/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.4125 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.3931 - val_sparse_categorical_accuracy: 0.8620
Epoch 5/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3920 - val_sparse_categorical_accuracy: 0.8624
Epoch 6/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.3761 - sparse_categorical_accuracy: 0.8683 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8632
Epoch 7/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.3635 - sparse_categorical_accuracy: 0.8715 - val_loss: 0.3710 - val_sparse_categorical_accuracy: 0.8720
Epoch 8/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.8761 - val_loss: 0.3803 - val_sparse_categorical_accuracy: 0.8568
Epoch 9/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.3422 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.3510 - val_sparse_categorical_accuracy: 0.8742
Epoch 10/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.3324 - sparse_categorical_accuracy: 0.8814 - val_loss: 0.3536 - val_sparse_categorical_accuracy: 0.8756
Epoch 11/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.3241 - sparse_categorical_accuracy: 0.8855 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8634
Epoch 12/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.3167 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.8736
Epoch 13/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.3302 - val_sparse_categorical_accuracy: 0.8816
Epoch 14/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.3026 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.3392 - val_sparse_categorical_accuracy: 0.8792
Epoch 15/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.2966 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.8802
Epoch 16/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2897 - sparse_categorical_accuracy: 0.8960 - val_loss: 0.3331 - val_sparse_categorical_accuracy: 0.8790
Epoch 17/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2844 - sparse_categorical_accuracy: 0.8982 - val_loss: 0.3423 - val_sparse_categorical_accuracy: 0.8768
Epoch 18/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2790 - sparse_categorical_accuracy: 0.8995 - val_loss: 0.3291 - val_sparse_categorical_accuracy: 0.8820
Epoch 19/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2740 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.3524 - val_sparse_categorical_accuracy: 0.8724
Epoch 20/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2688 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.3194 - val_sparse_categorical_accuracy: 0.8848
Epoch 21/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2639 - sparse_categorical_accuracy: 0.9049 - val_loss: 0.3208 - val_sparse_categorical_accuracy: 0.8834
Epoch 22/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.2591 - sparse_categorical_accuracy: 0.9054 - val_loss: 0.3151 - val_sparse_categorical_accuracy: 0.8828
Epoch 23/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2547 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.3433 - val_sparse_categorical_accuracy: 0.8764
Epoch 24/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2496 - sparse_categorical_accuracy: 0.9112 - val_loss: 0.3240 - val_sparse_categorical_accuracy: 0.8832
Epoch 25/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2454 - sparse_categorical_accuracy: 0.9119 - val_loss: 0.3186 - val_sparse_categorical_accuracy: 0.8828
Epoch 26/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2418 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3136 - val_sparse_categorical_accuracy: 0.8852
Epoch 27/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9149 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.8854
Epoch 28/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.2339 - sparse_categorical_accuracy: 0.9164 - val_loss: 0.3137 - val_sparse_categorical_accuracy: 0.8900
Epoch 29/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2298 - sparse_categorical_accuracy: 0.9173 - val_loss: 0.3207 - val_sparse_categorical_accuracy: 0.8860
Epoch 30/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2267 - sparse_categorical_accuracy: 0.9194 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.8902</code></pre>
</div>
</div>
<p>The <code>fit()</code> method returns a History object containing the training parameters (<code>history.params</code>), the list of epochs it went through (<code>history.epoch</code>), and most importantly <strong>a dictionary</strong> (<code>history.history</code>) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308420173,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="7686e5b1-7ca5-4454-b145-f065bb385127" data-execution_count="31">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a>history.params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>{'verbose': 1, 'epochs': 30, 'steps': 1719}</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308420174,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="02eb7c86-622c-4b02-b124-94e48fe03105" data-execution_count="32">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a>history.history.keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy'])</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:736,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308420907,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="813aaf63-c754-40a3-99a8-d84426071858" data-execution_count="33">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1"></a>pd.DataFrame(history.history).plot(</span>
<span id="cb56-2"><a href="#cb56-2"></a>    figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>), xlim<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">29</span>], ylim<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], grid<span class="op">=</span><span class="va">True</span>, xlabel<span class="op">=</span><span class="st">"Epoch"</span>,</span>
<span id="cb56-3"><a href="#cb56-3"></a>    style<span class="op">=</span>[<span class="st">"r--"</span>, <span class="st">"r--."</span>, <span class="st">"b-"</span>, <span class="st">"b-*"</span>])</span>
<span id="cb56-4"><a href="#cb56-4"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower left"</span>)</span>
<span id="cb56-5"><a href="#cb56-5"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="08_neural_nets_with_tensorflow_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>You can tell that the model has not quite converged yet, as the validation loss is still going down, so you should probably continue training. It’s as simple as calling the <code>fit()</code> method again, <strong>since Keras just continues training where it left off</strong>.</p>
<p>Once you are satisfied with your model’s validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deploy the model to production. You can easily do this using the <code>evaluate()</code> method.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:503,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308421382,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="ce6ee621-e7a3-4e6b-aae6-0f2253f94a17" data-execution_count="34">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a>model.evaluate(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 [==============================] - 1s 2ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.8860</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>[0.32261887192726135, 0.8859999775886536]</code></pre>
</div>
</div>
<p><strong>It is common to get slightly lower performance on the test set than on the validation set, because the hyperparameters are tuned on the validation set</strong>, not the test set (however, in this example, we did not do any hyperparameter tuning, so the lower accuracy is just bad luck).</p>
</section>
<section id="using-the-model-to-make-predictions" class="level3" data-number="8.4.4">
<h3 data-number="8.4.4" class="anchored" data-anchor-id="using-the-model-to-make-predictions"><span class="header-section-number">8.4.4</span> Using the Model to Make Predictions</h3>
<p>Next, we can use the model’s <code>predict()</code> method to make predictions on new instances. We will just use the first 3 instances of the test set:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:227,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308437327,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="f85d45d9-fe84-4da8-db17-2fbd1c16e36e" data-execution_count="35">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a>X_new <span class="op">=</span> X_test[:<span class="dv">3</span>]</span>
<span id="cb60-2"><a href="#cb60-2"></a>y_proba <span class="op">=</span> model.predict(X_new)</span>
<span id="cb60-3"><a href="#cb60-3"></a>y_proba.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 113ms/step</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97],
       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],
       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],
      dtype=float32)</code></pre>
</div>
</div>
<p>As you can see, for each instance the model estimates one probability per class, from class 0 to class 9. For example, for the first image it estimates that the probability of class 9 (ankle boot) is 95%, the probability of class 7 (sneaker) is 4%, and the other classes are negligible. In other words, it “believes” it’s footwear, probably ankle boots, but it’s not entirely sure, it might be sneakers instead. If you only care about the class with the highest estimated probability then you can use the following code:</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:332,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308459348,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="35d8203c-f686-4545-b2ec-fb7f1d6062fd" data-execution_count="36">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a>y_pred <span class="op">=</span> y_proba.argmax(axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb63-2"><a href="#cb63-2"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>array([9, 2, 1])</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:225,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308466705,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="c1397cf8-4da6-4826-8223-b4d4ed61ad3a" data-execution_count="37">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1"></a>np.array(class_names)[y_pred]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>array(['Ankle boot', 'Pullover', 'Trouser'], dtype='&lt;U11')</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308467063,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="d4e3f005-efd1-48b8-f6ff-a08b97573bce" data-execution_count="38">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a>y_new <span class="op">=</span> y_test[:<span class="dv">3</span>] <span class="co"># The classifier actually classified all three images correctly</span></span>
<span id="cb67-2"><a href="#cb67-2"></a>y_new</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>array([9, 2, 1], dtype=uint8)</code></pre>
</div>
</div>
</section>
<section id="try-different-network-architecture-and-hyperparameters" class="level3" data-number="8.4.5">
<h3 data-number="8.4.5" class="anchored" data-anchor-id="try-different-network-architecture-and-hyperparameters"><span class="header-section-number">8.4.5</span> Try different network architecture and hyperparameters</h3>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:580,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308552783,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-execution_count="39">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1"></a><span class="co"># Sometimes applying BN before the activation function works better (there's a debate on this topic)</span></span>
<span id="cb69-2"><a href="#cb69-2"></a>model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb69-3"><a href="#cb69-3"></a>    tf.keras.layers.Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]),</span>
<span id="cb69-4"><a href="#cb69-4"></a>    tf.keras.layers.Dense(<span class="dv">300</span>, kernel_initializer<span class="op">=</span>tf.keras.initializers.HeNormal),</span>
<span id="cb69-5"><a href="#cb69-5"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb69-6"><a href="#cb69-6"></a>    tf.keras.layers.Activation(<span class="st">"swish"</span>),</span>
<span id="cb69-7"><a href="#cb69-7"></a>    tf.keras.layers.Dropout(rate<span class="op">=</span><span class="fl">0.3</span>),    </span>
<span id="cb69-8"><a href="#cb69-8"></a>    tf.keras.layers.Dense(<span class="dv">100</span>, kernel_initializer<span class="op">=</span>tf.keras.initializers.HeNormal),</span>
<span id="cb69-9"><a href="#cb69-9"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb69-10"><a href="#cb69-10"></a>    tf.keras.layers.Activation(<span class="st">"swish"</span>),</span>
<span id="cb69-11"><a href="#cb69-11"></a>    tf.keras.layers.Dropout(rate<span class="op">=</span><span class="fl">0.3</span>),    </span>
<span id="cb69-12"><a href="#cb69-12"></a>    tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb69-13"><a href="#cb69-13"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:24,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308552784,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="938e2e5e-1fb2-4ba1-9d28-e1b736379355" data-execution_count="40">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_1 (Flatten)         (None, 784)               0         
                                                                 
 dense_3 (Dense)             (None, 300)               235500    
                                                                 
 batch_normalization (BatchN  (None, 300)              1200      
 ormalization)                                                   
                                                                 
 activation (Activation)     (None, 300)               0         
                                                                 
 dropout (Dropout)           (None, 300)               0         
                                                                 
 dense_4 (Dense)             (None, 100)               30100     
                                                                 
 batch_normalization_1 (Batc  (None, 100)              400       
 hNormalization)                                                 
                                                                 
 activation_1 (Activation)   (None, 100)               0         
                                                                 
 dropout_1 (Dropout)         (None, 100)               0         
                                                                 
 dense_5 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 268,210
Trainable params: 267,410
Non-trainable params: 800
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:263512,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1682308852021,&quot;user&quot;:{&quot;displayName&quot;:&quot;phonchi chung&quot;,&quot;userId&quot;:&quot;13517391734500420886&quot;},&quot;user_tz&quot;:-480}" data-outputid="7a60bbbc-9372-4f20-ddd9-4b56fbd4d197" data-execution_count="41">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a>lr_scheduler <span class="op">=</span> tf.keras.callbacks.ReduceLROnPlateau(factor<span class="op">=</span><span class="fl">0.5</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb72-2"><a href="#cb72-2"></a>optimizer <span class="op">=</span> tf.keras.optimizers.SGD(learning_rate<span class="op">=</span><span class="fl">0.05</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb72-3"><a href="#cb72-3"></a></span>
<span id="cb72-4"><a href="#cb72-4"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>, optimizer<span class="op">=</span>optimizer, metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb72-5"><a href="#cb72-5"></a>n_epochs <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb72-6"><a href="#cb72-6"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span>n_epochs,</span>
<span id="cb72-7"><a href="#cb72-7"></a>                    validation_data<span class="op">=</span>(X_valid, y_valid),</span>
<span id="cb72-8"><a href="#cb72-8"></a>                    callbacks<span class="op">=</span>[lr_scheduler])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/30
1719/1719 [==============================] - 10s 5ms/step - loss: 0.5526 - accuracy: 0.8029 - val_loss: 0.4146 - val_accuracy: 0.8486 - lr: 0.0500
Epoch 2/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.4318 - accuracy: 0.8441 - val_loss: 0.3784 - val_accuracy: 0.8612 - lr: 0.0500
Epoch 3/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.3955 - accuracy: 0.8555 - val_loss: 0.3812 - val_accuracy: 0.8642 - lr: 0.0500
Epoch 4/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.3691 - accuracy: 0.8660 - val_loss: 0.3280 - val_accuracy: 0.8766 - lr: 0.0500
Epoch 5/30
1719/1719 [==============================] - 10s 6ms/step - loss: 0.3551 - accuracy: 0.8705 - val_loss: 0.3447 - val_accuracy: 0.8682 - lr: 0.0500
Epoch 6/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.3398 - accuracy: 0.8754 - val_loss: 0.3373 - val_accuracy: 0.8742 - lr: 0.0500
Epoch 7/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.3249 - accuracy: 0.8811 - val_loss: 0.3297 - val_accuracy: 0.8808 - lr: 0.0500
Epoch 8/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.3138 - accuracy: 0.8843 - val_loss: 0.3136 - val_accuracy: 0.8840 - lr: 0.0500
Epoch 9/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.3078 - accuracy: 0.8859 - val_loss: 0.3263 - val_accuracy: 0.8766 - lr: 0.0500
Epoch 10/30
1719/1719 [==============================] - 12s 7ms/step - loss: 0.2978 - accuracy: 0.8896 - val_loss: 0.3302 - val_accuracy: 0.8770 - lr: 0.0500
Epoch 11/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.2939 - accuracy: 0.8919 - val_loss: 0.3071 - val_accuracy: 0.8892 - lr: 0.0500
Epoch 12/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2828 - accuracy: 0.8945 - val_loss: 0.3982 - val_accuracy: 0.8634 - lr: 0.0500
Epoch 13/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2746 - accuracy: 0.8971 - val_loss: 0.3154 - val_accuracy: 0.8880 - lr: 0.0500
Epoch 14/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2706 - accuracy: 0.8998 - val_loss: 0.3416 - val_accuracy: 0.8774 - lr: 0.0500
Epoch 15/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2661 - accuracy: 0.9007 - val_loss: 0.3111 - val_accuracy: 0.8894 - lr: 0.0500
Epoch 16/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.2592 - accuracy: 0.9032 - val_loss: 0.2984 - val_accuracy: 0.8900 - lr: 0.0500
Epoch 17/30
1719/1719 [==============================] - 10s 6ms/step - loss: 0.2547 - accuracy: 0.9049 - val_loss: 0.3290 - val_accuracy: 0.8878 - lr: 0.0500
Epoch 18/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2477 - accuracy: 0.9068 - val_loss: 0.3126 - val_accuracy: 0.8872 - lr: 0.0500
Epoch 19/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2438 - accuracy: 0.9081 - val_loss: 0.2994 - val_accuracy: 0.8914 - lr: 0.0500
Epoch 20/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.2407 - accuracy: 0.9102 - val_loss: 0.3374 - val_accuracy: 0.8800 - lr: 0.0500
Epoch 21/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.2346 - accuracy: 0.9123 - val_loss: 0.3032 - val_accuracy: 0.8880 - lr: 0.0500
Epoch 22/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2105 - accuracy: 0.9206 - val_loss: 0.2887 - val_accuracy: 0.8958 - lr: 0.0250
Epoch 23/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2019 - accuracy: 0.9258 - val_loss: 0.3020 - val_accuracy: 0.8984 - lr: 0.0250
Epoch 24/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.1984 - accuracy: 0.9243 - val_loss: 0.2939 - val_accuracy: 0.8960 - lr: 0.0250
Epoch 25/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.1933 - accuracy: 0.9265 - val_loss: 0.3062 - val_accuracy: 0.8966 - lr: 0.0250
Epoch 26/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.1947 - accuracy: 0.9268 - val_loss: 0.3093 - val_accuracy: 0.8924 - lr: 0.0250
Epoch 27/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.1919 - accuracy: 0.9275 - val_loss: 0.3100 - val_accuracy: 0.8990 - lr: 0.0250
Epoch 28/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.1743 - accuracy: 0.9354 - val_loss: 0.2958 - val_accuracy: 0.8992 - lr: 0.0125
Epoch 29/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.1739 - accuracy: 0.9354 - val_loss: 0.2910 - val_accuracy: 0.9004 - lr: 0.0125
Epoch 30/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.1685 - accuracy: 0.9367 - val_loss: 0.2951 - val_accuracy: 0.8994 - lr: 0.0125</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1"></a>model.evaluate(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a><span class="co"># Perform MC Dropout </span></span>
<span id="cb75-2"><a href="#cb75-2"></a>y_probas <span class="op">=</span> np.stack([model(X_test, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb75-3"><a href="#cb75-3"></a>                     <span class="cf">for</span> sample <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>)])</span>
<span id="cb75-4"><a href="#cb75-4"></a>y_proba <span class="op">=</span> y_probas.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-5"><a href="#cb75-5"></a>y_std <span class="op">=</span> y_probas.std(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-6"><a href="#cb75-6"></a>y_pred <span class="op">=</span> np.argmax(y_proba, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1"></a>accuracy <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">==</span> y_test) <span class="op">/</span> <span class="bu">len</span>(y_test)</span>
<span id="cb76-2"><a href="#cb76-2"></a>accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="building-a-regression-mlp-using-the-sequential-api" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="building-a-regression-mlp-using-the-sequential-api"><span class="header-section-number">8.5</span> Building a Regression MLP Using the Sequential API</h2>
<p>Let’s load, split and scale the California housing dataset (the original one, not the modified one as in our first lecture. This dataset is simpler than the one we used, since it contains only numerical features (there is no <code>ocean_proximity</code> feature, and there is no missing value.):</p>
<p><a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1"></a>housing <span class="op">=</span> fetch_california_housing()</span>
<span id="cb77-2"><a href="#cb77-2"></a></span>
<span id="cb77-3"><a href="#cb77-3"></a>X_train_full, X_test, y_train_full, y_test <span class="op">=</span> train_test_split(housing.data, housing.target, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb77-4"><a href="#cb77-4"></a>X_train, X_valid, y_train, y_valid <span class="op">=</span> train_test_split(X_train_full, y_train_full, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb77-5"><a href="#cb77-5"></a></span>
<span id="cb77-6"><a href="#cb77-6"></a><span class="co"># Scale the features</span></span>
<span id="cb77-7"><a href="#cb77-7"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb77-8"><a href="#cb77-8"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb77-9"><a href="#cb77-9"></a>X_valid <span class="op">=</span> scaler.transform(X_valid)</span>
<span id="cb77-10"><a href="#cb77-10"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1"></a>housing.data.shape, housing.target</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1"></a>pd.DataFrame(housing.data, columns<span class="op">=</span>housing.feature_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Building, training, evaluating and using a regression MLP using the Sequential API to make predictions is quite similar to what we did for classification. The main differences are the fact that the output layer has a single neuron (since we only want to predict a single value) and uses no activation function, and the loss function is the mean squared error.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb80-2"><a href="#cb80-2"></a>    tf.keras.layers.InputLayer(input_shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:]),</span>
<span id="cb80-3"><a href="#cb80-3"></a>    tf.keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb80-4"><a href="#cb80-4"></a>    tf.keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb80-5"><a href="#cb80-5"></a>    tf.keras.layers.Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb80-6"><a href="#cb80-6"></a>    tf.keras.layers.Dense(<span class="dv">1</span>)</span>
<span id="cb80-7"><a href="#cb80-7"></a>])</span>
<span id="cb80-8"><a href="#cb80-8"></a></span>
<span id="cb80-9"><a href="#cb80-9"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1"></a>optimizer <span class="op">=</span> tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb81-2"><a href="#cb81-2"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"mse"</span>, optimizer<span class="op">=</span>optimizer, metrics<span class="op">=</span>[<span class="st">"RootMeanSquaredError"</span>])</span>
<span id="cb81-3"><a href="#cb81-3"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb81-4"><a href="#cb81-4"></a>                    validation_data<span class="op">=</span>(X_valid, y_valid))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1"></a>mse_test, rmse_test <span class="op">=</span> model.evaluate(X_test, y_test)</span>
<span id="cb82-2"><a href="#cb82-2"></a>X_new <span class="op">=</span> X_test[:<span class="dv">3</span>]</span>
<span id="cb82-3"><a href="#cb82-3"></a>y_pred <span class="op">=</span> model.predict(X_new)</span>
<span id="cb82-4"><a href="#cb82-4"></a>rmse_test, y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="building-complex-models-using-the-functional-api-optional" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="building-complex-models-using-the-functional-api-optional"><span class="header-section-number">8.6</span> Building Complex Models Using the Functional API (Optional)</h2>
<p>Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide &amp; Deep neural network (see <a href="https://ai.google/research/pubs/pub45413">paper</a>) connects all or part of the inputs directly to the output layer. <strong>This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path).</strong> In contrast, a regular MLP forces all the data to flow through the full stack of layers, thus simple patterns in the data may end up being distorted by this sequence of transformations.</p>
<center>
<img src="https://drive.google.com/uc?id=1YfeBGcsHyReUuHokxltk8tQNWjV7L1cG" alt="drawing" width="400">
</center>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1"></a>normalization_layer <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb83-2"><a href="#cb83-2"></a>hidden_layer1 <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>)</span>
<span id="cb83-3"><a href="#cb83-3"></a>hidden_layer2 <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>)</span>
<span id="cb83-4"><a href="#cb83-4"></a>concat_layer <span class="op">=</span> tf.keras.layers.Concatenate()</span>
<span id="cb83-5"><a href="#cb83-5"></a>output_layer <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>)</span>
<span id="cb83-6"><a href="#cb83-6"></a></span>
<span id="cb83-7"><a href="#cb83-7"></a>input_ <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="cb83-8"><a href="#cb83-8"></a>normalized <span class="op">=</span> normalization_layer(input_)</span>
<span id="cb83-9"><a href="#cb83-9"></a>hidden1 <span class="op">=</span> hidden_layer1(normalized)</span>
<span id="cb83-10"><a href="#cb83-10"></a>hidden2 <span class="op">=</span> hidden_layer2(hidden1)</span>
<span id="cb83-11"><a href="#cb83-11"></a>concat <span class="op">=</span> concat_layer([normalized, hidden2])</span>
<span id="cb83-12"><a href="#cb83-12"></a>output <span class="op">=</span> output_layer(concat)</span>
<span id="cb83-13"><a href="#cb83-13"></a></span>
<span id="cb83-14"><a href="#cb83-14"></a>model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[input_], outputs<span class="op">=</span>[output])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>First, we need to create an <code>Input</code> object. This is needed because we may have multiple inputs, as we will see later.</li>
<li>Next, we create a <code>Dense</code> layer with 30 neurons and using the <code>ReLU</code> activation function. As soon as it is created, <strong>notice that we call it like a function</strong>, passing it the input. This is why this is called the Functional API. Note that we are just telling Keras how it should connect the layers together, no actual data is being processed yet.</li>
<li>We create a <code>Concatenate()</code> layer, and once again we immediately use it like a function, to <strong>concatenate the input layer and the output of the second hidden layer</strong>.</li>
<li>Lastly, we create a Keras Model, specifying which inputs and outputs to use.</li>
</ul>
<blockquote class="blockquote">
<p>The Normalization layer learns the feature means and standard deviations in the training data when you call the <code>adapt()</code> method. Yet when you display the model’s summary, these statistics are listed as non-trainable. This is because these parameters are not affected by gradient descent.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1"></a>tf.keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1"></a>optimizer <span class="op">=</span> tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb86-2"><a href="#cb86-2"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"mse"</span>, optimizer<span class="op">=</span>optimizer, metrics<span class="op">=</span>[<span class="st">"RootMeanSquaredError"</span>])</span>
<span id="cb86-3"><a href="#cb86-3"></a>normalization_layer.adapt(X_train) <span class="co"># Normalize the input</span></span>
<span id="cb86-4"><a href="#cb86-4"></a></span>
<span id="cb86-5"><a href="#cb86-5"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb86-6"><a href="#cb86-6"></a>                    validation_data<span class="op">=</span>(X_valid, y_valid))</span>
<span id="cb86-7"><a href="#cb86-7"></a>mse_test <span class="op">=</span> model.evaluate(X_test, y_test)</span>
<span id="cb86-8"><a href="#cb86-8"></a>y_pred <span class="op">=</span> model.predict(X_new)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1"></a>mse_test, rmse_test <span class="op">=</span> model.evaluate(X_test, y_test)</span>
<span id="cb87-2"><a href="#cb87-2"></a>X_new <span class="op">=</span> X_test[:<span class="dv">3</span>]</span>
<span id="cb87-3"><a href="#cb87-3"></a>y_pred <span class="op">=</span> model.predict(X_new)</span>
<span id="cb87-4"><a href="#cb87-4"></a>rmse_test, y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>But what if you want to send a subset of the features through the wide path, and a different subset (possibly overlapping) through the deep path? In this case, one solution is to use multiple inputs. For example, suppose we want to send 5 features through the deep path (features 0 to 4), and 6 features through the wide path (features 2 to 7).</p>
<center>
<img src="https://drive.google.com/uc?id=1YhJ-16zGDG0GkdDeZUJWi5FJAfPHQJvs" alt="drawing" width="400">
</center>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1"></a>input_wide <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>[<span class="dv">5</span>])  <span class="co"># features 0 to 4</span></span>
<span id="cb88-2"><a href="#cb88-2"></a>input_deep <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>[<span class="dv">6</span>])  <span class="co"># features 2 to 7</span></span>
<span id="cb88-3"><a href="#cb88-3"></a>norm_layer_wide <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb88-4"><a href="#cb88-4"></a>norm_layer_deep <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb88-5"><a href="#cb88-5"></a>norm_wide <span class="op">=</span> norm_layer_wide(input_wide)</span>
<span id="cb88-6"><a href="#cb88-6"></a>norm_deep <span class="op">=</span> norm_layer_deep(input_deep)</span>
<span id="cb88-7"><a href="#cb88-7"></a>hidden1 <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(norm_deep)</span>
<span id="cb88-8"><a href="#cb88-8"></a>hidden2 <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(hidden1)</span>
<span id="cb88-9"><a href="#cb88-9"></a>concat <span class="op">=</span> tf.keras.layers.concatenate([norm_wide, hidden2])</span>
<span id="cb88-10"><a href="#cb88-10"></a>output <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>)(concat)</span>
<span id="cb88-11"><a href="#cb88-11"></a>model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[input_wide, input_deep], outputs<span class="op">=</span>[output])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1"></a>tf.keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>On the other hand, there are also many use cases in which you may want to <strong>have multiple outputs</strong>: 1. The task may demand it, for example you may want to locate and classify the main object in a picture. This is both a regression task (finding the coordinates of the object’s center, as well as its width and height) and a classification task. 2. Similarly, you may have multiple independent tasks to perform based on the same data. Sure, you could train one neural network per task, but in many cases you will get better results on all tasks by training a single neural network with one output per task. This is because the neural network can <strong>learn features in the data that are useful across tasks</strong>. For instance, you may want to build a multitask classification on pictures of facesm using one out put to classify the facial expression while another to identify whether they are wearing glasses or not. 3. Another use case is as a regularization technique (i.e., a training constraint whose objective is to reduce overfitting and thus improve the model’s ability to generalize). For example, you may want to add some auxiliary outputs in a neural network architecture to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of thenetwork. Adding an auxiliary output for regularization:</p>
<p>The network we would like to build is thus like the following figure:</p>
<center>
<img src="https://drive.google.com/uc?id=1YiqI9s6oXEfV5P5GXXZjzSMOea4rqU8D" alt="drawing" width="400">
</center>
<p>Adding extra outputs is quite easy: just connect them to the appropriate layers and add them to your model’s list of outputs</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1"></a>tf.keras.backend.clear_session()</span>
<span id="cb91-2"><a href="#cb91-2"></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb91-3"><a href="#cb91-3"></a></span>
<span id="cb91-4"><a href="#cb91-4"></a>input_wide <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>[<span class="dv">5</span>])  <span class="co"># features 0 to 4</span></span>
<span id="cb91-5"><a href="#cb91-5"></a>input_deep <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>[<span class="dv">6</span>])  <span class="co"># features 2 to 7</span></span>
<span id="cb91-6"><a href="#cb91-6"></a>norm_layer_wide <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb91-7"><a href="#cb91-7"></a>norm_layer_deep <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb91-8"><a href="#cb91-8"></a>norm_wide <span class="op">=</span> norm_layer_wide(input_wide)</span>
<span id="cb91-9"><a href="#cb91-9"></a>norm_deep <span class="op">=</span> norm_layer_deep(input_deep)</span>
<span id="cb91-10"><a href="#cb91-10"></a>hidden1 <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(norm_deep)</span>
<span id="cb91-11"><a href="#cb91-11"></a>hidden2 <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(hidden1)</span>
<span id="cb91-12"><a href="#cb91-12"></a>concat <span class="op">=</span> tf.keras.layers.concatenate([norm_wide, hidden2])</span>
<span id="cb91-13"><a href="#cb91-13"></a>output <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>)(concat)</span>
<span id="cb91-14"><a href="#cb91-14"></a>aux_output <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>)(hidden2)</span>
<span id="cb91-15"><a href="#cb91-15"></a>model <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[input_wide, input_deep], outputs<span class="op">=</span>[output, aux_output])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1"></a>tf.keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Each output will need its own loss function, so when we compile the model we should pass a list of losses. By default, <code>Keras</code> will compute all these losses and simply add them up to get the final loss used for training. However, we care much more about the main output than about the auxiliary output (as it is just used for regularization), so we want to give the main output’s loss a much greater weight.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1"></a>optimizer <span class="op">=</span> tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb94-2"><a href="#cb94-2"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span>(<span class="st">"mse"</span>, <span class="st">"mse"</span>), loss_weights<span class="op">=</span>(<span class="fl">0.9</span>, <span class="fl">0.1</span>), optimizer<span class="op">=</span>optimizer,</span>
<span id="cb94-3"><a href="#cb94-3"></a>              metrics<span class="op">=</span>[<span class="st">"RootMeanSquaredError"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now when we train the model, we need to provide some labels for each output. In this example, the main output and the auxiliary output should try to predict the same thing, so they should use the same labels. So instead of passing <code>y_train</code>, we just need to pass <code>(y_train, y_train)</code> (and the same goes for <code>y_valid</code> and <code>y_test</code>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1"></a>X_train_wide, X_train_deep <span class="op">=</span> X_train[:, :<span class="dv">5</span>], X_train[:, <span class="dv">2</span>:]</span>
<span id="cb95-2"><a href="#cb95-2"></a>X_valid_wide, X_valid_deep <span class="op">=</span> X_valid[:, :<span class="dv">5</span>], X_valid[:, <span class="dv">2</span>:]</span>
<span id="cb95-3"><a href="#cb95-3"></a>X_test_wide, X_test_deep <span class="op">=</span> X_test[:, :<span class="dv">5</span>], X_test[:, <span class="dv">2</span>:]</span>
<span id="cb95-4"><a href="#cb95-4"></a>X_new_wide, X_new_deep <span class="op">=</span> X_test_wide[:<span class="dv">3</span>], X_test_deep[:<span class="dv">3</span>]</span>
<span id="cb95-5"><a href="#cb95-5"></a></span>
<span id="cb95-6"><a href="#cb95-6"></a>norm_layer_wide.adapt(X_train_wide)</span>
<span id="cb95-7"><a href="#cb95-7"></a>norm_layer_deep.adapt(X_train_deep)</span>
<span id="cb95-8"><a href="#cb95-8"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb95-9"><a href="#cb95-9"></a>    (X_train_wide, X_train_deep), (y_train, y_train), epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb95-10"><a href="#cb95-10"></a>    validation_data<span class="op">=</span>((X_valid_wide, X_valid_deep), (y_valid, y_valid))</span>
<span id="cb95-11"><a href="#cb95-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When we evaluate the model, Keras will return the total loss, as well as all the individual losses:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1"></a>eval_results <span class="op">=</span> model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))</span>
<span id="cb96-2"><a href="#cb96-2"></a>weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse <span class="op">=</span> eval_results</span>
<span id="cb96-3"><a href="#cb96-3"></a>weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1"></a>y_pred_main, y_pred_aux <span class="op">=</span> model.predict((X_new_wide, X_new_deep))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="building-dynamic-models-using-the-subclassing-api-optional" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="building-dynamic-models-using-the-subclassing-api-optional"><span class="header-section-number">8.7</span> Building Dynamic Models Using the Subclassing API (Optional)</h2>
<p>Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. For such cases, or simply if you prefer a more imperative programming style, the <code>Subclassing</code> API is for you.</p>
<p>Simply subclass the <code>Model</code> class, create the layers you need in the constructor, and use them to perform the computations you want in the <code>call()</code> method. For example, creating an instance of the following <code>WideAndDeepModel</code> class gives us an equivalent model to the one we just built with the Functional API.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1"></a><span class="kw">class</span> WideAndDeepModel(tf.keras.Model):</span>
<span id="cb98-2"><a href="#cb98-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, units<span class="op">=</span><span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>, <span class="op">**</span>kwargs):</span>
<span id="cb98-3"><a href="#cb98-3"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)  <span class="co"># needed to support naming the model</span></span>
<span id="cb98-4"><a href="#cb98-4"></a>        <span class="va">self</span>.norm_layer_wide <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb98-5"><a href="#cb98-5"></a>        <span class="va">self</span>.norm_layer_deep <span class="op">=</span> tf.keras.layers.Normalization()</span>
<span id="cb98-6"><a href="#cb98-6"></a>        <span class="va">self</span>.hidden1 <span class="op">=</span> tf.keras.layers.Dense(units, activation<span class="op">=</span>activation)</span>
<span id="cb98-7"><a href="#cb98-7"></a>        <span class="va">self</span>.hidden2 <span class="op">=</span> tf.keras.layers.Dense(units, activation<span class="op">=</span>activation)</span>
<span id="cb98-8"><a href="#cb98-8"></a>        <span class="va">self</span>.main_output <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>)</span>
<span id="cb98-9"><a href="#cb98-9"></a>        <span class="va">self</span>.aux_output <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>)</span>
<span id="cb98-10"><a href="#cb98-10"></a>        </span>
<span id="cb98-11"><a href="#cb98-11"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb98-12"><a href="#cb98-12"></a>        input_wide, input_deep <span class="op">=</span> inputs</span>
<span id="cb98-13"><a href="#cb98-13"></a>        norm_wide <span class="op">=</span> <span class="va">self</span>.norm_layer_wide(input_wide)</span>
<span id="cb98-14"><a href="#cb98-14"></a>        norm_deep <span class="op">=</span> <span class="va">self</span>.norm_layer_deep(input_deep)</span>
<span id="cb98-15"><a href="#cb98-15"></a>        hidden1 <span class="op">=</span> <span class="va">self</span>.hidden1(norm_deep)</span>
<span id="cb98-16"><a href="#cb98-16"></a>        hidden2 <span class="op">=</span> <span class="va">self</span>.hidden2(hidden1)</span>
<span id="cb98-17"><a href="#cb98-17"></a>        concat <span class="op">=</span> tf.keras.layers.concatenate([norm_wide, hidden2])</span>
<span id="cb98-18"><a href="#cb98-18"></a>        output <span class="op">=</span> <span class="va">self</span>.main_output(concat)</span>
<span id="cb98-19"><a href="#cb98-19"></a>        aux_output <span class="op">=</span> <span class="va">self</span>.aux_output(hidden2)</span>
<span id="cb98-20"><a href="#cb98-20"></a>        <span class="cf">return</span> output, aux_output</span>
<span id="cb98-21"><a href="#cb98-21"></a></span>
<span id="cb98-22"><a href="#cb98-22"></a>model <span class="op">=</span> WideAndDeepModel(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>, name<span class="op">=</span><span class="st">"my_cool_model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This example looks very much like the Functional API, except we do not need to create the inputs, we just use the input argument to the <code>call()</code> method, and <strong>we separate the creation of the layers in the constructor from their usage in the <code>call()</code> method.</strong> However, the big difference is that <strong>you can do pretty much anything you want in the <code>call()</code> method: for loops, if statements, low-level TensorFlow operations! This makes it a great API for researchers experimenting with new ideas.</strong></p>
<p>However, this extra flexibility comes at a cost: your model’s architecture is hidden within the <code>call()</code> method, so Keras cannot easily inspect it, it cannot save or clone it, and when you call the <code>summary()</code> method, you only get a list of layers, without any information on how they are connected to each other.Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1"></a>input_shape<span class="op">=</span>[(<span class="va">None</span>, <span class="dv">5</span>), (<span class="va">None</span>, <span class="dv">6</span>)]</span>
<span id="cb99-2"><a href="#cb99-2"></a>model.build(input_shape) <span class="co"># We have to tell keras the input shape to count the number of parameters</span></span>
<span id="cb99-3"><a href="#cb99-3"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1"></a>tf.keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1"></a>optimizer <span class="op">=</span> tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb101-2"><a href="#cb101-2"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"mse"</span>, loss_weights<span class="op">=</span>[<span class="fl">0.9</span>, <span class="fl">0.1</span>], optimizer<span class="op">=</span>optimizer,</span>
<span id="cb101-3"><a href="#cb101-3"></a>              metrics<span class="op">=</span>[<span class="st">"RootMeanSquaredError"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1"></a>model.norm_layer_wide.adapt(X_train_wide)</span>
<span id="cb102-2"><a href="#cb102-2"></a>model.norm_layer_deep.adapt(X_train_deep)</span>
<span id="cb102-3"><a href="#cb102-3"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb102-4"><a href="#cb102-4"></a>    (X_train_wide, X_train_deep), (y_train, y_train), epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb102-5"><a href="#cb102-5"></a>    validation_data<span class="op">=</span>((X_valid_wide, X_valid_deep), (y_valid, y_valid)))</span>
<span id="cb102-6"><a href="#cb102-6"></a>eval_results <span class="op">=</span> model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))</span>
<span id="cb102-7"><a href="#cb102-7"></a>weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse <span class="op">=</span> eval_results</span>
<span id="cb102-8"><a href="#cb102-8"></a>y_pred_main, y_pred_aux <span class="op">=</span> model.predict((X_new_wide, X_new_deep))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="saving-and-restoring" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="saving-and-restoring"><span class="header-section-number">8.8</span> Saving and Restoring</h2>
<p>When you set <code>save_format="tf"</code>, <code>Keras</code> saves the model using <code>TensorFlow</code>’s Saved‐Model format: this is a directory (with the given name) containing several files and subdirectories. In particular, the <code>saved_model.pb</code> file contains the model’s architecture and logic in the form of a serialized computation graph, so you don’t need to deploy the model’s source code in order to use it in production; the <code>SavedModel</code> is sufficient. The <code>keras_metadata.pb</code> file contains extra information needed by <code>Keras</code>. The variables subdirectory contains all the parameter values (including the connection weights, the biases, the normalization statistics, and the optimizer’s parameters), possibly split across multiple files if the model is very large. Lastly, the assets directory may contain extra files, such as data samples, feature names, class names, and so on. By default, the assets directory is empty. Since the optimizer is also saved, including its hyperparameters and any state it may have, after loading the model you can continue training if you want.</p>
<blockquote class="blockquote">
<p>If you set <code>save_format="h5"</code> or use a filename that ends with .h5, .hdf5, or .keras, then Keras will save the model to a single file using a Keras-specific format based on the HDF5 format. However, most TensorFlow deployment tools require the <code>SavedModel</code> format instead.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1"></a>model.save(<span class="st">"my_keras_model"</span>, save_format<span class="op">=</span><span class="st">"tf"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1"></a><span class="cf">for</span> path <span class="kw">in</span> <span class="bu">sorted</span>(Path(<span class="st">"my_keras_model"</span>).glob(<span class="st">"**/*"</span>)):</span>
<span id="cb104-2"><a href="#cb104-2"></a>    <span class="bu">print</span>(path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can then load the model using <code>tf.keras.models.load_model()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1"></a>model <span class="op">=</span> tf.keras.models.load_model(<span class="st">"my_keras_model"</span>)</span>
<span id="cb105-2"><a href="#cb105-2"></a>y_pred_main, y_pred_aux <span class="op">=</span> model.predict((X_new_wide, X_new_deep))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can also use <code>save_weights()</code> and <code>load_weights()</code> to save and load only the parameter values. This includes the connection weights, biases, preprocessing stats, optimizer state, etc. The parameter values are saved in one or more files such as <code>my_weights.data-00004-of-00052</code>, plus an index file like <code>my_weights.index</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1"></a>model.save_weights(<span class="st">"my_weights"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1"></a>model.load_weights(<span class="st">"my_weights"</span>) <span class="co"># Note that you have to get the model before loading weights here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1"></a><span class="cf">for</span> path <span class="kw">in</span> <span class="bu">sorted</span>(Path().glob(<span class="st">"my_weights.*"</span>)):</span>
<span id="cb108-2"><a href="#cb108-2"></a>    <span class="bu">print</span>(path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="using-callbacks-during-training" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="using-callbacks-during-training"><span class="header-section-number">8.9</span> Using Callbacks during Training</h2>
<p>But what if training lasts several hours? In this case, you should not only save your model at the end of training, but also save checkpoints at regular intervals during training. The <code>fit()</code> method accepts a callbacks argument that lets you specify a list of objects that Keras will call during training at the start and end of training, at the start and end of each epoch and even before and after processing each batch. For example, the <code>ModelCheckpoint</code> callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch:</p>
<p><a href="https://keras.io/callbacks/">https://keras.io/callbacks/</a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1"></a><span class="co"># if you use a validation set during training, you can set</span></span>
<span id="cb109-2"><a href="#cb109-2"></a><span class="co"># save_best_only=True when creating the ModelCheckpoint. In this case, it will only</span></span>
<span id="cb109-3"><a href="#cb109-3"></a><span class="co"># save your model when its performance on the validation set is the best so far.</span></span>
<span id="cb109-4"><a href="#cb109-4"></a>checkpoint_cb <span class="op">=</span> tf.keras.callbacks.ModelCheckpoint(<span class="st">"my_checkpoints"</span>, save_best_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb109-5"><a href="#cb109-5"></a></span>
<span id="cb109-6"><a href="#cb109-6"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb109-7"><a href="#cb109-7"></a>    (X_train_wide, X_train_deep), (y_train, y_train), epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb109-8"><a href="#cb109-8"></a>    validation_data<span class="op">=</span>((X_valid_wide, X_valid_deep), (y_valid, y_valid)),</span>
<span id="cb109-9"><a href="#cb109-9"></a>    callbacks<span class="op">=</span>[checkpoint_cb])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Another way to implement early stopping is to simply use the <code>EarlyStopping</code> callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the <code>patience</code> argument), and it will optionally roll back to the best model. <strong>You can combine both callbacks to both save checkpoints of your model</strong> (in case your computer crashes), and actually interrupt training early when there is no more progress (to avoid wasting time and resources):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1"></a>early_stopping_cb <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">10</span>, restore_best_weights<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb110-2"><a href="#cb110-2"></a></span>
<span id="cb110-3"><a href="#cb110-3"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb110-4"><a href="#cb110-4"></a>    (X_train_wide, X_train_deep), (y_train, y_train), epochs<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb110-5"><a href="#cb110-5"></a>    validation_data<span class="op">=</span>((X_valid_wide, X_valid_deep), (y_valid, y_valid)),</span>
<span id="cb110-6"><a href="#cb110-6"></a>    callbacks<span class="op">=</span>[checkpoint_cb, early_stopping_cb])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The number of epochs can be set to a large value since training will stop automatically when there is no more progress (just make sure the learning rate is not too small, or else it might keep making slow progress until the end). The <code>EarlyStopping</code> callback will store the weights of the best model in RAM, and it will restore them for you at the end of training.</p>
<p>If you need extra control, you can easily write your own custom callbacks. For example, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1"></a><span class="kw">class</span> PrintValTrainRatioCallback(tf.keras.callbacks.Callback):</span>
<span id="cb111-2"><a href="#cb111-2"></a>    <span class="kw">def</span> on_epoch_end(<span class="va">self</span>, epoch, logs):</span>
<span id="cb111-3"><a href="#cb111-3"></a>        ratio <span class="op">=</span> logs[<span class="st">"val_loss"</span>] <span class="op">/</span> logs[<span class="st">"loss"</span>]</span>
<span id="cb111-4"><a href="#cb111-4"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch=</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, val/train=</span><span class="sc">{</span>ratio<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1"></a>val_train_ratio_cb <span class="op">=</span> PrintValTrainRatioCallback()</span>
<span id="cb112-2"><a href="#cb112-2"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb112-3"><a href="#cb112-3"></a>    (X_train_wide, X_train_deep), (y_train, y_train), epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb112-4"><a href="#cb112-4"></a>    validation_data<span class="op">=</span>((X_valid_wide, X_valid_deep), (y_valid, y_valid)),</span>
<span id="cb112-5"><a href="#cb112-5"></a>    callbacks<span class="op">=</span>[val_train_ratio_cb], verbose<span class="op">=</span><span class="dv">0</span>) <span class="co"># Note that we use verbose=0 here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tensorboard" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="tensorboard"><span class="header-section-number">8.10</span> TensorBoard</h2>
<p>Now let’s take a look at one more tool you should definitely have in your toolbox when using <code>tf.keras</code>: TensorBoard. TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, and more!</p>
<p>To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called <strong>event files</strong>. Each binary data record is called a <em>summary</em>. The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations.</p>
<p>In general, you want to point the TensorBoard server to a root log directory, and configure your program so that it writes to a different subdirectory every time it runs. So let’s start by defining the root log directory we will use for our TensorBoard logs, plus a small function that will generate a subdirectory path based on the current date and time, so that it is different at every run.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1"></a>root_logdir <span class="op">=</span> os.path.join(os.curdir, <span class="st">"my_logs"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1"></a><span class="kw">def</span> get_run_logdir(root_logdir<span class="op">=</span><span class="st">"my_logs"</span>):</span>
<span id="cb114-2"><a href="#cb114-2"></a>    <span class="cf">return</span> Path(root_logdir) <span class="op">/</span> strftime(<span class="st">"run_%Y_%m_</span><span class="sc">%d</span><span class="st">_%H_%M_%S"</span>)</span>
<span id="cb114-3"><a href="#cb114-3"></a></span>
<span id="cb114-4"><a href="#cb114-4"></a>run_logdir <span class="op">=</span> get_run_logdir()</span>
<span id="cb114-5"><a href="#cb114-5"></a>run_logdir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1"></a><span class="co"># builds the first regression model we used earlier</span></span>
<span id="cb115-2"><a href="#cb115-2"></a></span>
<span id="cb115-3"><a href="#cb115-3"></a>norm_layer <span class="op">=</span> tf.keras.layers.Normalization(input_shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="cb115-4"><a href="#cb115-4"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb115-5"><a href="#cb115-5"></a>    norm_layer,</span>
<span id="cb115-6"><a href="#cb115-6"></a>    tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb115-7"><a href="#cb115-7"></a>    tf.keras.layers.Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb115-8"><a href="#cb115-8"></a>    tf.keras.layers.Dense(<span class="dv">1</span>)</span>
<span id="cb115-9"><a href="#cb115-9"></a>])</span>
<span id="cb115-10"><a href="#cb115-10"></a>optimizer <span class="op">=</span> tf.keras.optimizers.SGD(learning_rate<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb115-11"><a href="#cb115-11"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"mse"</span>, optimizer<span class="op">=</span>optimizer, metrics<span class="op">=</span>[<span class="st">"RootMeanSquaredError"</span>])</span>
<span id="cb115-12"><a href="#cb115-12"></a>norm_layer.adapt(X_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1"></a>tensorboard_cb <span class="op">=</span> tf.keras.callbacks.TensorBoard(run_logdir, profile_batch<span class="op">=</span>(<span class="dv">100</span>, <span class="dv">200</span>))</span>
<span id="cb116-2"><a href="#cb116-2"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb116-3"><a href="#cb116-3"></a>                    validation_data<span class="op">=</span>(X_valid, y_valid),</span>
<span id="cb116-4"><a href="#cb116-4"></a>                    callbacks<span class="op">=</span>[tensorboard_cb])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1"></a><span class="bu">print</span>(<span class="st">"my_logs"</span>)</span>
<span id="cb117-2"><a href="#cb117-2"></a><span class="cf">for</span> path <span class="kw">in</span> <span class="bu">sorted</span>(Path(<span class="st">"my_logs"</span>).glob(<span class="st">"**/*"</span>)):</span>
<span id="cb117-3"><a href="#cb117-3"></a>    <span class="bu">print</span>(<span class="st">"  "</span> <span class="op">*</span> (<span class="bu">len</span>(path.parts) <span class="op">-</span> <span class="dv">1</span>) <span class="op">+</span> path.parts[<span class="op">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook’s directory, then type:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb118-1"><a href="#cb118-1"></a><span class="ex">$</span> tensorboard <span class="at">--logdir</span><span class="op">=</span>./my_logs <span class="at">--port</span><span class="op">=</span>6006</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can then open your web browser to <a href="http://localhost:6006">localhost:6006</a> and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.</p>
<p>Alternatively, you can load TensorBoard’s Jupyter extension and run it like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1"></a><span class="op">%</span>load_ext tensorboard</span>
<span id="cb119-2"><a href="#cb119-2"></a><span class="op">%</span>tensorboard <span class="op">--</span>logdir<span class="op">=</span>.<span class="op">/</span>my_logs <span class="op">--</span>port<span class="op">=</span><span class="dv">6006</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1"></a><span class="im">from</span> tensorboard <span class="im">import</span> notebook</span>
<span id="cb120-2"><a href="#cb120-2"></a>notebook.<span class="bu">list</span>() <span class="co"># View open TensorBoard instances</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Check out the other available logging options:</p>
<p><a href="https://www.tensorflow.org/tensorboard/get_started">https://www.tensorflow.org/tensorboard/get_started</a></p>
</section>
<section id="references" class="level2" data-number="8.11">
<h2 data-number="8.11" class="anchored" data-anchor-id="references"><span class="header-section-number">8.11</span> References</h2>
<ol type="1">
<li><a href="https://github.com/ageron/handson-ml3/">https://github.com/ageron/handson-ml3/</a></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./07_Deploy.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Deploy and monitoring</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./09_Convolutional_NeuralNetworks_tensorflow.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Image processing with Convolutional Neural Networks - Tensorflow</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>